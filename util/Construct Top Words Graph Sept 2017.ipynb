{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numbers\n",
    "import pickle\n",
    "import snap\n",
    "from os import path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data/academia.stackexchange.com\"\n",
    "POST_TOP_NGRAM_PATH = path.join(BASE_PATH, \"Posts-top_words_more.tsv\")\n",
    "USERID_NGRAM_TSV_PATH_POSTSEPT17 = path.join(BASE_PATH, \"Userid_Ngram_Bipartite_Graph_PostSept17.tsv\")\n",
    "POSTID_NGRAM_TSV_PATH_POSTSEPT17 = path.join(BASE_PATH, \"Postid_Ngram_Bipartite_Graph_PostSept17.tsv\")\n",
    "NGRAMID_DICT_PICKLE_PATH_POSTSEPT17 = path.join(BASE_PATH, \"Ngramid_Dict_PostSept17.pickle\")\n",
    "USERID_SET_PICKLE_PATH_POSTSEPT17 = path.join(BASE_PATH, \"Userid_setPostSept17.pickle\")\n",
    "POSTID_SET_PICKLE_PATH_POSTSEPT17 = path.join(BASE_PATH, \"Postid_setPostSept17.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load top words from posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_top_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_word_columns = [\"TopWord%d\" % i for i in xrange(1, num_top_words+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(\"2012-02-14T20:23:40.127\".split(\"T\")[0], \"%Y-%m-%d\").year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(date_str):\n",
    "    return datetime.strptime(date_str.split(\"T\")[0], \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_top_ngram_df(topwords_path):\n",
    "    # Load csv containing the top words.\n",
    "    posts_df = pd.read_csv(topwords_path, sep = \"\\t\", usecols = \n",
    "                           [\"Id\", \"OwnerUserId\", \"TopWord1\", \"TopWord2\", \"TopWord3\", \"TopWord4\", \"TopWord5\",\n",
    "                           \"PostTypeId\", \"Date\"])\n",
    "    \n",
    "    # Clean dataframe.\n",
    "    posts_df = posts_df.dropna()\n",
    "    posts_df = posts_df.rename(columns={\n",
    "            \"Id\": \"post_id\", \"OwnerUserId\": \"user_id\", \"PostTypeId\": \"Type\",\n",
    "            \"Date\": \"date\"})\n",
    "    posts_df[\"user_id\"] = posts_df[\"user_id\"].astype(np.int64)\n",
    "    posts_df[\"post_id\"] = posts_df[\"post_id\"].astype(np.int64)\n",
    "    posts_df = posts_df[posts_df[\"user_id\"] > 0]\n",
    "    posts_df = posts_df[posts_df[\"post_id\"] > 0]\n",
    "    \n",
    "    # Convert date from string to datetime.\n",
    "    posts_df[\"date\"] = posts_df[\"date\"].apply(get_date)\n",
    "    \n",
    "    # Create a year column.\n",
    "    posts_df[\"year\"] = posts_df[\"date\"].apply(lambda x: x.year)\n",
    "\n",
    "    return posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_ngram_set(posts_df):\n",
    "    top_ngram_set = set()\n",
    "    for col in top_word_columns:\n",
    "        top_ngram_set.update(posts_df[col].values)\n",
    "    return top_ngram_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_df = load_top_ngram_df(POST_TOP_NGRAM_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit posts to only ones occuring date limit_date.\n",
    "2017-09-02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_date = datetime(2017, 9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_df = posts_df[posts_df[\"date\"] >= limit_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct top_ngram_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_ngram_set = get_top_ngram_set(posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of n-grams: 17907\n"
     ]
    }
   ],
   "source": [
    "print \"Number of n-grams:\", len(top_ngram_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct User-Id to Ngram and Post-Id to Ngram Graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ngram_id_dict(top_ngram_set, init_index):\n",
    "    \"\"\"\n",
    "    Create dictionary mapping n-gram to an integer index greater than or equal to init_index.\n",
    "    \"\"\"    \n",
    "    # Create dictinonary that maps n-gram to its id.\n",
    "    ngram_id_dict = dict()\n",
    "    curr_index = init_index\n",
    "    for ngram in top_ngram_set:\n",
    "        ngram_id_dict[ngram] = curr_index\n",
    "        curr_index += 1\n",
    "    \n",
    "    return ngram_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph_dfs(top_ngram_set, posts_df):\n",
    "    \"\"\"\n",
    "    Create user-id to n-gram and post-id to n-gram graph. The graphs will be stored as a Pandas dataframe.\n",
    "        Each row of the dataframe contains an edge of the graph. The dataframe can be written out as a tsv\n",
    "        to be read in as a Snap graph.\n",
    "    Returns:\n",
    "        Tuple (userid_ngram_df, postid_ngram_df, ngram_id_dict, user_id_set, post_id_set). ngramid_dict is\n",
    "        a dictionary mapping ngram to its assigned id value. userid_set is a set containing the user id nodes\n",
    "        that are included in the user-id graph. postid_set is a containing the post id nodes that\n",
    "        are included in teh post-id graph.\n",
    "    \"\"\"\n",
    "    # Create n-gram dict.\n",
    "    max_post_id = max(posts_df[\"post_id\"].values)\n",
    "    max_user_id = max(posts_df[\"user_id\"].values)\n",
    "    ngram_id_dict = create_ngram_id_dict(top_ngram_set, max(max_post_id, max_user_id) + 1)\n",
    "    \n",
    "    # Create dataframes storing the edges in the graphs.\n",
    "    user_id_nodes = []\n",
    "    post_id_nodes = []\n",
    "    ngram_id_nodes = []\n",
    "    for _, row in posts_df.iterrows():\n",
    "        user_id = row[\"user_id\"]\n",
    "        post_id = row[\"post_id\"]\n",
    "        top_ngrams = list(row[top_word_columns])        \n",
    "        if ((user_id < 0) or (post_id) < 0): continue\n",
    "        for ngram, ngram_id in ngram_id_dict.items():\n",
    "            if ngram in top_ngrams:\n",
    "                ngram_id_nodes.append(ngram_id)\n",
    "                user_id_nodes.append(user_id)\n",
    "                post_id_nodes.append(post_id)\n",
    "      \n",
    "    userid_ngram_df = pd.DataFrame({\"user_id\": user_id_nodes, \"ngram_id\": ngram_id_nodes})\n",
    "    postid_ngram_df = pd.DataFrame({\"post_id\": post_id_nodes, \"ngram_id\": ngram_id_nodes})\n",
    "    return userid_ngram_df, postid_ngram_df, ngram_id_dict, set(user_id_nodes), set(post_id_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct graphs stored in dataframes.\n",
    "userid_ngram_df, postid_ngram_df, ngramid_dict, userid_set, postid_set = create_graph_dfs(top_ngram_set, posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write graphs as tsv files that can be read as a Snap graph.\n",
    "userid_ngram_df.to_csv(USERID_NGRAM_TSV_PATH_POSTSEPT17, sep=\"\\t\", header=False, index=False)\n",
    "postid_ngram_df.to_csv(POSTID_NGRAM_TSV_PATH_POSTSEPT17, sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle to store ngramid_dict, userid_set, postid_set.\n",
    "pickle_out = open(NGRAMID_DICT_PICKLE_PATH_POSTSEPT17,\"wb\")\n",
    "pickle.dump(ngramid_dict, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(USERID_SET_PICKLE_PATH_POSTSEPT17,\"wb\")\n",
    "pickle.dump(userid_set, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(POSTID_SET_PICKLE_PATH_POSTSEPT17,\"wb\")\n",
    "pickle.dump(postid_set, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
