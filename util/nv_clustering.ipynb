{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_PATH='../data/stats.stackexchange.com/Mixed/Userid_Ngram_Folded_Graph.edges'\n",
    "EMB_PATH='../data/stats.stackexchange.com/Mixed/node2vec/Userid_Ngram_Folded_Graph.emb'\n",
    "EMB_PATH_10='../data/stats.stackexchange.com/Mixed/node2vec/Userid_Ngram_Folded_Graph_epoch10.emb'\n",
    "\n",
    "NGRAMID_DICT_PICKLE_PATH='../data/stats.stackexchange.com/Mixed/ngram_dict_STATS_20k-Posts_11-top_uni&bigrams_nostem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the graph DOES NOT WORK\n",
    "\n",
    "def read_graph(edgelist):\n",
    "    '''\n",
    "    Reads the input network in networkx.\n",
    "    '''\n",
    "    G = nx.read_edgelist(edgelist, nodetype=int, create_using=nx.DiGraph())\n",
    "    for edge in G.edges():\n",
    "        G[edge[0]][edge[1]]['weight'] = 1\n",
    "    G = G.to_undirected()\n",
    "    return G\n",
    "\n",
    "# load the graph\n",
    "nx_G = read_graph(GRAPH_PATH)\n",
    "\n",
    "NUM_DRAW_NODES = 10\n",
    "DRAW_PATH = '../fig/stats_mixed_ngrams_%d.png' % NUM_DRAW_NODES\n",
    "\n",
    "ngramid_dict = pickle.load(open(NGRAMID_DICT_PICKLE_PATH, \"rb\"))\n",
    "idngram_dict = {v: k for k, v in ngramid_dict.iteritems()}\n",
    "nx.draw_networkx(nx_G, labels=idngram_dict, nodelist=random.sample(list(nx_G.nodes()), NUM_NODES))\n",
    "plt.savefig(DRAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word vectors\n",
    "wv = KeyedVectors.load_word2vec_format(EMB_PATH, binary=False)\n",
    "X = wv[wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_e10 = KeyedVectors.load_word2vec_format(EMB_PATH_10, binary=False)\n",
    "X_e10 = wv_e10[wv_e10.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans clustering\n",
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=1)\n",
    "assigned_clusters = kclusterer.cluster(X, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=1,avoid_empty_clusters=True)\n",
    "assigned_clusters_e10 = kclusterer.cluster(X_e10, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['points data', 'comparison occur', 'appreciated reproducible', 'survey predicts', 'learning model', 'ucla edu', 'variable measures', 'single regression', 'assign flags', 'juvenile sex']\n"
     ]
    }
   ],
   "source": [
    "def get_average(nodes):\n",
    "    clust_X = [wv.get_vector(str(n)) for n in nodes]\n",
    "    ave = np.average(clust_X, axis=0)\n",
    "    return ave\n",
    "ave = get_average(cluster_to_nodes[0])\n",
    "top10 = wv.similar_by_vector(ave)\n",
    "print [idngram_dict[int(w[0])] for w in top10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual inspection\n",
    "def write_clusters(dict_path, words_path, assignments):\n",
    "    clusters_dict = {}\n",
    "    for w, clust in zip(wv.vocab, assignments):\n",
    "        clusters_dict[int(w)] = clust\n",
    "    \n",
    "    # save cluster mapping\n",
    "    with open(dict_path, 'w') as outfile:\n",
    "        pickle.dump(clusters_dict, outfile)\n",
    "    \n",
    "    cluster_to_nodes = defaultdict(list)\n",
    "    for node in clusters_dict:\n",
    "        cluster_to_nodes[clusters_dict[node]].append(node)\n",
    "\n",
    "    with open(words_path, 'w') as outfile:\n",
    "        for clust in cluster_to_nodes:  \n",
    "            outfile.write(\"Cluster %d [%d]\\n\" % (clust, len(cluster_to_nodes[clust])))\n",
    "            outfile.write('----------------\\n')\n",
    "            ave = get_average(cluster_to_nodes[clust])\n",
    "            top10 = wv.similar_by_vector(ave)\n",
    "            outfile.write('Top words: %s\\n' % [idngram_dict[int(w[0])] for w in top10])\n",
    "            for nid in cluster_to_nodes[clust]:\n",
    "                outfile.write(idngram_dict[nid]+'\\n')\n",
    "            outfile.write('----------------\\n')\n",
    "            outfile.write('----------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERS_PATH = '../data/stats.stackexchange.com/Mixed/node2vec_clusters_%d.words' % NUM_CLUSTERS\n",
    "CLUSTERS_DICT_PATH = '../data/stats.stackexchange.com/Mixed/node2vec_clusters_%d.dict' % NUM_CLUSTERS\n",
    "write_clusters(CLUSTERS_PATH, CLUSTERS_DICT_PATH, assigned_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write_clusters() takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-42aaa233dcb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCLUSTERS_PATH_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/stats.stackexchange.com/Mixed/node2vec_clusters_%d_epoch10.words'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mNUM_CLUSTERS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCLUSTERS_DICT_PATH_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/stats.stackexchange.com/Mixed/node2vec_clusters_%d_epoch10.dict'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mNUM_CLUSTERS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwrite_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLUSTERS_PATH_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLUSTERS_DICT_PATH_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massigned_clusters_e10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: write_clusters() takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "CLUSTERS_PATH_10 = '../data/stats.stackexchange.com/Mixed/node2vec_clusters_%d_epoch10.words' % NUM_CLUSTERS\n",
    "CLUSTERS_DICT_PATH_10 = '../data/stats.stackexchange.com/Mixed/node2vec_clusters_%d_epoch10.dict' % NUM_CLUSTERS\n",
    "write_clusters(CLUSTERS_PATH_10, CLUSTERS_DICT_PATH_10, assigned_clusters_e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modularity\n",
    "import get_modularity from get_modularity\n",
    "\n",
    "G = # to snap graph\n",
    "mod = get_modularity()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
