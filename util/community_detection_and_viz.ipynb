{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snap\n",
    "from os import path\n",
    "import pickle\n",
    "import collections\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data/stats.stackexchange.com/Mixed\"\n",
    "FOLDED_NGRAM_GRAPH_PATH = path.join(BASE_PATH, \"Userid_Ngram_Folded_Graph.graph\")\n",
    "FOLDED_POSTID_GRAPH_PATH = path.join(BASE_PATH, \"Postid_Folded_Graph.graph\")\n",
    "NGRAM_DICT_PICKLE = path.join(BASE_PATH, \"Bigramid_Dict\")\n",
    "POSTID_PICKLE = path.join(BASE_PATH, \"STATS_20k-Posts_11-top_uni&bigrams_nostem.pickle\")\n",
    "POST_TOP_NGRAM_PATH = path.join(BASE_PATH, \"STATS_20k-Posts_11-top_uni&bigrams_nostem.tsv\")\n",
    "COMMUNITIES_PATH = path.join(BASE_PATH, 'postid-communities-with-postbodies.txt')\n",
    "COMMUNITIES_VEC_PATH = path.join(BASE_PATH, 'postid-communities.vector')\n",
    "EDGELIST_PATH = path.join(BASE_PATH, 'postid_edges.txt')\n",
    "COMMUNITIES_VIZ_PATH = path.join(BASE_PATH, 'postid-communities-viz.csv')\n",
    "COMMUNITIES_VIZ_PATH2 = path.join(BASE_PATH, 'postid-spectral-communities-viz.csv')\n",
    "SPEC_COMMUNITIES_PICKLE = path.join(BASE_PATH, 'Spectral_Node_to_Community_dict.pickle')\n",
    "CNM_COMMUNITIES_PICKLE = path.join(BASE_PATH, 'CNM_Node_to_Community_dict.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modularity(G, community_dict):\n",
    "    two_M = G.GetEdges() * 2.0\n",
    "    mod_sum = 0.0\n",
    "    for NI in G.Nodes():\n",
    "        NI_id = NI.GetId()\n",
    "        for NJ in G.Nodes():\n",
    "            NJ_id = NJ.GetId()\n",
    "            if (community_dict[NI_id] == community_dict[NJ_id]):\n",
    "                mod_sum += G.IsEdge(NI_id, NJ_id) - ((NI.GetDeg() * NJ.GetDeg()) / two_M)\n",
    "    modularity = mod_sum / two_M\n",
    "    return modularity\n",
    "\n",
    "def load_top_ngram_df(topwords_path):\n",
    "    # Load csv containing the top words.\n",
    "    posts_df = pd.read_csv(topwords_path, sep = \"\\t\", usecols =\n",
    "                           [\"Id\", \"OwnerUserId\", \"TopWord1\", \"TopWord2\", \"TopWord3\", \"TopWord4\", \"TopWord5\"])\n",
    "\n",
    "    # Clean dataframe.\n",
    "    posts_df = posts_df.dropna()\n",
    "    posts_df = posts_df.rename(columns={\n",
    "            \"Id\": \"post_id\", \"OwnerUserId\": \"user_id\"})\n",
    "    posts_df[\"user_id\"] = posts_df[\"user_id\"].astype(np.int64)\n",
    "    posts_df[\"post_id\"] = posts_df[\"post_id\"].astype(np.int64)\n",
    "    posts_df = posts_df[posts_df[\"user_id\"] > 0]\n",
    "    posts_df = posts_df[posts_df[\"post_id\"] > 0]\n",
    "\n",
    "    return posts_df\n",
    "\n",
    "def add_communities_post_df(post_df, best_comm_map, postid_dict):\n",
    "    # Iterate over rows and add each community to each row.\n",
    "    community_array = []\n",
    "    for index, row in post_df.iterrows():\n",
    "        user_id = row[\"post_id\"]\n",
    "        A_id = postid_dict.get(user_id, -1)\n",
    "        if (A_id < 0):\n",
    "            community_array.append(-1)\n",
    "        else:\n",
    "            community_array.append(best_comm_map[A_id])\n",
    "    post_df.loc[:,'Community'] = community_array\n",
    "\n",
    "    return post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original nodes 19725\n",
      "edges 567729\n",
      "new nodes (no degree-0) 17139\n"
     ]
    }
   ],
   "source": [
    "f_in = snap.TFIn(FOLDED_POSTID_GRAPH_PATH)\n",
    "post_graph = snap.TUNGraph.Load(f_in)\n",
    "print \"original nodes\", post_graph.GetNodes()\n",
    "print \"edges\", post_graph.GetEdges()\n",
    "assert snap.CntSelfEdges(post_graph) == 0\n",
    "snap.DelZeroDegNodes(post_graph)\n",
    "print \"new nodes (no degree-0)\", post_graph.GetNodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modularity 0.441618294539\n"
     ]
    }
   ],
   "source": [
    "comm_vec = snap.TCnComV()\n",
    "modularity = snap.CommunityCNM(post_graph, comm_vec)\n",
    "\n",
    "print \"modularity\", modularity\n",
    "\n",
    "f_out = snap.TFOut(COMMUNITIES_VEC_PATH)\n",
    "comm_vec.Save(f_out)\n",
    "f_out.Flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "communities 66\n"
     ]
    }
   ],
   "source": [
    "f_in = snap.TFIn(COMMUNITIES_VEC_PATH)\n",
    "comm_vec = snap.TCnComV()\n",
    "comm_vec.Load(f_in)\n",
    "\n",
    "print \"communities\", len(comm_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open(POSTID_PICKLE, 'rb')\n",
    "postid_dict = pickle.load(pickle_file)\n",
    "\n",
    "community_dict = collections.defaultdict(int)\n",
    "\n",
    "with open(COMMUNITIES_PATH, 'w') as f:\n",
    "    for i, comm in enumerate(comm_vec):\n",
    "        f.write(\"#####Community {}#####\\n\".format(i))\n",
    "        community = snap.TIntV()\n",
    "        for node in comm:\n",
    "            community.Add(node)\n",
    "#             f.write(\"Node {}: {}\\n\".format(node, postid_dict[node]))\n",
    "            community_dict[node] = i\n",
    "        f.write('Community {}, nodes: {} modularity: {}\\n'.format(i, len(comm), snap.GetModularity(post_graph, community, post_graph.GetEdges())))\n",
    "    f.write(\"The modularity of the network is {}\\n\".format(modularity))\n",
    "    alt_modularity = get_modularity(post_graph, community_dict)\n",
    "    f.write(\"Alternate modularity of the network (sanity check) is {}\".format(alt_modularity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "postid_dict2 = collections.defaultdict(int)\n",
    "for node in community_dict:\n",
    "    postid_dict2[node] = node\n",
    "\n",
    "post_df = load_top_ngram_df(POST_TOP_NGRAM_PATH)\n",
    "post_df_w_comm = add_communities_post_df(post_df, community_dict, postid_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community: 0 Size: 4030\n",
      "Community: 1 Size: 2303\n",
      "Community: 2 Size: 24\n",
      "Community: 3 Size: 4711\n",
      "Community: 4 Size: 5343\n",
      "Community: 5 Size: 97\n",
      "Community: 6 Size: 4\n",
      "Community: 7 Size: 5\n",
      "Community: 8 Size: 159\n",
      "Community: 9 Size: 127\n",
      "Community: 10 Size: 2\n",
      "Community: 11 Size: 4\n",
      "Community: 12 Size: 9\n",
      "Community: 13 Size: 36\n",
      "Community: 14 Size: 4\n",
      "Community: 15 Size: 9\n",
      "Community: 16 Size: 2\n",
      "Community: 17 Size: 46\n",
      "Community: 18 Size: 3\n",
      "Community: 19 Size: 8\n",
      "Community: 20 Size: 2\n",
      "Community: 21 Size: 7\n",
      "Community: 22 Size: 55\n",
      "Community: 23 Size: 4\n",
      "Community: 24 Size: 4\n",
      "Community: 25 Size: 3\n",
      "Community: 26 Size: 4\n",
      "Community: 27 Size: 5\n",
      "Community: 28 Size: 10\n",
      "Community: 29 Size: 17\n",
      "Community: 30 Size: 4\n",
      "Community: 31 Size: 8\n",
      "Community: 32 Size: 12\n",
      "Community: 33 Size: 2\n",
      "Community: 34 Size: 2\n",
      "Community: 35 Size: 2\n",
      "Community: 36 Size: 4\n",
      "Community: 37 Size: 4\n",
      "Community: 38 Size: 2\n",
      "Community: 39 Size: 5\n",
      "Community: 40 Size: 2\n",
      "Community: 41 Size: 2\n",
      "Community: 42 Size: 3\n",
      "Community: 43 Size: 2\n",
      "Community: 44 Size: 2\n",
      "Community: 45 Size: 2\n",
      "Community: 46 Size: 2\n",
      "Community: 47 Size: 2\n",
      "Community: 48 Size: 5\n",
      "Community: 49 Size: 2\n",
      "Community: 50 Size: 2\n",
      "Community: 51 Size: 2\n",
      "Community: 52 Size: 2\n",
      "Community: 53 Size: 2\n",
      "Community: 54 Size: 2\n",
      "Community: 55 Size: 2\n",
      "Community: 56 Size: 2\n",
      "Community: 57 Size: 2\n",
      "Community: 58 Size: 2\n",
      "Community: 59 Size: 2\n",
      "Community: 60 Size: 2\n",
      "Community: 61 Size: 3\n",
      "Community: 62 Size: 2\n",
      "Community: 63 Size: 2\n",
      "Community: 64 Size: 2\n",
      "Community: 65 Size: 2\n",
      "Community: -1 Size: 2586\n"
     ]
    }
   ],
   "source": [
    "communities = set(post_df_w_comm[\"Community\"])\n",
    "for comm in communities:\n",
    "    print \"Community:\", comm, \"Size:\", len(post_df[post_df_w_comm[\"Community\"] == comm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "      <th>Community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>317812</td>\n",
       "      <td>140340</td>\n",
       "      <td>graphs</td>\n",
       "      <td>acyclic directed</td>\n",
       "      <td>art estimating</td>\n",
       "      <td>cycles current</td>\n",
       "      <td>described likely</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>318082</td>\n",
       "      <td>10278</td>\n",
       "      <td>architecture</td>\n",
       "      <td>reinforcement learning</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>learning</td>\n",
       "      <td>24x24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>318311</td>\n",
       "      <td>152805</td>\n",
       "      <td>ordinate</td>\n",
       "      <td>elbow</td>\n",
       "      <td>elbow point</td>\n",
       "      <td>drops</td>\n",
       "      <td>value ordinate</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>318423</td>\n",
       "      <td>46427</td>\n",
       "      <td>texts</td>\n",
       "      <td>author</td>\n",
       "      <td>learning</td>\n",
       "      <td>author texts</td>\n",
       "      <td>berger extremely</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>319061</td>\n",
       "      <td>83134</td>\n",
       "      <td>bus</td>\n",
       "      <td>observe process</td>\n",
       "      <td>having seen</td>\n",
       "      <td>long</td>\n",
       "      <td>minutes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>319130</td>\n",
       "      <td>119749</td>\n",
       "      <td>hardness</td>\n",
       "      <td>learning</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>deep</td>\n",
       "      <td>non informative</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>319532</td>\n",
       "      <td>17908</td>\n",
       "      <td>principled</td>\n",
       "      <td>science</td>\n",
       "      <td>learning</td>\n",
       "      <td>able technologies</td>\n",
       "      <td>build ships</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>319569</td>\n",
       "      <td>53690</td>\n",
       "      <td>optimizer</td>\n",
       "      <td>checking help</td>\n",
       "      <td>file function</td>\n",
       "      <td>help file</td>\n",
       "      <td>file</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>319581</td>\n",
       "      <td>30834</td>\n",
       "      <td>adam</td>\n",
       "      <td>optimizer</td>\n",
       "      <td>accuracies say</td>\n",
       "      <td>accuracy nearly</td>\n",
       "      <td>adam popular</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>319650</td>\n",
       "      <td>187209</td>\n",
       "      <td>graphs</td>\n",
       "      <td>asset</td>\n",
       "      <td>asset classes</td>\n",
       "      <td>having graphs</td>\n",
       "      <td>make report</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>320042</td>\n",
       "      <td>145911</td>\n",
       "      <td>file</td>\n",
       "      <td>creation</td>\n",
       "      <td>bins minutes</td>\n",
       "      <td>file creation</td>\n",
       "      <td>minutes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>320161</td>\n",
       "      <td>83900</td>\n",
       "      <td>fractal brownian</td>\n",
       "      <td>fractal</td>\n",
       "      <td>brownian motion</td>\n",
       "      <td>brownian</td>\n",
       "      <td>motion</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>320357</td>\n",
       "      <td>188759</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>multilayer</td>\n",
       "      <td>deep</td>\n",
       "      <td>learning</td>\n",
       "      <td>learning algorithm</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>320397</td>\n",
       "      <td>145911</td>\n",
       "      <td>minutes range</td>\n",
       "      <td>mm ss</td>\n",
       "      <td>hh mm</td>\n",
       "      <td>file</td>\n",
       "      <td>time stamp</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>320527</td>\n",
       "      <td>140995</td>\n",
       "      <td>step</td>\n",
       "      <td>model step</td>\n",
       "      <td>simplifications</td>\n",
       "      <td>meassure</td>\n",
       "      <td>obtained step</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>320824</td>\n",
       "      <td>113632</td>\n",
       "      <td>optimizer</td>\n",
       "      <td>advanced optimizer</td>\n",
       "      <td>animations training</td>\n",
       "      <td>cs231n free</td>\n",
       "      <td>data zoomed</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>321328</td>\n",
       "      <td>17760</td>\n",
       "      <td>called</td>\n",
       "      <td>learning</td>\n",
       "      <td>multivariate</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>machine</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>321378</td>\n",
       "      <td>136275</td>\n",
       "      <td>probability estimate</td>\n",
       "      <td>increasing</td>\n",
       "      <td>estimate increasing</td>\n",
       "      <td>difference increasing</td>\n",
       "      <td>increasing confidence</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>321476</td>\n",
       "      <td>26218</td>\n",
       "      <td>unique formula</td>\n",
       "      <td>formula</td>\n",
       "      <td>unique</td>\n",
       "      <td>learning</td>\n",
       "      <td>arrive right</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>321885</td>\n",
       "      <td>189356</td>\n",
       "      <td>20cabs</td>\n",
       "      <td>drive</td>\n",
       "      <td>minutes</td>\n",
       "      <td>20cabs drive</td>\n",
       "      <td>20cabs minutes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>321901</td>\n",
       "      <td>9964</td>\n",
       "      <td>free lunch</td>\n",
       "      <td>make assumptions</td>\n",
       "      <td>lunch</td>\n",
       "      <td>free</td>\n",
       "      <td>algorithm uniformly</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>321925</td>\n",
       "      <td>190684</td>\n",
       "      <td>conditioning choice</td>\n",
       "      <td>conditioning</td>\n",
       "      <td>best effects</td>\n",
       "      <td>choice brands</td>\n",
       "      <td>choice costumer</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>323220</td>\n",
       "      <td>191514</td>\n",
       "      <td>deep</td>\n",
       "      <td>theorems</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>learning</td>\n",
       "      <td>9ee1f7fb2808</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>323534</td>\n",
       "      <td>191023</td>\n",
       "      <td>learning</td>\n",
       "      <td>different supervised</td>\n",
       "      <td>doing mnist</td>\n",
       "      <td>https keon</td>\n",
       "      <td>keon</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>323548</td>\n",
       "      <td>67413</td>\n",
       "      <td>motion tracker</td>\n",
       "      <td>points second</td>\n",
       "      <td>tracker</td>\n",
       "      <td>motion</td>\n",
       "      <td>graphs</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>323596</td>\n",
       "      <td>191898</td>\n",
       "      <td>represents</td>\n",
       "      <td>probability drops</td>\n",
       "      <td>axis represents</td>\n",
       "      <td>drops</td>\n",
       "      <td>minutes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>323689</td>\n",
       "      <td>190818</td>\n",
       "      <td>overview</td>\n",
       "      <td>cobbled</td>\n",
       "      <td>cobbled following</td>\n",
       "      <td>couldn easily</td>\n",
       "      <td>easily nice</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>324119</td>\n",
       "      <td>179103</td>\n",
       "      <td>average deviations</td>\n",
       "      <td>estimate seasonal</td>\n",
       "      <td>deviations</td>\n",
       "      <td>seasonal component</td>\n",
       "      <td>second step</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>324142</td>\n",
       "      <td>192252</td>\n",
       "      <td>highest</td>\n",
       "      <td>best</td>\n",
       "      <td>predictors chosen</td>\n",
       "      <td>best predictors</td>\n",
       "      <td>pick highest</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>324273</td>\n",
       "      <td>177099</td>\n",
       "      <td>increse</td>\n",
       "      <td>max steps</td>\n",
       "      <td>learning</td>\n",
       "      <td>batch size</td>\n",
       "      <td>rate</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15945</th>\n",
       "      <td>339304</td>\n",
       "      <td>7224</td>\n",
       "      <td>bijective</td>\n",
       "      <td>conditioning</td>\n",
       "      <td>bijective measurable</td>\n",
       "      <td>bijective transform</td>\n",
       "      <td>conditioning bijective</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16196</th>\n",
       "      <td>339631</td>\n",
       "      <td>183283</td>\n",
       "      <td>line sin</td>\n",
       "      <td>tracking problem</td>\n",
       "      <td>sin function</td>\n",
       "      <td>tracks</td>\n",
       "      <td>tracking</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16490</th>\n",
       "      <td>340011</td>\n",
       "      <td>102265</td>\n",
       "      <td>votes counted</td>\n",
       "      <td>votes</td>\n",
       "      <td>counted minutes</td>\n",
       "      <td>counted</td>\n",
       "      <td>minutes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16528</th>\n",
       "      <td>340061</td>\n",
       "      <td>204</td>\n",
       "      <td>directory</td>\n",
       "      <td>file</td>\n",
       "      <td>directories number</td>\n",
       "      <td>child directories</td>\n",
       "      <td>file naming</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16994</th>\n",
       "      <td>340660</td>\n",
       "      <td>203151</td>\n",
       "      <td>learning</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>statistical machine</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning statistical</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17068</th>\n",
       "      <td>340761</td>\n",
       "      <td>127096</td>\n",
       "      <td>reinforcement learning</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>learning</td>\n",
       "      <td>application gradient</td>\n",
       "      <td>books ve</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17126</th>\n",
       "      <td>340841</td>\n",
       "      <td>199108</td>\n",
       "      <td>decay</td>\n",
       "      <td>grid scan</td>\n",
       "      <td>high node</td>\n",
       "      <td>node count</td>\n",
       "      <td>decay value</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17145</th>\n",
       "      <td>340866</td>\n",
       "      <td>132651</td>\n",
       "      <td>offline learning</td>\n",
       "      <td>learning</td>\n",
       "      <td>offline</td>\n",
       "      <td>online</td>\n",
       "      <td>discussed online</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17267</th>\n",
       "      <td>341027</td>\n",
       "      <td>176238</td>\n",
       "      <td>delayed rewards</td>\n",
       "      <td>sparse delayed</td>\n",
       "      <td>eligibility traces</td>\n",
       "      <td>delayed</td>\n",
       "      <td>eligibility</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17386</th>\n",
       "      <td>341177</td>\n",
       "      <td>199063</td>\n",
       "      <td>best science</td>\n",
       "      <td>produce best</td>\n",
       "      <td>science</td>\n",
       "      <td>best</td>\n",
       "      <td>answer rqs</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>341231</td>\n",
       "      <td>162527</td>\n",
       "      <td>adam</td>\n",
       "      <td>adam used</td>\n",
       "      <td>choice adam</td>\n",
       "      <td>history choice</td>\n",
       "      <td>adam method</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17476</th>\n",
       "      <td>341303</td>\n",
       "      <td>196323</td>\n",
       "      <td>apart</td>\n",
       "      <td>increasing</td>\n",
       "      <td>apart point</td>\n",
       "      <td>attributes shown</td>\n",
       "      <td>binned bins</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17573</th>\n",
       "      <td>341434</td>\n",
       "      <td>173082</td>\n",
       "      <td>regret</td>\n",
       "      <td>regret theory</td>\n",
       "      <td>hindsight knowledge</td>\n",
       "      <td>hindsight</td>\n",
       "      <td>theory</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17596</th>\n",
       "      <td>341467</td>\n",
       "      <td>121522</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning</td>\n",
       "      <td>ensemble machine</td>\n",
       "      <td>meta ensemble</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17739</th>\n",
       "      <td>341645</td>\n",
       "      <td>27765</td>\n",
       "      <td>learning rate</td>\n",
       "      <td>rate</td>\n",
       "      <td>learning</td>\n",
       "      <td>adaptive learning</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867</th>\n",
       "      <td>341817</td>\n",
       "      <td>98219</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning</td>\n",
       "      <td>learned</td>\n",
       "      <td>accuracy overly</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17981</th>\n",
       "      <td>341959</td>\n",
       "      <td>80635</td>\n",
       "      <td>update formula</td>\n",
       "      <td>learning</td>\n",
       "      <td>representation state</td>\n",
       "      <td>formula learning</td>\n",
       "      <td>difference learning</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299</th>\n",
       "      <td>342392</td>\n",
       "      <td>20980</td>\n",
       "      <td>step ahead</td>\n",
       "      <td>ahead model</td>\n",
       "      <td>ahead</td>\n",
       "      <td>step</td>\n",
       "      <td>perspective</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18396</th>\n",
       "      <td>342534</td>\n",
       "      <td>205752</td>\n",
       "      <td>adam</td>\n",
       "      <td>abs information</td>\n",
       "      <td>adam generalize</td>\n",
       "      <td>adam requires</td>\n",
       "      <td>aren definitive</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18577</th>\n",
       "      <td>342771</td>\n",
       "      <td>28666</td>\n",
       "      <td>adam</td>\n",
       "      <td>diederik</td>\n",
       "      <td>diederik kingma</td>\n",
       "      <td>jimmy</td>\n",
       "      <td>jimmy lei</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18676</th>\n",
       "      <td>342898</td>\n",
       "      <td>205280</td>\n",
       "      <td>graphs</td>\n",
       "      <td>conclusion</td>\n",
       "      <td>basically studying</td>\n",
       "      <td>conclusion graphs</td>\n",
       "      <td>decomposition graphs</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18806</th>\n",
       "      <td>343053</td>\n",
       "      <td>116440</td>\n",
       "      <td>suppose depend</td>\n",
       "      <td>necessarily independent</td>\n",
       "      <td>independent example</td>\n",
       "      <td>example suppose</td>\n",
       "      <td>necessarily</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18962</th>\n",
       "      <td>343250</td>\n",
       "      <td>163648</td>\n",
       "      <td>referrals</td>\n",
       "      <td>rate referrals</td>\n",
       "      <td>hlm</td>\n",
       "      <td>discipline</td>\n",
       "      <td>rate</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19121</th>\n",
       "      <td>343441</td>\n",
       "      <td>138575</td>\n",
       "      <td>learning</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>machine</td>\n",
       "      <td>attend tell</td>\n",
       "      <td>tell paper</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19133</th>\n",
       "      <td>343454</td>\n",
       "      <td>9964</td>\n",
       "      <td>theory</td>\n",
       "      <td>learning theory</td>\n",
       "      <td>book</td>\n",
       "      <td>learning</td>\n",
       "      <td>freely available</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19223</th>\n",
       "      <td>343569</td>\n",
       "      <td>68444</td>\n",
       "      <td>hastie</td>\n",
       "      <td>learning</td>\n",
       "      <td>free</td>\n",
       "      <td>addition elements</td>\n",
       "      <td>agreement author</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>343686</td>\n",
       "      <td>141297</td>\n",
       "      <td>best approach</td>\n",
       "      <td>best</td>\n",
       "      <td>came figured</td>\n",
       "      <td>cons decide</td>\n",
       "      <td>counterpart like</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19495</th>\n",
       "      <td>343935</td>\n",
       "      <td>195935</td>\n",
       "      <td>fuel</td>\n",
       "      <td>mpg</td>\n",
       "      <td>average mpg</td>\n",
       "      <td>distance travel</td>\n",
       "      <td>minutes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19583</th>\n",
       "      <td>344053</td>\n",
       "      <td>67137</td>\n",
       "      <td>pb</td>\n",
       "      <td>vs level</td>\n",
       "      <td>effect pb</td>\n",
       "      <td>pb level</td>\n",
       "      <td>pa pb</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>344595</td>\n",
       "      <td>230</td>\n",
       "      <td>example unsupervised</td>\n",
       "      <td>unsupervised learning</td>\n",
       "      <td>simple example</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>learning</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  user_id                TopWord1                 TopWord2  \\\n",
       "86      317812   140340                  graphs         acyclic directed   \n",
       "307     318082    10278            architecture   reinforcement learning   \n",
       "474     318311   152805                ordinate                    elbow   \n",
       "564     318423    46427                   texts                   author   \n",
       "1064    319061    83134                     bus          observe process   \n",
       "1120    319130   119749                hardness                 learning   \n",
       "1422    319532    17908              principled                  science   \n",
       "1453    319569    53690               optimizer            checking help   \n",
       "1463    319581    30834                    adam                optimizer   \n",
       "1514    319650   187209                  graphs                    asset   \n",
       "1825    320042   145911                    file                 creation   \n",
       "1913    320161    83900        fractal brownian                  fractal   \n",
       "2058    320357   188759           deep learning               multilayer   \n",
       "2083    320397   145911           minutes range                    mm ss   \n",
       "2189    320527   140995                    step               model step   \n",
       "2424    320824   113632               optimizer       advanced optimizer   \n",
       "2817    321328    17760                  called                 learning   \n",
       "2858    321378   136275    probability estimate               increasing   \n",
       "2934    321476    26218          unique formula                  formula   \n",
       "3251    321885   189356                  20cabs                    drive   \n",
       "3266    321901     9964              free lunch         make assumptions   \n",
       "3288    321925   190684     conditioning choice             conditioning   \n",
       "4280    323220   191514                    deep                 theorems   \n",
       "4536    323534   191023                learning     different supervised   \n",
       "4544    323548    67413          motion tracker            points second   \n",
       "4583    323596   191898              represents        probability drops   \n",
       "4662    323689   190818                overview                  cobbled   \n",
       "4993    324119   179103      average deviations        estimate seasonal   \n",
       "5013    324142   192252                 highest                     best   \n",
       "5111    324273   177099                 increse                max steps   \n",
       "...        ...      ...                     ...                      ...   \n",
       "15945   339304     7224               bijective             conditioning   \n",
       "16196   339631   183283                line sin         tracking problem   \n",
       "16490   340011   102265           votes counted                    votes   \n",
       "16528   340061      204               directory                     file   \n",
       "16994   340660   203151                learning         machine learning   \n",
       "17068   340761   127096  reinforcement learning            reinforcement   \n",
       "17126   340841   199108                   decay                grid scan   \n",
       "17145   340866   132651        offline learning                 learning   \n",
       "17267   341027   176238         delayed rewards           sparse delayed   \n",
       "17386   341177   199063            best science             produce best   \n",
       "17419   341231   162527                    adam                adam used   \n",
       "17476   341303   196323                   apart               increasing   \n",
       "17573   341434   173082                  regret            regret theory   \n",
       "17596   341467   121522        machine learning                  machine   \n",
       "17739   341645    27765           learning rate                     rate   \n",
       "17867   341817    98219        machine learning                  machine   \n",
       "17981   341959    80635          update formula                 learning   \n",
       "18299   342392    20980              step ahead              ahead model   \n",
       "18396   342534   205752                    adam          abs information   \n",
       "18577   342771    28666                    adam                 diederik   \n",
       "18676   342898   205280                  graphs               conclusion   \n",
       "18806   343053   116440          suppose depend  necessarily independent   \n",
       "18962   343250   163648               referrals           rate referrals   \n",
       "19121   343441   138575                learning         machine learning   \n",
       "19133   343454     9964                  theory          learning theory   \n",
       "19223   343569    68444                  hastie                 learning   \n",
       "19313   343686   141297           best approach                     best   \n",
       "19495   343935   195935                    fuel                      mpg   \n",
       "19583   344053    67137                      pb                 vs level   \n",
       "19986   344595      230    example unsupervised    unsupervised learning   \n",
       "\n",
       "                   TopWord3               TopWord4                TopWord5  \\\n",
       "86           art estimating         cycles current        described likely   \n",
       "307           reinforcement               learning                   24x24   \n",
       "474             elbow point                  drops          value ordinate   \n",
       "564                learning           author texts        berger extremely   \n",
       "1064            having seen                   long                 minutes   \n",
       "1120          deep learning                   deep         non informative   \n",
       "1422               learning      able technologies             build ships   \n",
       "1453          file function              help file                    file   \n",
       "1463         accuracies say        accuracy nearly            adam popular   \n",
       "1514          asset classes          having graphs             make report   \n",
       "1825           bins minutes          file creation                 minutes   \n",
       "1913        brownian motion               brownian                  motion   \n",
       "2058                   deep               learning      learning algorithm   \n",
       "2083                  hh mm                   file              time stamp   \n",
       "2189        simplifications               meassure           obtained step   \n",
       "2424    animations training            cs231n free             data zoomed   \n",
       "2817           multivariate       machine learning                 machine   \n",
       "2858    estimate increasing  difference increasing   increasing confidence   \n",
       "2934                 unique               learning            arrive right   \n",
       "3251                minutes           20cabs drive          20cabs minutes   \n",
       "3266                  lunch                   free     algorithm uniformly   \n",
       "3288           best effects          choice brands         choice costumer   \n",
       "4280          deep learning               learning            9ee1f7fb2808   \n",
       "4536            doing mnist             https keon                    keon   \n",
       "4544                tracker                 motion                  graphs   \n",
       "4583        axis represents                  drops                 minutes   \n",
       "4662      cobbled following          couldn easily             easily nice   \n",
       "4993             deviations     seasonal component             second step   \n",
       "5013      predictors chosen        best predictors            pick highest   \n",
       "5111               learning             batch size                    rate   \n",
       "...                     ...                    ...                     ...   \n",
       "15945  bijective measurable    bijective transform  conditioning bijective   \n",
       "16196          sin function                 tracks                tracking   \n",
       "16490       counted minutes                counted                 minutes   \n",
       "16528    directories number      child directories             file naming   \n",
       "16994   statistical machine                machine    learning statistical   \n",
       "17068              learning   application gradient                books ve   \n",
       "17126             high node             node count             decay value   \n",
       "17145               offline                 online        discussed online   \n",
       "17267    eligibility traces                delayed             eligibility   \n",
       "17386               science                   best              answer rqs   \n",
       "17419           choice adam         history choice             adam method   \n",
       "17476           apart point       attributes shown             binned bins   \n",
       "17573   hindsight knowledge              hindsight                  theory   \n",
       "17596              learning       ensemble machine           meta ensemble   \n",
       "17739              learning      adaptive learning                adaptive   \n",
       "17867              learning                learned         accuracy overly   \n",
       "17981  representation state       formula learning     difference learning   \n",
       "18299                 ahead                   step             perspective   \n",
       "18396       adam generalize          adam requires         aren definitive   \n",
       "18577       diederik kingma                  jimmy               jimmy lei   \n",
       "18676    basically studying      conclusion graphs    decomposition graphs   \n",
       "18806   independent example        example suppose             necessarily   \n",
       "18962                   hlm             discipline                    rate   \n",
       "19121               machine            attend tell              tell paper   \n",
       "19133                  book               learning        freely available   \n",
       "19223                  free      addition elements        agreement author   \n",
       "19313          came figured            cons decide        counterpart like   \n",
       "19495           average mpg        distance travel                 minutes   \n",
       "19583             effect pb               pb level                   pa pb   \n",
       "19986        simple example           unsupervised                learning   \n",
       "\n",
       "       Community  \n",
       "86             9  \n",
       "307            9  \n",
       "474            9  \n",
       "564            9  \n",
       "1064           9  \n",
       "1120           9  \n",
       "1422           9  \n",
       "1453           9  \n",
       "1463           9  \n",
       "1514           9  \n",
       "1825           9  \n",
       "1913           9  \n",
       "2058           9  \n",
       "2083           9  \n",
       "2189           9  \n",
       "2424           9  \n",
       "2817           9  \n",
       "2858           9  \n",
       "2934           9  \n",
       "3251           9  \n",
       "3266           9  \n",
       "3288           9  \n",
       "4280           9  \n",
       "4536           9  \n",
       "4544           9  \n",
       "4583           9  \n",
       "4662           9  \n",
       "4993           9  \n",
       "5013           9  \n",
       "5111           9  \n",
       "...          ...  \n",
       "15945          9  \n",
       "16196          9  \n",
       "16490          9  \n",
       "16528          9  \n",
       "16994          9  \n",
       "17068          9  \n",
       "17126          9  \n",
       "17145          9  \n",
       "17267          9  \n",
       "17386          9  \n",
       "17419          9  \n",
       "17476          9  \n",
       "17573          9  \n",
       "17596          9  \n",
       "17739          9  \n",
       "17867          9  \n",
       "17981          9  \n",
       "18299          9  \n",
       "18396          9  \n",
       "18577          9  \n",
       "18676          9  \n",
       "18806          9  \n",
       "18962          9  \n",
       "19121          9  \n",
       "19133          9  \n",
       "19223          9  \n",
       "19313          9  \n",
       "19495          9  \n",
       "19583          9  \n",
       "19986          9  \n",
       "\n",
       "[127 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df[post_df_w_comm[\"Community\"] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap.SaveEdgeList(post_graph, EDGELIST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word frequency in communities\n",
    "word_counts = collections.defaultdict(dict)\n",
    "word_freqs = collections.defaultdict(dict)\n",
    "for comm in communities:\n",
    "    total_words = 0.0\n",
    "    word_counts[comm] = collections.defaultdict(int)\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord1']:\n",
    "        word_counts[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord2']:\n",
    "        word_counts[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord3']:\n",
    "        word_counts[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord4']:\n",
    "        word_counts[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord5']:\n",
    "        word_counts[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in word_counts[comm]:\n",
    "        word_freqs[comm][word] = word_counts[comm][word] / total_words\n",
    "   \n",
    "sorted_word_freqs = collections.defaultdict(dict)\n",
    "for comm in word_freqs:\n",
    "    sorted_word_freqs[comm] = sorted(word_freqs[comm].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "COMM_TERMS = 9\n",
    "y_pos = []\n",
    "x_labels = []\n",
    "for word in sorted_word_freqs[COMM_TERMS][:10]:\n",
    "    y_pos.append(word[1])\n",
    "    x_labels.append(word[0])\n",
    "    \n",
    "plt.bar(x_labels, y_pos)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word frequency in communities\n",
    "word_counts = collections.defaultdict(dict)\n",
    "word_freqs = collections.defaultdict(dict)\n",
    "for comm in communities:\n",
    "    total_rows = 0.0\n",
    "    word_counts[comm] = collections.defaultdict(int)\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord1']:\n",
    "        word_counts[comm][word] += 1\n",
    "        total_rows += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord2']:\n",
    "        word_counts[comm][word] += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord3']:\n",
    "        word_counts[comm][word] += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord4']:\n",
    "        word_counts[comm][word] += 1\n",
    "    for word in post_df_w_comm[post_df_w_comm[\"Community\"] == comm]['TopWord5']:\n",
    "        word_counts[comm][word] += 1\n",
    "    for word in word_counts[comm]:\n",
    "        word_freqs[comm][word] = word_counts[comm][word] / total_rows\n",
    "        \n",
    "sorted_word_freqs = collections.defaultdict(dict)\n",
    "for comm in word_freqs:\n",
    "    sorted_word_freqs[comm] = sorted(word_freqs[comm].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "COMM_TERMS = 9\n",
    "y_pos = []\n",
    "x_labels = []\n",
    "for word in sorted_word_freqs[COMM_TERMS][:10]:\n",
    "    y_pos.append(word[1])\n",
    "    x_labels.append(word[0])\n",
    "    \n",
    "plt.bar(x_labels, y_pos)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Proportion of posts\")\n",
    "plt.title(\"CNM community 'learning|rate|minutes'\")\n",
    "plt.suptitle('Proportion of posts for which a specific term is \"important\"')\n",
    "plt.savefig('cnm_proportion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 5343, 27.08745247148289, 'series|time|group'),\n",
       " (3, 4711, 23.88339670468948, 'test|training|validation'),\n",
       " (0, 4030, 20.430925221799747, 'distribution|sample|probability'),\n",
       " (1, 2303, 11.67553865652725, 'matrix|model|variables'),\n",
       " (8, 159, 0.8060836501901141, 'size|power|uncertainty'),\n",
       " (9, 127, 0.6438529784537389, 'learning|rate|minutes'),\n",
       " (5, 97, 0.4917617237008872, 'outliers|bias|percentile'),\n",
       " (22, 55, 0.2788339670468948, 'lt|gt|gt gt'),\n",
       " (17, 46, 0.2332065906210393, 'inequality|code|money'),\n",
       " (13, 36, 0.18250950570342206, 'sensitivity|specificity|cut'),\n",
       " (2, 24, 0.12167300380228137, 'pattern|sklearn|truck'),\n",
       " (29, 17, 0.08618504435994931, 'table|holt winters|winters'),\n",
       " (32, 12, 0.060836501901140684, 'question|invertible|dgp'),\n",
       " (28, 10, 0.050697084917617236, 'near|plm|popularity'),\n",
       " (12, 9, 0.045627376425855515, 'count data|count|data time'),\n",
       " (15, 9, 0.045627376425855515, 'concentration|flow|water'),\n",
       " (19, 8, 0.04055766793409379, 'populations|performing|phenotype'),\n",
       " (31, 8, 0.04055766793409379, 'dynamic|time warping|estimate model'),\n",
       " (21, 7, 0.035487959442332066, 'result|good|flows'),\n",
       " (7, 5, 0.025348542458808618, 'nest|materials|common materials'),\n",
       " (27, 5, 0.025348542458808618, 'wilcox|wilcox test|sums version'),\n",
       " (39, 5, 0.025348542458808618, 'https github|github com|com'),\n",
       " (48, 5, 0.025348542458808618, 'fdr|produced|scale inference'),\n",
       " (6, 4, 0.020278833967046894, 'et|al|et al'),\n",
       " (11, 4, 0.020278833967046894, 'cars|amounts cars|meet conditions'),\n",
       " (14, 4, 0.020278833967046894, 'hypertension|calcium|assay'),\n",
       " (23, 4, 0.020278833967046894, 'metropolis|rcpp|loops'),\n",
       " (24, 4, 0.020278833967046894, 'birds|work|distances'),\n",
       " (26, 4, 0.020278833967046894, 'dickey fuller|fuller|dickey'),\n",
       " (30, 4, 0.020278833967046894, 'beta3|beta2|decaying'),\n",
       " (36, 4, 0.020278833967046894, 'orange|vitamin|linux'),\n",
       " (37, 4, 0.020278833967046894, 'containing|case txs|answers advance'),\n",
       " (18, 3, 0.015209125475285171, 'payment|booking|booking cancelled'),\n",
       " (25, 3, 0.015209125475285171, 'let let|correct answers|let number'),\n",
       " (42, 3, 0.015209125475285171, 'names|applicants|adjusted icc'),\n",
       " (61, 3, 0.015209125475285171, 'quotes|query|sql server'),\n",
       " (10, 2, 0.010139416983523447, 'rmsep|lowest rmsep|command validation'),\n",
       " (16, 2, 0.010139416983523447, 'map2|change map2|argument change'),\n",
       " (20, 2, 0.010139416983523447, 'attention|attention based|using attention'),\n",
       " (33, 2, 0.010139416983523447, 'advice|functions image|variance group'),\n",
       " (34,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'structure coefficients|corville|additionally sure'),\n",
       " (35, 2, 0.010139416983523447, 'geo|thrown getting|coin thrown'),\n",
       " (38, 2, 0.010139416983523447, 'donors|lapsed|frequency donations'),\n",
       " (40,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'distributed random|having exponential|convergeges'),\n",
       " (41, 2, 0.010139416983523447, 'armax|actually end|armax model'),\n",
       " (43, 2, 0.010139416983523447, 'stuck|suppose hypotheses|able stuck'),\n",
       " (44, 2, 0.010139416983523447, 'tso|lets nn1|tso function'),\n",
       " (45,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'covariance variable|equivalent variance|equals variance'),\n",
       " (46, 2, 0.010139416983523447, 'independent measures|anova scores|violating'),\n",
       " (47, 2, 0.010139416983523447, 'factor1|factor2|according factor2'),\n",
       " (49, 2, 0.010139416983523447, 'explain does|estimation come|does maximum'),\n",
       " (50,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'tests sampling|assumptions large|assumptions amp'),\n",
       " (51,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'samples groups|error anova|groups similarities'),\n",
       " (52,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'consultation|care treatment|bothering consult'),\n",
       " (53, 2, 0.010139416983523447, 'km curve|mean km|correct job'),\n",
       " (54, 2, 0.010139416983523447, 'berry esseen|berry|esseen'),\n",
       " (55,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'convolution quite|quite nicely|nicely different'),\n",
       " (56, 2, 0.010139416983523447, 'ed|distributions ed|budgetary'),\n",
       " (57, 2, 0.010139416983523447, 'wondering value|know place|place firstly'),\n",
       " (58,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'using boruta|meaning interpret|correctly feature'),\n",
       " (59,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'random component|component actually|complex stochastic'),\n",
       " (60, 2, 0.010139416983523447, 'group comparison|trt2|comparison procedure'),\n",
       " (62,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'coefficient simple|work difference|coefficients refer'),\n",
       " (63, 2, 0.010139416983523447, 'grain|mineral|assume grain'),\n",
       " (64, 2, 0.010139416983523447, 'filtering|filtering step|arrays'),\n",
       " (65, 2, 0.010139416983523447, 'unclear vague|scope use|tags instead')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_freqs = collections.defaultdict(dict)\n",
    "for comm in word_freqs:\n",
    "    sorted_word_freqs[comm] = sorted(word_freqs[comm].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "community_labels = collections.defaultdict(str) \n",
    "\n",
    "for ind, comm in enumerate(sorted_word_freqs):\n",
    "    community_labels[comm] = \"{}|{}|{}\".format(sorted_word_freqs[comm][0][0], sorted_word_freqs[comm][1][0], sorted_word_freqs[comm][2][0])\n",
    "\n",
    "rankings = []\n",
    "\n",
    "for comm in communities:\n",
    "    if comm == -1: continue\n",
    "#     print \"Community: {:3}  Size: {:5}  Proportion: {:.8f}  Label: {}\".format(comm, len(post_df[post_df_w_comm[\"Community\"] == comm]), len(post_df[post_df_w_comm[\"Community\"] == comm]) / float(len(post_df)), community_labels[comm])\n",
    "    rankings.append((comm, len(post_df[post_df_w_comm[\"Community\"] == comm]), 100.0 * len(post_df[post_df_w_comm[\"Community\"] == comm]) / len(post_df), community_labels[comm]))\n",
    "    \n",
    "rankings.sort(key=lambda x: x[2], reverse = True)\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots\n",
    "\n",
    "y_pos = []\n",
    "x_labels = []\n",
    "for comm in communities:\n",
    "    if comm == -1: continue\n",
    "    y_pos.append(len(post_df[post_df_w_comm[\"Community\"] == comm]))\n",
    "#     x_labels.append(\"{}: {}\".format(comm, community_labels[comm]))\n",
    "    x_labels.append(community_labels[comm])\n",
    "\n",
    "y_pos, x_labels = zip(*sorted(zip(y_pos, x_labels), reverse=True))\n",
    "\n",
    "plt.plot(y_pos)\n",
    "plt.title(\"Size of communities generated by CNM\")\n",
    "plt.ylabel(\"Number of nodes\")\n",
    "plt.yscale('log')\n",
    "plt.ylim((1,10000))\n",
    "plt.xlabel(\"Community number\")\n",
    "plt.savefig('cnm_community_size.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "      <th>Community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317697</td>\n",
       "      <td>134975</td>\n",
       "      <td>variables statistically</td>\n",
       "      <td>mixed effect</td>\n",
       "      <td>mixed</td>\n",
       "      <td>variables</td>\n",
       "      <td>statistically significant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317699</td>\n",
       "      <td>45374</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>validation accuracy</td>\n",
       "      <td>training accuracy</td>\n",
       "      <td>shallow</td>\n",
       "      <td>validation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317701</td>\n",
       "      <td>171235</td>\n",
       "      <td>freedom</td>\n",
       "      <td>mean</td>\n",
       "      <td>degrees freedom</td>\n",
       "      <td>degrees</td>\n",
       "      <td>data degree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317703</td>\n",
       "      <td>187797</td>\n",
       "      <td>patients</td>\n",
       "      <td>treating</td>\n",
       "      <td>excel</td>\n",
       "      <td>treat</td>\n",
       "      <td>bias treating</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317704</td>\n",
       "      <td>61496</td>\n",
       "      <td>uncertainty</td>\n",
       "      <td>error ways</td>\n",
       "      <td>estimate realistic</td>\n",
       "      <td>forecast method</td>\n",
       "      <td>predicts time</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>317705</td>\n",
       "      <td>134369</td>\n",
       "      <td>bonferroni correction</td>\n",
       "      <td>bonferroni</td>\n",
       "      <td>correction</td>\n",
       "      <td>outliers</td>\n",
       "      <td>don understand</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>317707</td>\n",
       "      <td>187792</td>\n",
       "      <td>environmental variables</td>\n",
       "      <td>traits</td>\n",
       "      <td>environmental</td>\n",
       "      <td>plant traits</td>\n",
       "      <td>plant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>317708</td>\n",
       "      <td>82816</td>\n",
       "      <td>solve differential</td>\n",
       "      <td>equation distribution</td>\n",
       "      <td>differential equation</td>\n",
       "      <td>need solve</td>\n",
       "      <td>distribution pdf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>317710</td>\n",
       "      <td>61092</td>\n",
       "      <td>monotonically increasing</td>\n",
       "      <td>monotonically</td>\n",
       "      <td>differentiable</td>\n",
       "      <td>increasing</td>\n",
       "      <td>assuming differentiable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>317711</td>\n",
       "      <td>179343</td>\n",
       "      <td>affect specified</td>\n",
       "      <td>shock affect</td>\n",
       "      <td>understand shock</td>\n",
       "      <td>prof</td>\n",
       "      <td>shock</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>317712</td>\n",
       "      <td>67137</td>\n",
       "      <td>simr</td>\n",
       "      <td>able edit</td>\n",
       "      <td>deciding sample</td>\n",
       "      <td>edit turns</td>\n",
       "      <td>effect variety</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>317713</td>\n",
       "      <td>67137</td>\n",
       "      <td>measures construct</td>\n",
       "      <td>power</td>\n",
       "      <td>measures</td>\n",
       "      <td>outcome measures</td>\n",
       "      <td>multivariate regression</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>317716</td>\n",
       "      <td>187803</td>\n",
       "      <td>terms applications</td>\n",
       "      <td>difference poisson</td>\n",
       "      <td>process terms</td>\n",
       "      <td>process markov</td>\n",
       "      <td>markov process</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>317717</td>\n",
       "      <td>113090</td>\n",
       "      <td>graphical</td>\n",
       "      <td>graphical models</td>\n",
       "      <td>log linear</td>\n",
       "      <td>models</td>\n",
       "      <td>log</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>317718</td>\n",
       "      <td>80922</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>deep recurrent</td>\n",
       "      <td>neural network</td>\n",
       "      <td>recurrent neural</td>\n",
       "      <td>neural</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>317719</td>\n",
       "      <td>187804</td>\n",
       "      <td>person</td>\n",
       "      <td>young old</td>\n",
       "      <td>young</td>\n",
       "      <td>old</td>\n",
       "      <td>age indicator</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>317721</td>\n",
       "      <td>177228</td>\n",
       "      <td>intervention</td>\n",
       "      <td>male respondents</td>\n",
       "      <td>intervention time</td>\n",
       "      <td>respondents</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>317722</td>\n",
       "      <td>187806</td>\n",
       "      <td>fans</td>\n",
       "      <td>band</td>\n",
       "      <td>universe</td>\n",
       "      <td>overall universe</td>\n",
       "      <td>cities</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>317723</td>\n",
       "      <td>8123</td>\n",
       "      <td>distinguishes legged</td>\n",
       "      <td>legged</td>\n",
       "      <td>old style</td>\n",
       "      <td>seek opinions</td>\n",
       "      <td>recognition</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>317724</td>\n",
       "      <td>117168</td>\n",
       "      <td>block</td>\n",
       "      <td>resampling</td>\n",
       "      <td>series</td>\n",
       "      <td>blocks</td>\n",
       "      <td>resample</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>317725</td>\n",
       "      <td>185581</td>\n",
       "      <td>rows small</td>\n",
       "      <td>corresponding rows</td>\n",
       "      <td>constraint</td>\n",
       "      <td>matrix shape</td>\n",
       "      <td>row</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>317727</td>\n",
       "      <td>117168</td>\n",
       "      <td>block</td>\n",
       "      <td>blocks</td>\n",
       "      <td>block observation</td>\n",
       "      <td>resample</td>\n",
       "      <td>fourth block</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>317728</td>\n",
       "      <td>187809</td>\n",
       "      <td>subscribe</td>\n",
       "      <td>mining</td>\n",
       "      <td>brief ideally</td>\n",
       "      <td>customer subscribe</td>\n",
       "      <td>incorporate mining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>317729</td>\n",
       "      <td>31484</td>\n",
       "      <td>beta distribution</td>\n",
       "      <td>beta</td>\n",
       "      <td>distribution prove</td>\n",
       "      <td>look beta</td>\n",
       "      <td>prove beta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>317730</td>\n",
       "      <td>111479</td>\n",
       "      <td>eigenvector</td>\n",
       "      <td>grey</td>\n",
       "      <td>components</td>\n",
       "      <td>eigenvalue</td>\n",
       "      <td>variables</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>317731</td>\n",
       "      <td>805</td>\n",
       "      <td>beta</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>symmetric beta</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>beta gaussian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>317732</td>\n",
       "      <td>88727</td>\n",
       "      <td>signal</td>\n",
       "      <td>bound</td>\n",
       "      <td>bound saturated</td>\n",
       "      <td>channel variance</td>\n",
       "      <td>deriving relationships</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>317733</td>\n",
       "      <td>131977</td>\n",
       "      <td>don understand</td>\n",
       "      <td>architecture explaining</td>\n",
       "      <td>concatenate inputs</td>\n",
       "      <td>deep mind</td>\n",
       "      <td>explaining works</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>317734</td>\n",
       "      <td>187810</td>\n",
       "      <td>intervention</td>\n",
       "      <td>signal</td>\n",
       "      <td>events</td>\n",
       "      <td>external events</td>\n",
       "      <td>external</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>317735</td>\n",
       "      <td>8402</td>\n",
       "      <td>denote noncentral</td>\n",
       "      <td>derived theory</td>\n",
       "      <td>don proof</td>\n",
       "      <td>ingersoll ros</td>\n",
       "      <td>proof prove</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>344573</td>\n",
       "      <td>94586</td>\n",
       "      <td>tree species</td>\n",
       "      <td>species</td>\n",
       "      <td>tree</td>\n",
       "      <td>crown</td>\n",
       "      <td>lidar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>344574</td>\n",
       "      <td>105149</td>\n",
       "      <td>college</td>\n",
       "      <td>college highschool</td>\n",
       "      <td>highschool</td>\n",
       "      <td>student answer</td>\n",
       "      <td>correctly question</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>344575</td>\n",
       "      <td>136275</td>\n",
       "      <td>mean</td>\n",
       "      <td>use mean</td>\n",
       "      <td>test set</td>\n",
       "      <td>test</td>\n",
       "      <td>mean test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>344578</td>\n",
       "      <td>163648</td>\n",
       "      <td>number correct</td>\n",
       "      <td>correct answers</td>\n",
       "      <td>let number</td>\n",
       "      <td>high school</td>\n",
       "      <td>let let</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>344579</td>\n",
       "      <td>207112</td>\n",
       "      <td>equal equal</td>\n",
       "      <td>distribution variable</td>\n",
       "      <td>function parameters</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>parameters</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>344580</td>\n",
       "      <td>195935</td>\n",
       "      <td>model</td>\n",
       "      <td>mean</td>\n",
       "      <td>application model</td>\n",
       "      <td>baseline renders</td>\n",
       "      <td>building important</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>344581</td>\n",
       "      <td>195935</td>\n",
       "      <td>pairwise comparisons</td>\n",
       "      <td>pairwise</td>\n",
       "      <td>comparisons</td>\n",
       "      <td>ability explicitly</td>\n",
       "      <td>addition pairwise</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>344583</td>\n",
       "      <td>195935</td>\n",
       "      <td>assume continous</td>\n",
       "      <td>binary models</td>\n",
       "      <td>combining binary</td>\n",
       "      <td>continous distribution</td>\n",
       "      <td>decisions assume</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>344585</td>\n",
       "      <td>207115</td>\n",
       "      <td>instrumental variables</td>\n",
       "      <td>instrumental</td>\n",
       "      <td>accounting political</td>\n",
       "      <td>author help</td>\n",
       "      <td>economics health</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>344586</td>\n",
       "      <td>206620</td>\n",
       "      <td>fonction</td>\n",
       "      <td>anova fonction</td>\n",
       "      <td>lm fonction</td>\n",
       "      <td>lm</td>\n",
       "      <td>avoid overpramatizing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>344587</td>\n",
       "      <td>207096</td>\n",
       "      <td>probability</td>\n",
       "      <td>probability density</td>\n",
       "      <td>density function</td>\n",
       "      <td>density</td>\n",
       "      <td>function</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>344588</td>\n",
       "      <td>198848</td>\n",
       "      <td>sufficient estimator</td>\n",
       "      <td>bernoulli</td>\n",
       "      <td>binomial distributions</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>textbook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>344589</td>\n",
       "      <td>206947</td>\n",
       "      <td>spss</td>\n",
       "      <td>come instruction</td>\n",
       "      <td>downloaded plugin</td>\n",
       "      <td>fully motivated</td>\n",
       "      <td>instruction spss</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>344592</td>\n",
       "      <td>96600</td>\n",
       "      <td>area posterior</td>\n",
       "      <td>axis reasonable</td>\n",
       "      <td>direction observed</td>\n",
       "      <td>does unable</td>\n",
       "      <td>effect opposite</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>344593</td>\n",
       "      <td>206570</td>\n",
       "      <td>gain lift</td>\n",
       "      <td>lift used</td>\n",
       "      <td>metrics auc</td>\n",
       "      <td>score gain</td>\n",
       "      <td>different evaluation</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>344594</td>\n",
       "      <td>207118</td>\n",
       "      <td>neurons</td>\n",
       "      <td>basis</td>\n",
       "      <td>inputs</td>\n",
       "      <td>correlations</td>\n",
       "      <td>basing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>344595</td>\n",
       "      <td>230</td>\n",
       "      <td>example unsupervised</td>\n",
       "      <td>unsupervised learning</td>\n",
       "      <td>simple example</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>learning</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>344596</td>\n",
       "      <td>207021</td>\n",
       "      <td>plant</td>\n",
       "      <td>host</td>\n",
       "      <td>dodder</td>\n",
       "      <td>host plant</td>\n",
       "      <td>dodder plant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>344597</td>\n",
       "      <td>207096</td>\n",
       "      <td>estimating</td>\n",
       "      <td>clustering meta</td>\n",
       "      <td>clusters estimating</td>\n",
       "      <td>density estimating</td>\n",
       "      <td>estimating density</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>344598</td>\n",
       "      <td>207058</td>\n",
       "      <td>series</td>\n",
       "      <td>paper</td>\n",
       "      <td>time series</td>\n",
       "      <td>time</td>\n",
       "      <td>forecasting</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>344599</td>\n",
       "      <td>207096</td>\n",
       "      <td>spaces</td>\n",
       "      <td>probability measures</td>\n",
       "      <td>functions probability</td>\n",
       "      <td>finite dimensional</td>\n",
       "      <td>discrete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>344600</td>\n",
       "      <td>163114</td>\n",
       "      <td>dickey fuller</td>\n",
       "      <td>dickey</td>\n",
       "      <td>fuller</td>\n",
       "      <td>fuller test</td>\n",
       "      <td>test stata</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>344601</td>\n",
       "      <td>207099</td>\n",
       "      <td>possible wilcox</td>\n",
       "      <td>check sample</td>\n",
       "      <td>different possible</td>\n",
       "      <td>wilcox test</td>\n",
       "      <td>sample normal</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>344602</td>\n",
       "      <td>121522</td>\n",
       "      <td>logistic</td>\n",
       "      <td>logistic tag</td>\n",
       "      <td>number relevant</td>\n",
       "      <td>relevant questions</td>\n",
       "      <td>tag number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>344604</td>\n",
       "      <td>161278</td>\n",
       "      <td>effects limited</td>\n",
       "      <td>existing mean</td>\n",
       "      <td>matrix existing</td>\n",
       "      <td>permanent effect</td>\n",
       "      <td>matter variable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>344605</td>\n",
       "      <td>207126</td>\n",
       "      <td>pasta</td>\n",
       "      <td>anova tukeys</td>\n",
       "      <td>apologies incorrectly</td>\n",
       "      <td>batches pasta</td>\n",
       "      <td>cooking anova</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>344607</td>\n",
       "      <td>121270</td>\n",
       "      <td>rbms</td>\n",
       "      <td>networks</td>\n",
       "      <td>hopfield nets</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>hinton</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>344608</td>\n",
       "      <td>191681</td>\n",
       "      <td>hessian</td>\n",
       "      <td>approximate hessian</td>\n",
       "      <td>dealing hessian</td>\n",
       "      <td>trying approximate</td>\n",
       "      <td>bfgs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>344609</td>\n",
       "      <td>127538</td>\n",
       "      <td>spikes</td>\n",
       "      <td>tsclean</td>\n",
       "      <td>winsorization</td>\n",
       "      <td>dummy variables</td>\n",
       "      <td>explainable</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>344610</td>\n",
       "      <td>207128</td>\n",
       "      <td>normality</td>\n",
       "      <td>dismiss assumption</td>\n",
       "      <td>know violate</td>\n",
       "      <td>know wilcox</td>\n",
       "      <td>lt dismiss</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19725 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  user_id                  TopWord1                 TopWord2  \\\n",
       "0       317697   134975   variables statistically             mixed effect   \n",
       "1       317699    45374                  accuracy      validation accuracy   \n",
       "2       317701   171235                   freedom                     mean   \n",
       "3       317703   187797                  patients                 treating   \n",
       "4       317704    61496               uncertainty               error ways   \n",
       "5       317705   134369     bonferroni correction               bonferroni   \n",
       "6       317707   187792   environmental variables                   traits   \n",
       "7       317708    82816        solve differential    equation distribution   \n",
       "8       317710    61092  monotonically increasing            monotonically   \n",
       "9       317711   179343          affect specified             shock affect   \n",
       "10      317712    67137                      simr                able edit   \n",
       "11      317713    67137        measures construct                    power   \n",
       "12      317716   187803        terms applications       difference poisson   \n",
       "13      317717   113090                 graphical         graphical models   \n",
       "14      317718    80922                 recurrent           deep recurrent   \n",
       "15      317719   187804                    person                young old   \n",
       "16      317721   177228              intervention         male respondents   \n",
       "17      317722   187806                      fans                     band   \n",
       "18      317723     8123      distinguishes legged                   legged   \n",
       "19      317724   117168                     block               resampling   \n",
       "20      317725   185581                rows small       corresponding rows   \n",
       "21      317727   117168                     block                   blocks   \n",
       "22      317728   187809                 subscribe                   mining   \n",
       "23      317729    31484         beta distribution                     beta   \n",
       "24      317730   111479               eigenvector                     grey   \n",
       "25      317731      805                      beta                 gaussian   \n",
       "26      317732    88727                    signal                    bound   \n",
       "27      317733   131977            don understand  architecture explaining   \n",
       "28      317734   187810              intervention                   signal   \n",
       "29      317735     8402         denote noncentral           derived theory   \n",
       "...        ...      ...                       ...                      ...   \n",
       "19970   344573    94586              tree species                  species   \n",
       "19971   344574   105149                   college       college highschool   \n",
       "19972   344575   136275                      mean                 use mean   \n",
       "19973   344578   163648            number correct          correct answers   \n",
       "19974   344579   207112               equal equal    distribution variable   \n",
       "19975   344580   195935                     model                     mean   \n",
       "19976   344581   195935      pairwise comparisons                 pairwise   \n",
       "19977   344583   195935          assume continous            binary models   \n",
       "19978   344585   207115    instrumental variables             instrumental   \n",
       "19979   344586   206620                  fonction           anova fonction   \n",
       "19980   344587   207096               probability      probability density   \n",
       "19981   344588   198848      sufficient estimator                bernoulli   \n",
       "19982   344589   206947                      spss         come instruction   \n",
       "19983   344592    96600            area posterior          axis reasonable   \n",
       "19984   344593   206570                 gain lift                lift used   \n",
       "19985   344594   207118                   neurons                    basis   \n",
       "19986   344595      230      example unsupervised    unsupervised learning   \n",
       "19987   344596   207021                     plant                     host   \n",
       "19988   344597   207096                estimating          clustering meta   \n",
       "19989   344598   207058                    series                    paper   \n",
       "19990   344599   207096                    spaces     probability measures   \n",
       "19991   344600   163114             dickey fuller                   dickey   \n",
       "19992   344601   207099           possible wilcox             check sample   \n",
       "19993   344602   121522                  logistic             logistic tag   \n",
       "19994   344604   161278           effects limited            existing mean   \n",
       "19995   344605   207126                     pasta             anova tukeys   \n",
       "19996   344607   121270                      rbms                 networks   \n",
       "19997   344608   191681                   hessian      approximate hessian   \n",
       "19998   344609   127538                    spikes                  tsclean   \n",
       "19999   344610   207128                 normality       dismiss assumption   \n",
       "\n",
       "                     TopWord3                TopWord4  \\\n",
       "0                       mixed               variables   \n",
       "1           training accuracy                 shallow   \n",
       "2             degrees freedom                 degrees   \n",
       "3                       excel                   treat   \n",
       "4          estimate realistic         forecast method   \n",
       "5                  correction                outliers   \n",
       "6               environmental            plant traits   \n",
       "7       differential equation              need solve   \n",
       "8              differentiable              increasing   \n",
       "9            understand shock                    prof   \n",
       "10            deciding sample              edit turns   \n",
       "11                   measures        outcome measures   \n",
       "12              process terms          process markov   \n",
       "13                 log linear                  models   \n",
       "14             neural network        recurrent neural   \n",
       "15                      young                     old   \n",
       "16          intervention time             respondents   \n",
       "17                   universe        overall universe   \n",
       "18                  old style           seek opinions   \n",
       "19                     series                  blocks   \n",
       "20                 constraint            matrix shape   \n",
       "21          block observation                resample   \n",
       "22              brief ideally      customer subscribe   \n",
       "23         distribution prove               look beta   \n",
       "24                 components              eigenvalue   \n",
       "25             symmetric beta               symmetric   \n",
       "26            bound saturated        channel variance   \n",
       "27         concatenate inputs               deep mind   \n",
       "28                     events         external events   \n",
       "29                  don proof           ingersoll ros   \n",
       "...                       ...                     ...   \n",
       "19970                    tree                   crown   \n",
       "19971              highschool          student answer   \n",
       "19972                test set                    test   \n",
       "19973              let number             high school   \n",
       "19974     function parameters          interpretation   \n",
       "19975       application model        baseline renders   \n",
       "19976             comparisons      ability explicitly   \n",
       "19977        combining binary  continous distribution   \n",
       "19978    accounting political             author help   \n",
       "19979             lm fonction                      lm   \n",
       "19980        density function                 density   \n",
       "19981  binomial distributions              sufficient   \n",
       "19982       downloaded plugin         fully motivated   \n",
       "19983      direction observed             does unable   \n",
       "19984             metrics auc              score gain   \n",
       "19985                  inputs            correlations   \n",
       "19986          simple example            unsupervised   \n",
       "19987                  dodder              host plant   \n",
       "19988     clusters estimating      density estimating   \n",
       "19989             time series                    time   \n",
       "19990   functions probability      finite dimensional   \n",
       "19991                  fuller             fuller test   \n",
       "19992      different possible             wilcox test   \n",
       "19993         number relevant      relevant questions   \n",
       "19994         matrix existing        permanent effect   \n",
       "19995   apologies incorrectly           batches pasta   \n",
       "19996           hopfield nets                hopfield   \n",
       "19997         dealing hessian      trying approximate   \n",
       "19998           winsorization         dummy variables   \n",
       "19999            know violate             know wilcox   \n",
       "\n",
       "                        TopWord5  Community  \n",
       "0      statistically significant          1  \n",
       "1                     validation          3  \n",
       "2                    data degree          0  \n",
       "3                  bias treating          4  \n",
       "4                  predicts time          8  \n",
       "5                 don understand          4  \n",
       "6                          plant          1  \n",
       "7               distribution pdf          0  \n",
       "8        assuming differentiable          0  \n",
       "9                          shock          4  \n",
       "10                effect variety         -1  \n",
       "11       multivariate regression          8  \n",
       "12                markov process          3  \n",
       "13                           log          0  \n",
       "14                        neural          3  \n",
       "15                 age indicator          4  \n",
       "16                          male          4  \n",
       "17                        cities          4  \n",
       "18                   recognition          3  \n",
       "19                      resample          4  \n",
       "20                           row          3  \n",
       "21                  fourth block          4  \n",
       "22            incorporate mining          3  \n",
       "23                    prove beta          0  \n",
       "24                     variables          1  \n",
       "25                 beta gaussian          0  \n",
       "26        deriving relationships          4  \n",
       "27              explaining works          0  \n",
       "28                      external          4  \n",
       "29                   proof prove         -1  \n",
       "...                          ...        ...  \n",
       "19970                      lidar          3  \n",
       "19971         correctly question          4  \n",
       "19972                  mean test          3  \n",
       "19973                    let let         25  \n",
       "19974                 parameters          0  \n",
       "19975         building important          0  \n",
       "19976          addition pairwise          4  \n",
       "19977           decisions assume         -1  \n",
       "19978           economics health          0  \n",
       "19979      avoid overpramatizing          1  \n",
       "19980                   function          0  \n",
       "19981                   textbook          0  \n",
       "19982           instruction spss          8  \n",
       "19983            effect opposite         -1  \n",
       "19984       different evaluation         -1  \n",
       "19985                     basing          3  \n",
       "19986                   learning          9  \n",
       "19987               dodder plant          1  \n",
       "19988         estimating density          3  \n",
       "19989                forecasting          4  \n",
       "19990                   discrete          1  \n",
       "19991                 test stata         26  \n",
       "19992              sample normal         27  \n",
       "19993                 tag number          1  \n",
       "19994            matter variable         -1  \n",
       "19995              cooking anova         -1  \n",
       "19996                     hinton          3  \n",
       "19997                       bfgs          0  \n",
       "19998                explainable          4  \n",
       "19999                 lt dismiss          4  \n",
       "\n",
       "[19725 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df_w_comm.to_csv(COMMUNITIES_VIZ_PATH, encoding='utf-8', index=False, columns = ['post_id', 'Community'])\n",
    "post_df_w_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 1,\n",
       " 2: 74,\n",
       " 3: 78,\n",
       " 4: 106,\n",
       " 5: 1,\n",
       " 6: 99,\n",
       " 7: 1,\n",
       " 8: 78,\n",
       " 9: 1,\n",
       " 10: 111,\n",
       " 11: 83,\n",
       " 12: 17,\n",
       " 13: 61,\n",
       " 14: 133,\n",
       " 15: 1,\n",
       " 16: 93,\n",
       " 17: 118,\n",
       " 18: 1,\n",
       " 19: 1,\n",
       " 20: 1,\n",
       " 21: 1,\n",
       " 22: 56,\n",
       " 23: 118,\n",
       " 24: 118,\n",
       " 25: 102,\n",
       " 26: 1,\n",
       " 27: 1,\n",
       " 28: 118,\n",
       " 29: 118,\n",
       " 30: 126,\n",
       " 31: 1,\n",
       " 32: 1,\n",
       " 33: 50,\n",
       " 34: 1,\n",
       " 35: 1,\n",
       " 36: 1,\n",
       " 37: 1,\n",
       " 38: 1,\n",
       " 39: 1,\n",
       " 40: 66,\n",
       " 41: 1,\n",
       " 42: 1,\n",
       " 43: 66,\n",
       " 44: 1,\n",
       " 45: 1,\n",
       " 46: 16,\n",
       " 47: 147,\n",
       " 48: 122,\n",
       " 49: 143,\n",
       " 50: 58,\n",
       " 51: 1,\n",
       " 52: 1,\n",
       " 53: 119,\n",
       " 54: 1,\n",
       " 55: 1,\n",
       " 56: 1,\n",
       " 57: 130,\n",
       " 58: 1,\n",
       " 59: 1,\n",
       " 60: 1,\n",
       " 61: 1,\n",
       " 62: 1,\n",
       " 63: 1,\n",
       " 64: 96,\n",
       " 65: 129,\n",
       " 66: 1,\n",
       " 67: 1,\n",
       " 68: 1,\n",
       " 69: 1,\n",
       " 70: 1,\n",
       " 71: 61,\n",
       " 72: 77,\n",
       " 73: 118,\n",
       " 74: 117,\n",
       " 75: 1,\n",
       " 76: 145,\n",
       " 77: 1,\n",
       " 78: 135,\n",
       " 79: 1,\n",
       " 80: 72,\n",
       " 81: 118,\n",
       " 82: 1,\n",
       " 83: 68,\n",
       " 84: 1,\n",
       " 85: 1,\n",
       " 86: 1,\n",
       " 87: 54,\n",
       " 88: 58,\n",
       " 89: 1,\n",
       " 90: 1,\n",
       " 91: 1,\n",
       " 92: 1,\n",
       " 93: 137,\n",
       " 94: 1,\n",
       " 95: 111,\n",
       " 96: 66,\n",
       " 97: 1,\n",
       " 98: 121,\n",
       " 99: 1,\n",
       " 100: 1,\n",
       " 101: 106,\n",
       " 102: 1,\n",
       " 103: 1,\n",
       " 104: 1,\n",
       " 105: 101,\n",
       " 106: 1,\n",
       " 107: 109,\n",
       " 108: 1,\n",
       " 109: 118,\n",
       " 110: 69,\n",
       " 111: 137,\n",
       " 112: 130,\n",
       " 113: 1,\n",
       " 114: 117,\n",
       " 115: 1,\n",
       " 116: 1,\n",
       " 117: 1,\n",
       " 118: 73,\n",
       " 119: 60,\n",
       " 120: 1,\n",
       " 121: 73,\n",
       " 122: 71,\n",
       " 123: 1,\n",
       " 124: 70,\n",
       " 125: 1,\n",
       " 126: 93,\n",
       " 127: 42,\n",
       " 128: 1,\n",
       " 129: 1,\n",
       " 130: 118,\n",
       " 131: 1,\n",
       " 132: 1,\n",
       " 133: 103,\n",
       " 134: 86,\n",
       " 135: 1,\n",
       " 136: 122,\n",
       " 137: 1,\n",
       " 138: 102,\n",
       " 139: 1,\n",
       " 140: 118,\n",
       " 141: 1,\n",
       " 142: 93,\n",
       " 143: 66,\n",
       " 144: 1,\n",
       " 145: 1,\n",
       " 146: 1,\n",
       " 147: 1,\n",
       " 148: 118,\n",
       " 149: 118,\n",
       " 150: 1,\n",
       " 151: 1,\n",
       " 152: 1,\n",
       " 153: 56,\n",
       " 154: 118,\n",
       " 155: 56,\n",
       " 156: 1,\n",
       " 157: 1,\n",
       " 158: 138,\n",
       " 159: 84,\n",
       " 160: 1,\n",
       " 161: 1,\n",
       " 162: 84,\n",
       " 163: 90,\n",
       " 164: 1,\n",
       " 165: 1,\n",
       " 166: 147,\n",
       " 167: 134,\n",
       " 168: 107,\n",
       " 169: 22,\n",
       " 170: 120,\n",
       " 171: 102,\n",
       " 172: 145,\n",
       " 173: 133,\n",
       " 174: 1,\n",
       " 175: 1,\n",
       " 176: 1,\n",
       " 177: 1,\n",
       " 178: 147,\n",
       " 179: 1,\n",
       " 180: 1,\n",
       " 181: 1,\n",
       " 182: 145,\n",
       " 183: 1,\n",
       " 184: 40,\n",
       " 185: 135,\n",
       " 186: 140,\n",
       " 187: 1,\n",
       " 188: 1,\n",
       " 189: 1,\n",
       " 190: 1,\n",
       " 191: 1,\n",
       " 192: 147,\n",
       " 193: 1,\n",
       " 194: 1,\n",
       " 195: 1,\n",
       " 196: 87,\n",
       " 197: 1,\n",
       " 198: 1,\n",
       " 199: 124,\n",
       " 200: 118,\n",
       " 201: 147,\n",
       " 202: 1,\n",
       " 203: 1,\n",
       " 204: 1,\n",
       " 205: 1,\n",
       " 206: 102,\n",
       " 207: 1,\n",
       " 208: 95,\n",
       " 209: 1,\n",
       " 210: 1,\n",
       " 211: 102,\n",
       " 212: 1,\n",
       " 213: 118,\n",
       " 214: 99,\n",
       " 215: 1,\n",
       " 216: 88,\n",
       " 217: 86,\n",
       " 218: 42,\n",
       " 219: 1,\n",
       " 220: 1,\n",
       " 221: 1,\n",
       " 222: 1,\n",
       " 223: 86,\n",
       " 224: 119,\n",
       " 225: 1,\n",
       " 226: 118,\n",
       " 227: 1,\n",
       " 228: 119,\n",
       " 229: 68,\n",
       " 230: 1,\n",
       " 231: 1,\n",
       " 232: 1,\n",
       " 233: 1,\n",
       " 234: 1,\n",
       " 235: 60,\n",
       " 236: 1,\n",
       " 237: 1,\n",
       " 238: 1,\n",
       " 239: 64,\n",
       " 240: 1,\n",
       " 241: 77,\n",
       " 242: 93,\n",
       " 243: 118,\n",
       " 244: 132,\n",
       " 245: 133,\n",
       " 246: 93,\n",
       " 247: 145,\n",
       " 248: 42,\n",
       " 249: 118,\n",
       " 250: 58,\n",
       " 251: 78,\n",
       " 252: 145,\n",
       " 253: 122,\n",
       " 254: 1,\n",
       " 255: 1,\n",
       " 256: 1,\n",
       " 257: 1,\n",
       " 258: 1,\n",
       " 259: 1,\n",
       " 260: 16,\n",
       " 261: 93,\n",
       " 262: 135,\n",
       " 263: 117,\n",
       " 264: 102,\n",
       " 265: 1,\n",
       " 266: 78,\n",
       " 267: 1,\n",
       " 268: 137,\n",
       " 269: 1,\n",
       " 270: 122,\n",
       " 271: 1,\n",
       " 272: 140,\n",
       " 273: 1,\n",
       " 274: 118,\n",
       " 275: 1,\n",
       " 276: 66,\n",
       " 277: 118,\n",
       " 278: 1,\n",
       " 279: 1,\n",
       " 280: 132,\n",
       " 281: 1,\n",
       " 282: 1,\n",
       " 283: 1,\n",
       " 284: 137,\n",
       " 285: 66,\n",
       " 286: 1,\n",
       " 287: 22,\n",
       " 288: 132,\n",
       " 289: 1,\n",
       " 290: 1,\n",
       " 291: 1,\n",
       " 292: 117,\n",
       " 293: 67,\n",
       " 294: 124,\n",
       " 295: 50,\n",
       " 296: 1,\n",
       " 297: 1,\n",
       " 298: 1,\n",
       " 299: 1,\n",
       " 300: 42,\n",
       " 301: 102,\n",
       " 302: 39,\n",
       " 303: 140,\n",
       " 304: 1,\n",
       " 305: 1,\n",
       " 306: 84,\n",
       " 307: 1,\n",
       " 308: 95,\n",
       " 309: 132,\n",
       " 310: 1,\n",
       " 311: 145,\n",
       " 312: 66,\n",
       " 313: 17,\n",
       " 314: 1,\n",
       " 315: 1,\n",
       " 316: 137,\n",
       " 317: 124,\n",
       " 318: 1,\n",
       " 319: 1,\n",
       " 320: 84,\n",
       " 321: 1,\n",
       " 322: 1,\n",
       " 323: 148,\n",
       " 324: 100,\n",
       " 325: 111,\n",
       " 326: 1,\n",
       " 327: 105,\n",
       " 328: 109,\n",
       " 329: 1,\n",
       " 330: 1,\n",
       " 331: 77,\n",
       " 332: 144,\n",
       " 333: 1,\n",
       " 334: 1,\n",
       " 335: 1,\n",
       " 336: 1,\n",
       " 337: 1,\n",
       " 338: 102,\n",
       " 339: 120,\n",
       " 340: 68,\n",
       " 341: 1,\n",
       " 342: 44,\n",
       " 343: 1,\n",
       " 344: 140,\n",
       " 345: 1,\n",
       " 346: 1,\n",
       " 347: 50,\n",
       " 348: 125,\n",
       " 349: 148,\n",
       " 350: 103,\n",
       " 351: 1,\n",
       " 352: 1,\n",
       " 353: 95,\n",
       " 354: 1,\n",
       " 355: 95,\n",
       " 356: 101,\n",
       " 357: 1,\n",
       " 358: 140,\n",
       " 359: 1,\n",
       " 360: 64,\n",
       " 361: 95,\n",
       " 362: 137,\n",
       " 363: 108,\n",
       " 364: 54,\n",
       " 365: 16,\n",
       " 366: 1,\n",
       " 367: 1,\n",
       " 368: 1,\n",
       " 369: 1,\n",
       " 370: 118,\n",
       " 371: 118,\n",
       " 372: 1,\n",
       " 373: 131,\n",
       " 374: 50,\n",
       " 375: 118,\n",
       " 376: 1,\n",
       " 377: 1,\n",
       " 378: 1,\n",
       " 379: 1,\n",
       " 380: 1,\n",
       " 381: 118,\n",
       " 382: 1,\n",
       " 383: 1,\n",
       " 384: 17,\n",
       " 385: 1,\n",
       " 386: 87,\n",
       " 387: 1,\n",
       " 388: 68,\n",
       " 389: 1,\n",
       " 390: 1,\n",
       " 391: 1,\n",
       " 392: 96,\n",
       " 393: 1,\n",
       " 394: 1,\n",
       " 395: 1,\n",
       " 396: 1,\n",
       " 397: 1,\n",
       " 398: 118,\n",
       " 399: 1,\n",
       " 400: 119,\n",
       " 401: 83,\n",
       " 402: 145,\n",
       " 403: 1,\n",
       " 404: 66,\n",
       " 405: 66,\n",
       " 406: 68,\n",
       " 407: 59,\n",
       " 408: 1,\n",
       " 409: 101,\n",
       " 410: 1,\n",
       " 411: 107,\n",
       " 412: 89,\n",
       " 413: 1,\n",
       " 414: 1,\n",
       " 415: 1,\n",
       " 416: 145,\n",
       " 417: 1,\n",
       " 418: 1,\n",
       " 419: 1,\n",
       " 420: 88,\n",
       " 421: 1,\n",
       " 422: 147,\n",
       " 423: 1,\n",
       " 424: 1,\n",
       " 425: 118,\n",
       " 426: 1,\n",
       " 427: 1,\n",
       " 428: 140,\n",
       " 429: 54,\n",
       " 430: 1,\n",
       " 431: 16,\n",
       " 432: 130,\n",
       " 433: 72,\n",
       " 434: 1,\n",
       " 435: 1,\n",
       " 436: 58,\n",
       " 437: 58,\n",
       " 438: 1,\n",
       " 439: 1,\n",
       " 440: 130,\n",
       " 441: 54,\n",
       " 442: 1,\n",
       " 443: 147,\n",
       " 444: 1,\n",
       " 445: 110,\n",
       " 446: 1,\n",
       " 447: 58,\n",
       " 448: 118,\n",
       " 449: 59,\n",
       " 450: 1,\n",
       " 451: 1,\n",
       " 452: 1,\n",
       " 453: 130,\n",
       " 454: 118,\n",
       " 455: 100,\n",
       " 456: 1,\n",
       " 457: 1,\n",
       " 458: 1,\n",
       " 459: 54,\n",
       " 460: 1,\n",
       " 461: 1,\n",
       " 462: 1,\n",
       " 463: 95,\n",
       " 464: 64,\n",
       " 465: 123,\n",
       " 466: 1,\n",
       " 467: 115,\n",
       " 468: 42,\n",
       " 469: 54,\n",
       " 470: 118,\n",
       " 471: 1,\n",
       " 472: 1,\n",
       " 473: 89,\n",
       " 474: 16,\n",
       " 475: 1,\n",
       " 476: 102,\n",
       " 477: 1,\n",
       " 478: 131,\n",
       " 479: 66,\n",
       " 480: 118,\n",
       " 481: 118,\n",
       " 482: 118,\n",
       " 483: 107,\n",
       " 484: 117,\n",
       " 485: 1,\n",
       " 486: 1,\n",
       " 487: 1,\n",
       " 488: 66,\n",
       " 489: 88,\n",
       " 490: 107,\n",
       " 491: 17,\n",
       " 492: 143,\n",
       " 493: 1,\n",
       " 494: 54,\n",
       " 495: 137,\n",
       " 496: 1,\n",
       " 497: 118,\n",
       " 498: 134,\n",
       " 499: 50,\n",
       " 500: 73,\n",
       " 501: 116,\n",
       " 502: 145,\n",
       " 503: 145,\n",
       " 504: 77,\n",
       " 505: 66,\n",
       " 506: 84,\n",
       " 507: 1,\n",
       " 508: 1,\n",
       " 509: 1,\n",
       " 510: 1,\n",
       " 511: 58,\n",
       " 512: 84,\n",
       " 513: 1,\n",
       " 514: 1,\n",
       " 515: 131,\n",
       " 516: 1,\n",
       " 517: 1,\n",
       " 518: 89,\n",
       " 519: 101,\n",
       " 520: 1,\n",
       " 521: 1,\n",
       " 522: 147,\n",
       " 523: 1,\n",
       " 524: 118,\n",
       " 525: 1,\n",
       " 526: 118,\n",
       " 527: 1,\n",
       " 528: 105,\n",
       " 529: 1,\n",
       " 530: 16,\n",
       " 531: 1,\n",
       " 532: 131,\n",
       " 533: 16,\n",
       " 534: 1,\n",
       " 535: 58,\n",
       " 536: 84,\n",
       " 537: 1,\n",
       " 538: 1,\n",
       " 539: 108,\n",
       " 540: 1,\n",
       " 541: 1,\n",
       " 542: 137,\n",
       " 543: 77,\n",
       " 544: 82,\n",
       " 545: 131,\n",
       " 546: 76,\n",
       " 547: 1,\n",
       " 548: 1,\n",
       " 549: 1,\n",
       " 550: 1,\n",
       " 551: 116,\n",
       " 552: 76,\n",
       " 553: 118,\n",
       " 554: 117,\n",
       " 555: 1,\n",
       " 556: 1,\n",
       " 557: 125,\n",
       " 558: 67,\n",
       " 559: 134,\n",
       " 560: 66,\n",
       " 561: 126,\n",
       " 562: 102,\n",
       " 563: 78,\n",
       " 564: 1,\n",
       " 565: 1,\n",
       " 566: 1,\n",
       " 567: 1,\n",
       " 568: 77,\n",
       " 569: 1,\n",
       " 570: 72,\n",
       " 571: 76,\n",
       " 572: 146,\n",
       " 573: 137,\n",
       " 574: 140,\n",
       " 575: 137,\n",
       " 576: 1,\n",
       " 577: 119,\n",
       " 578: 1,\n",
       " 579: 1,\n",
       " 580: 138,\n",
       " 581: 1,\n",
       " 582: 1,\n",
       " 583: 137,\n",
       " 584: 63,\n",
       " 585: 68,\n",
       " 586: 83,\n",
       " 587: 118,\n",
       " 588: 95,\n",
       " 589: 140,\n",
       " 590: 67,\n",
       " 591: 1,\n",
       " 592: 110,\n",
       " 593: 1,\n",
       " 594: 118,\n",
       " 595: 130,\n",
       " 596: 118,\n",
       " 597: 118,\n",
       " 598: 1,\n",
       " 599: 1,\n",
       " 600: 93,\n",
       " 601: 102,\n",
       " 602: 118,\n",
       " 603: 1,\n",
       " 604: 126,\n",
       " 605: 1,\n",
       " 606: 65,\n",
       " 607: 107,\n",
       " 608: 58,\n",
       " 609: 1,\n",
       " 610: 1,\n",
       " 611: 63,\n",
       " 612: 144,\n",
       " 613: 86,\n",
       " 614: 118,\n",
       " 615: 1,\n",
       " 616: 102,\n",
       " 617: 118,\n",
       " 618: 1,\n",
       " 619: 1,\n",
       " 620: 125,\n",
       " 621: 1,\n",
       " 622: 67,\n",
       " 623: 67,\n",
       " 624: 82,\n",
       " 625: 1,\n",
       " 626: 1,\n",
       " 627: 1,\n",
       " 628: 67,\n",
       " 629: 67,\n",
       " 630: 1,\n",
       " 631: 1,\n",
       " 632: 1,\n",
       " 633: 1,\n",
       " 634: 1,\n",
       " 635: 1,\n",
       " 636: 1,\n",
       " 637: 1,\n",
       " 638: 105,\n",
       " 639: 1,\n",
       " 640: 123,\n",
       " 641: 135,\n",
       " 642: 1,\n",
       " 643: 58,\n",
       " 644: 125,\n",
       " 645: 1,\n",
       " 646: 1,\n",
       " 647: 1,\n",
       " 648: 122,\n",
       " 649: 28,\n",
       " 650: 1,\n",
       " 651: 50,\n",
       " 652: 1,\n",
       " 653: 1,\n",
       " 654: 117,\n",
       " 655: 1,\n",
       " 656: 145,\n",
       " 657: 135,\n",
       " 658: 1,\n",
       " 659: 91,\n",
       " 660: 50,\n",
       " 661: 89,\n",
       " 662: 108,\n",
       " 663: 1,\n",
       " 664: 1,\n",
       " 665: 1,\n",
       " 666: 97,\n",
       " 667: 118,\n",
       " 668: 97,\n",
       " 669: 97,\n",
       " 670: 1,\n",
       " 671: 1,\n",
       " 672: 1,\n",
       " 673: 1,\n",
       " 674: 1,\n",
       " 675: 1,\n",
       " 676: 91,\n",
       " 677: 1,\n",
       " 678: 1,\n",
       " 679: 103,\n",
       " 680: 107,\n",
       " 681: 1,\n",
       " 682: 1,\n",
       " 683: 1,\n",
       " 684: 1,\n",
       " 685: 1,\n",
       " 686: 97,\n",
       " 687: 1,\n",
       " 688: 1,\n",
       " 689: 145,\n",
       " 690: 130,\n",
       " 691: 64,\n",
       " 692: 1,\n",
       " 693: 118,\n",
       " 694: 103,\n",
       " 695: 106,\n",
       " 696: 1,\n",
       " 697: 1,\n",
       " 698: 1,\n",
       " 699: 1,\n",
       " 700: 96,\n",
       " 701: 1,\n",
       " 702: 1,\n",
       " 703: 1,\n",
       " 704: 147,\n",
       " 705: 1,\n",
       " 706: 1,\n",
       " 707: 118,\n",
       " 708: 50,\n",
       " 709: 77,\n",
       " 710: 1,\n",
       " 711: 1,\n",
       " 712: 1,\n",
       " 713: 1,\n",
       " 714: 1,\n",
       " 715: 78,\n",
       " 716: 1,\n",
       " 717: 1,\n",
       " 718: 1,\n",
       " 719: 1,\n",
       " 720: 147,\n",
       " 721: 1,\n",
       " 722: 1,\n",
       " 723: 67,\n",
       " 724: 1,\n",
       " 725: 1,\n",
       " 726: 1,\n",
       " 727: 1,\n",
       " 728: 1,\n",
       " 729: 0,\n",
       " 730: 1,\n",
       " 731: 1,\n",
       " 732: 134,\n",
       " 733: 123,\n",
       " 734: 109,\n",
       " 735: 119,\n",
       " 736: 1,\n",
       " 737: 1,\n",
       " 738: 1,\n",
       " 739: 118,\n",
       " 740: 50,\n",
       " 741: 123,\n",
       " 742: 117,\n",
       " 743: 1,\n",
       " 744: 102,\n",
       " 745: 101,\n",
       " 746: 130,\n",
       " 747: 1,\n",
       " 748: 1,\n",
       " 749: 1,\n",
       " 750: 1,\n",
       " 751: 145,\n",
       " 752: 130,\n",
       " 753: 1,\n",
       " 754: 126,\n",
       " 755: 114,\n",
       " 756: 1,\n",
       " 757: 141,\n",
       " 758: 1,\n",
       " 759: 50,\n",
       " 760: 101,\n",
       " 761: 50,\n",
       " 762: 1,\n",
       " 763: 1,\n",
       " 764: 1,\n",
       " 765: 1,\n",
       " 766: 91,\n",
       " 767: 134,\n",
       " 768: 64,\n",
       " 769: 1,\n",
       " 770: 50,\n",
       " 771: 82,\n",
       " 772: 1,\n",
       " 773: 1,\n",
       " 774: 95,\n",
       " 775: 103,\n",
       " 776: 117,\n",
       " 777: 118,\n",
       " 778: 1,\n",
       " 779: 91,\n",
       " 780: 1,\n",
       " 781: 1,\n",
       " 782: 1,\n",
       " 783: 18,\n",
       " 784: 1,\n",
       " 785: 117,\n",
       " 786: 1,\n",
       " 787: 78,\n",
       " 788: 118,\n",
       " 789: 1,\n",
       " 790: 1,\n",
       " 791: 118,\n",
       " 792: 1,\n",
       " 793: 1,\n",
       " 794: 117,\n",
       " 795: 118,\n",
       " 796: 1,\n",
       " 797: 116,\n",
       " 798: 140,\n",
       " 799: 54,\n",
       " 800: 1,\n",
       " 801: 103,\n",
       " 802: 135,\n",
       " 803: 1,\n",
       " 804: 54,\n",
       " 805: 1,\n",
       " 806: 54,\n",
       " 807: 17,\n",
       " 808: 68,\n",
       " 809: 67,\n",
       " 810: 1,\n",
       " 811: 1,\n",
       " 812: 118,\n",
       " 813: 137,\n",
       " 814: 105,\n",
       " 815: 1,\n",
       " 816: 58,\n",
       " 817: 1,\n",
       " 818: 1,\n",
       " 819: 1,\n",
       " 820: 1,\n",
       " 821: 1,\n",
       " 822: 1,\n",
       " 823: 1,\n",
       " 824: 1,\n",
       " 825: 118,\n",
       " 826: 118,\n",
       " 827: 1,\n",
       " 828: 1,\n",
       " 829: 118,\n",
       " 830: 145,\n",
       " 831: 1,\n",
       " 832: 84,\n",
       " 833: 16,\n",
       " 834: 132,\n",
       " 835: 132,\n",
       " 836: 1,\n",
       " 837: 137,\n",
       " 838: 1,\n",
       " 839: 135,\n",
       " 840: 60,\n",
       " 841: 1,\n",
       " 842: 1,\n",
       " 843: 1,\n",
       " 844: 137,\n",
       " 845: 16,\n",
       " 846: 56,\n",
       " 847: 1,\n",
       " 848: 145,\n",
       " 849: 56,\n",
       " 850: 1,\n",
       " 851: 118,\n",
       " 852: 1,\n",
       " 853: 1,\n",
       " 854: 105,\n",
       " 855: 147,\n",
       " 856: 123,\n",
       " 857: 96,\n",
       " 858: 51,\n",
       " 859: 1,\n",
       " 860: 117,\n",
       " 861: 105,\n",
       " 862: 84,\n",
       " 863: 118,\n",
       " 864: 115,\n",
       " 865: 1,\n",
       " 866: 1,\n",
       " 867: 1,\n",
       " 868: 145,\n",
       " 869: 1,\n",
       " 870: 118,\n",
       " 871: 1,\n",
       " 872: 42,\n",
       " 873: 1,\n",
       " 874: 1,\n",
       " 875: 1,\n",
       " 876: 78,\n",
       " 877: 1,\n",
       " 878: 54,\n",
       " 879: 137,\n",
       " 880: 1,\n",
       " 881: 120,\n",
       " 882: 1,\n",
       " 883: 127,\n",
       " 884: 16,\n",
       " 885: 123,\n",
       " 886: 1,\n",
       " 887: 1,\n",
       " 888: 147,\n",
       " 889: 108,\n",
       " 890: 1,\n",
       " 891: 147,\n",
       " 892: 1,\n",
       " 893: 1,\n",
       " 894: 118,\n",
       " 895: 87,\n",
       " 896: 1,\n",
       " 897: 144,\n",
       " 898: 1,\n",
       " 899: 16,\n",
       " 900: 1,\n",
       " 901: 1,\n",
       " 902: 67,\n",
       " 903: 1,\n",
       " 904: 1,\n",
       " 905: 102,\n",
       " 906: 100,\n",
       " 907: 147,\n",
       " 908: 66,\n",
       " 909: 1,\n",
       " 910: 118,\n",
       " 911: 119,\n",
       " 912: 30,\n",
       " 913: 93,\n",
       " 914: 118,\n",
       " 915: 131,\n",
       " 916: 1,\n",
       " 917: 78,\n",
       " 918: 78,\n",
       " 919: 1,\n",
       " 920: 1,\n",
       " 921: 107,\n",
       " 922: 1,\n",
       " 923: 114,\n",
       " 924: 105,\n",
       " 925: 1,\n",
       " 926: 1,\n",
       " 927: 1,\n",
       " 928: 146,\n",
       " 929: 1,\n",
       " 930: 1,\n",
       " 931: 1,\n",
       " 932: 118,\n",
       " 933: 67,\n",
       " 934: 84,\n",
       " 935: 118,\n",
       " 936: 118,\n",
       " 937: 147,\n",
       " 938: 147,\n",
       " 939: 1,\n",
       " 940: 96,\n",
       " 941: 1,\n",
       " 942: 0,\n",
       " 943: 119,\n",
       " 944: 123,\n",
       " 945: 66,\n",
       " 946: 68,\n",
       " 947: 118,\n",
       " 948: 84,\n",
       " 949: 1,\n",
       " 950: 42,\n",
       " 951: 147,\n",
       " 952: 1,\n",
       " 953: 1,\n",
       " 954: 54,\n",
       " 955: 129,\n",
       " 956: 148,\n",
       " 957: 1,\n",
       " 958: 118,\n",
       " 959: 1,\n",
       " 960: 118,\n",
       " 961: 1,\n",
       " 962: 140,\n",
       " 963: 50,\n",
       " 964: 1,\n",
       " 965: 140,\n",
       " 966: 107,\n",
       " 967: 1,\n",
       " 968: 1,\n",
       " 969: 1,\n",
       " 970: 1,\n",
       " 971: 1,\n",
       " 972: 1,\n",
       " 973: 113,\n",
       " 974: 54,\n",
       " 975: 113,\n",
       " 976: 1,\n",
       " 977: 54,\n",
       " 978: 1,\n",
       " 979: 58,\n",
       " 980: 1,\n",
       " 981: 54,\n",
       " 982: 1,\n",
       " 983: 102,\n",
       " 984: 118,\n",
       " 985: 89,\n",
       " 986: 42,\n",
       " 987: 122,\n",
       " 988: 1,\n",
       " 989: 1,\n",
       " 990: 1,\n",
       " 991: 70,\n",
       " 992: 1,\n",
       " 993: 76,\n",
       " 994: 145,\n",
       " 995: 102,\n",
       " 996: 1,\n",
       " 997: 1,\n",
       " 998: 134,\n",
       " 999: 1,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spectral clustering\n",
    "pickle_f = open(SPEC_COMMUNITIES_PICKLE, 'rb')\n",
    "community_dict2 = pickle.load(pickle_f)\n",
    "pickle_f.close()\n",
    "\n",
    "community_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_postids(G):\n",
    "    \"\"\"\n",
    "    Returns a Graph containing all the remapped post_ids so that they go from 0 to n. \n",
    "    Also returns the dictionary that maps the ids to their new value.\n",
    "    \"\"\"\n",
    "    postid_map = dict()\n",
    "    new_G = snap.TUNGraph.New()\n",
    "    index = 0\n",
    "    \n",
    "    # Remap all nodes. Only keep ones with degree > 0.\n",
    "    for N in G.Nodes():\n",
    "        if (N.GetDeg() < 1): continue \n",
    "        postid_map[N.GetId()] = index\n",
    "        new_G.AddNode(index)\n",
    "        index += 1\n",
    "                \n",
    "    # Remap all edges.\n",
    "    for E in G.Edges(): # Edge traversal\n",
    "        new_G.AddEdge(postid_map[E.GetSrcNId()], postid_map[E.GetDstNId()])\n",
    "        \n",
    "    return new_G, postid_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, postid_dict2 = remap_postids(post_graph)\n",
    "\n",
    "post_df2 = load_top_ngram_df(POST_TOP_NGRAM_PATH)\n",
    "post_df_w_comm2 = add_communities_post_df(post_df2, community_dict2, postid_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "      <th>Community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317697</td>\n",
       "      <td>134975</td>\n",
       "      <td>variables statistically</td>\n",
       "      <td>mixed effect</td>\n",
       "      <td>mixed</td>\n",
       "      <td>variables</td>\n",
       "      <td>statistically significant</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317699</td>\n",
       "      <td>45374</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>validation accuracy</td>\n",
       "      <td>training accuracy</td>\n",
       "      <td>shallow</td>\n",
       "      <td>validation</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317701</td>\n",
       "      <td>171235</td>\n",
       "      <td>freedom</td>\n",
       "      <td>mean</td>\n",
       "      <td>degrees freedom</td>\n",
       "      <td>degrees</td>\n",
       "      <td>data degree</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317703</td>\n",
       "      <td>187797</td>\n",
       "      <td>patients</td>\n",
       "      <td>treating</td>\n",
       "      <td>excel</td>\n",
       "      <td>treat</td>\n",
       "      <td>bias treating</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317704</td>\n",
       "      <td>61496</td>\n",
       "      <td>uncertainty</td>\n",
       "      <td>error ways</td>\n",
       "      <td>estimate realistic</td>\n",
       "      <td>forecast method</td>\n",
       "      <td>predicts time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>317705</td>\n",
       "      <td>134369</td>\n",
       "      <td>bonferroni correction</td>\n",
       "      <td>bonferroni</td>\n",
       "      <td>correction</td>\n",
       "      <td>outliers</td>\n",
       "      <td>don understand</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>317707</td>\n",
       "      <td>187792</td>\n",
       "      <td>environmental variables</td>\n",
       "      <td>traits</td>\n",
       "      <td>environmental</td>\n",
       "      <td>plant traits</td>\n",
       "      <td>plant</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>317708</td>\n",
       "      <td>82816</td>\n",
       "      <td>solve differential</td>\n",
       "      <td>equation distribution</td>\n",
       "      <td>differential equation</td>\n",
       "      <td>need solve</td>\n",
       "      <td>distribution pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>317710</td>\n",
       "      <td>61092</td>\n",
       "      <td>monotonically increasing</td>\n",
       "      <td>monotonically</td>\n",
       "      <td>differentiable</td>\n",
       "      <td>increasing</td>\n",
       "      <td>assuming differentiable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>317711</td>\n",
       "      <td>179343</td>\n",
       "      <td>affect specified</td>\n",
       "      <td>shock affect</td>\n",
       "      <td>understand shock</td>\n",
       "      <td>prof</td>\n",
       "      <td>shock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>317712</td>\n",
       "      <td>67137</td>\n",
       "      <td>simr</td>\n",
       "      <td>able edit</td>\n",
       "      <td>deciding sample</td>\n",
       "      <td>edit turns</td>\n",
       "      <td>effect variety</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>317713</td>\n",
       "      <td>67137</td>\n",
       "      <td>measures construct</td>\n",
       "      <td>power</td>\n",
       "      <td>measures</td>\n",
       "      <td>outcome measures</td>\n",
       "      <td>multivariate regression</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>317716</td>\n",
       "      <td>187803</td>\n",
       "      <td>terms applications</td>\n",
       "      <td>difference poisson</td>\n",
       "      <td>process terms</td>\n",
       "      <td>process markov</td>\n",
       "      <td>markov process</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>317717</td>\n",
       "      <td>113090</td>\n",
       "      <td>graphical</td>\n",
       "      <td>graphical models</td>\n",
       "      <td>log linear</td>\n",
       "      <td>models</td>\n",
       "      <td>log</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>317718</td>\n",
       "      <td>80922</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>deep recurrent</td>\n",
       "      <td>neural network</td>\n",
       "      <td>recurrent neural</td>\n",
       "      <td>neural</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>317719</td>\n",
       "      <td>187804</td>\n",
       "      <td>person</td>\n",
       "      <td>young old</td>\n",
       "      <td>young</td>\n",
       "      <td>old</td>\n",
       "      <td>age indicator</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>317721</td>\n",
       "      <td>177228</td>\n",
       "      <td>intervention</td>\n",
       "      <td>male respondents</td>\n",
       "      <td>intervention time</td>\n",
       "      <td>respondents</td>\n",
       "      <td>male</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>317722</td>\n",
       "      <td>187806</td>\n",
       "      <td>fans</td>\n",
       "      <td>band</td>\n",
       "      <td>universe</td>\n",
       "      <td>overall universe</td>\n",
       "      <td>cities</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>317723</td>\n",
       "      <td>8123</td>\n",
       "      <td>distinguishes legged</td>\n",
       "      <td>legged</td>\n",
       "      <td>old style</td>\n",
       "      <td>seek opinions</td>\n",
       "      <td>recognition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>317724</td>\n",
       "      <td>117168</td>\n",
       "      <td>block</td>\n",
       "      <td>resampling</td>\n",
       "      <td>series</td>\n",
       "      <td>blocks</td>\n",
       "      <td>resample</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>317725</td>\n",
       "      <td>185581</td>\n",
       "      <td>rows small</td>\n",
       "      <td>corresponding rows</td>\n",
       "      <td>constraint</td>\n",
       "      <td>matrix shape</td>\n",
       "      <td>row</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>317727</td>\n",
       "      <td>117168</td>\n",
       "      <td>block</td>\n",
       "      <td>blocks</td>\n",
       "      <td>block observation</td>\n",
       "      <td>resample</td>\n",
       "      <td>fourth block</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>317728</td>\n",
       "      <td>187809</td>\n",
       "      <td>subscribe</td>\n",
       "      <td>mining</td>\n",
       "      <td>brief ideally</td>\n",
       "      <td>customer subscribe</td>\n",
       "      <td>incorporate mining</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>317729</td>\n",
       "      <td>31484</td>\n",
       "      <td>beta distribution</td>\n",
       "      <td>beta</td>\n",
       "      <td>distribution prove</td>\n",
       "      <td>look beta</td>\n",
       "      <td>prove beta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>317730</td>\n",
       "      <td>111479</td>\n",
       "      <td>eigenvector</td>\n",
       "      <td>grey</td>\n",
       "      <td>components</td>\n",
       "      <td>eigenvalue</td>\n",
       "      <td>variables</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>317731</td>\n",
       "      <td>805</td>\n",
       "      <td>beta</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>symmetric beta</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>beta gaussian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>317732</td>\n",
       "      <td>88727</td>\n",
       "      <td>signal</td>\n",
       "      <td>bound</td>\n",
       "      <td>bound saturated</td>\n",
       "      <td>channel variance</td>\n",
       "      <td>deriving relationships</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>317733</td>\n",
       "      <td>131977</td>\n",
       "      <td>don understand</td>\n",
       "      <td>architecture explaining</td>\n",
       "      <td>concatenate inputs</td>\n",
       "      <td>deep mind</td>\n",
       "      <td>explaining works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>317734</td>\n",
       "      <td>187810</td>\n",
       "      <td>intervention</td>\n",
       "      <td>signal</td>\n",
       "      <td>events</td>\n",
       "      <td>external events</td>\n",
       "      <td>external</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>317735</td>\n",
       "      <td>8402</td>\n",
       "      <td>denote noncentral</td>\n",
       "      <td>derived theory</td>\n",
       "      <td>don proof</td>\n",
       "      <td>ingersoll ros</td>\n",
       "      <td>proof prove</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>344573</td>\n",
       "      <td>94586</td>\n",
       "      <td>tree species</td>\n",
       "      <td>species</td>\n",
       "      <td>tree</td>\n",
       "      <td>crown</td>\n",
       "      <td>lidar</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>344574</td>\n",
       "      <td>105149</td>\n",
       "      <td>college</td>\n",
       "      <td>college highschool</td>\n",
       "      <td>highschool</td>\n",
       "      <td>student answer</td>\n",
       "      <td>correctly question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>344575</td>\n",
       "      <td>136275</td>\n",
       "      <td>mean</td>\n",
       "      <td>use mean</td>\n",
       "      <td>test set</td>\n",
       "      <td>test</td>\n",
       "      <td>mean test</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>344578</td>\n",
       "      <td>163648</td>\n",
       "      <td>number correct</td>\n",
       "      <td>correct answers</td>\n",
       "      <td>let number</td>\n",
       "      <td>high school</td>\n",
       "      <td>let let</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>344579</td>\n",
       "      <td>207112</td>\n",
       "      <td>equal equal</td>\n",
       "      <td>distribution variable</td>\n",
       "      <td>function parameters</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>parameters</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>344580</td>\n",
       "      <td>195935</td>\n",
       "      <td>model</td>\n",
       "      <td>mean</td>\n",
       "      <td>application model</td>\n",
       "      <td>baseline renders</td>\n",
       "      <td>building important</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>344581</td>\n",
       "      <td>195935</td>\n",
       "      <td>pairwise comparisons</td>\n",
       "      <td>pairwise</td>\n",
       "      <td>comparisons</td>\n",
       "      <td>ability explicitly</td>\n",
       "      <td>addition pairwise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>344583</td>\n",
       "      <td>195935</td>\n",
       "      <td>assume continous</td>\n",
       "      <td>binary models</td>\n",
       "      <td>combining binary</td>\n",
       "      <td>continous distribution</td>\n",
       "      <td>decisions assume</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>344585</td>\n",
       "      <td>207115</td>\n",
       "      <td>instrumental variables</td>\n",
       "      <td>instrumental</td>\n",
       "      <td>accounting political</td>\n",
       "      <td>author help</td>\n",
       "      <td>economics health</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>344586</td>\n",
       "      <td>206620</td>\n",
       "      <td>fonction</td>\n",
       "      <td>anova fonction</td>\n",
       "      <td>lm fonction</td>\n",
       "      <td>lm</td>\n",
       "      <td>avoid overpramatizing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>344587</td>\n",
       "      <td>207096</td>\n",
       "      <td>probability</td>\n",
       "      <td>probability density</td>\n",
       "      <td>density function</td>\n",
       "      <td>density</td>\n",
       "      <td>function</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>344588</td>\n",
       "      <td>198848</td>\n",
       "      <td>sufficient estimator</td>\n",
       "      <td>bernoulli</td>\n",
       "      <td>binomial distributions</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>textbook</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>344589</td>\n",
       "      <td>206947</td>\n",
       "      <td>spss</td>\n",
       "      <td>come instruction</td>\n",
       "      <td>downloaded plugin</td>\n",
       "      <td>fully motivated</td>\n",
       "      <td>instruction spss</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>344592</td>\n",
       "      <td>96600</td>\n",
       "      <td>area posterior</td>\n",
       "      <td>axis reasonable</td>\n",
       "      <td>direction observed</td>\n",
       "      <td>does unable</td>\n",
       "      <td>effect opposite</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>344593</td>\n",
       "      <td>206570</td>\n",
       "      <td>gain lift</td>\n",
       "      <td>lift used</td>\n",
       "      <td>metrics auc</td>\n",
       "      <td>score gain</td>\n",
       "      <td>different evaluation</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>344594</td>\n",
       "      <td>207118</td>\n",
       "      <td>neurons</td>\n",
       "      <td>basis</td>\n",
       "      <td>inputs</td>\n",
       "      <td>correlations</td>\n",
       "      <td>basing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>344595</td>\n",
       "      <td>230</td>\n",
       "      <td>example unsupervised</td>\n",
       "      <td>unsupervised learning</td>\n",
       "      <td>simple example</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>learning</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>344596</td>\n",
       "      <td>207021</td>\n",
       "      <td>plant</td>\n",
       "      <td>host</td>\n",
       "      <td>dodder</td>\n",
       "      <td>host plant</td>\n",
       "      <td>dodder plant</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>344597</td>\n",
       "      <td>207096</td>\n",
       "      <td>estimating</td>\n",
       "      <td>clustering meta</td>\n",
       "      <td>clusters estimating</td>\n",
       "      <td>density estimating</td>\n",
       "      <td>estimating density</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>344598</td>\n",
       "      <td>207058</td>\n",
       "      <td>series</td>\n",
       "      <td>paper</td>\n",
       "      <td>time series</td>\n",
       "      <td>time</td>\n",
       "      <td>forecasting</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>344599</td>\n",
       "      <td>207096</td>\n",
       "      <td>spaces</td>\n",
       "      <td>probability measures</td>\n",
       "      <td>functions probability</td>\n",
       "      <td>finite dimensional</td>\n",
       "      <td>discrete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>344600</td>\n",
       "      <td>163114</td>\n",
       "      <td>dickey fuller</td>\n",
       "      <td>dickey</td>\n",
       "      <td>fuller</td>\n",
       "      <td>fuller test</td>\n",
       "      <td>test stata</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>344601</td>\n",
       "      <td>207099</td>\n",
       "      <td>possible wilcox</td>\n",
       "      <td>check sample</td>\n",
       "      <td>different possible</td>\n",
       "      <td>wilcox test</td>\n",
       "      <td>sample normal</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>344602</td>\n",
       "      <td>121522</td>\n",
       "      <td>logistic</td>\n",
       "      <td>logistic tag</td>\n",
       "      <td>number relevant</td>\n",
       "      <td>relevant questions</td>\n",
       "      <td>tag number</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>344604</td>\n",
       "      <td>161278</td>\n",
       "      <td>effects limited</td>\n",
       "      <td>existing mean</td>\n",
       "      <td>matrix existing</td>\n",
       "      <td>permanent effect</td>\n",
       "      <td>matter variable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>344605</td>\n",
       "      <td>207126</td>\n",
       "      <td>pasta</td>\n",
       "      <td>anova tukeys</td>\n",
       "      <td>apologies incorrectly</td>\n",
       "      <td>batches pasta</td>\n",
       "      <td>cooking anova</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>344607</td>\n",
       "      <td>121270</td>\n",
       "      <td>rbms</td>\n",
       "      <td>networks</td>\n",
       "      <td>hopfield nets</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>hinton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>344608</td>\n",
       "      <td>191681</td>\n",
       "      <td>hessian</td>\n",
       "      <td>approximate hessian</td>\n",
       "      <td>dealing hessian</td>\n",
       "      <td>trying approximate</td>\n",
       "      <td>bfgs</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>344609</td>\n",
       "      <td>127538</td>\n",
       "      <td>spikes</td>\n",
       "      <td>tsclean</td>\n",
       "      <td>winsorization</td>\n",
       "      <td>dummy variables</td>\n",
       "      <td>explainable</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>344610</td>\n",
       "      <td>207128</td>\n",
       "      <td>normality</td>\n",
       "      <td>dismiss assumption</td>\n",
       "      <td>know violate</td>\n",
       "      <td>know wilcox</td>\n",
       "      <td>lt dismiss</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19725 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  user_id                  TopWord1                 TopWord2  \\\n",
       "0       317697   134975   variables statistically             mixed effect   \n",
       "1       317699    45374                  accuracy      validation accuracy   \n",
       "2       317701   171235                   freedom                     mean   \n",
       "3       317703   187797                  patients                 treating   \n",
       "4       317704    61496               uncertainty               error ways   \n",
       "5       317705   134369     bonferroni correction               bonferroni   \n",
       "6       317707   187792   environmental variables                   traits   \n",
       "7       317708    82816        solve differential    equation distribution   \n",
       "8       317710    61092  monotonically increasing            monotonically   \n",
       "9       317711   179343          affect specified             shock affect   \n",
       "10      317712    67137                      simr                able edit   \n",
       "11      317713    67137        measures construct                    power   \n",
       "12      317716   187803        terms applications       difference poisson   \n",
       "13      317717   113090                 graphical         graphical models   \n",
       "14      317718    80922                 recurrent           deep recurrent   \n",
       "15      317719   187804                    person                young old   \n",
       "16      317721   177228              intervention         male respondents   \n",
       "17      317722   187806                      fans                     band   \n",
       "18      317723     8123      distinguishes legged                   legged   \n",
       "19      317724   117168                     block               resampling   \n",
       "20      317725   185581                rows small       corresponding rows   \n",
       "21      317727   117168                     block                   blocks   \n",
       "22      317728   187809                 subscribe                   mining   \n",
       "23      317729    31484         beta distribution                     beta   \n",
       "24      317730   111479               eigenvector                     grey   \n",
       "25      317731      805                      beta                 gaussian   \n",
       "26      317732    88727                    signal                    bound   \n",
       "27      317733   131977            don understand  architecture explaining   \n",
       "28      317734   187810              intervention                   signal   \n",
       "29      317735     8402         denote noncentral           derived theory   \n",
       "...        ...      ...                       ...                      ...   \n",
       "19970   344573    94586              tree species                  species   \n",
       "19971   344574   105149                   college       college highschool   \n",
       "19972   344575   136275                      mean                 use mean   \n",
       "19973   344578   163648            number correct          correct answers   \n",
       "19974   344579   207112               equal equal    distribution variable   \n",
       "19975   344580   195935                     model                     mean   \n",
       "19976   344581   195935      pairwise comparisons                 pairwise   \n",
       "19977   344583   195935          assume continous            binary models   \n",
       "19978   344585   207115    instrumental variables             instrumental   \n",
       "19979   344586   206620                  fonction           anova fonction   \n",
       "19980   344587   207096               probability      probability density   \n",
       "19981   344588   198848      sufficient estimator                bernoulli   \n",
       "19982   344589   206947                      spss         come instruction   \n",
       "19983   344592    96600            area posterior          axis reasonable   \n",
       "19984   344593   206570                 gain lift                lift used   \n",
       "19985   344594   207118                   neurons                    basis   \n",
       "19986   344595      230      example unsupervised    unsupervised learning   \n",
       "19987   344596   207021                     plant                     host   \n",
       "19988   344597   207096                estimating          clustering meta   \n",
       "19989   344598   207058                    series                    paper   \n",
       "19990   344599   207096                    spaces     probability measures   \n",
       "19991   344600   163114             dickey fuller                   dickey   \n",
       "19992   344601   207099           possible wilcox             check sample   \n",
       "19993   344602   121522                  logistic             logistic tag   \n",
       "19994   344604   161278           effects limited            existing mean   \n",
       "19995   344605   207126                     pasta             anova tukeys   \n",
       "19996   344607   121270                      rbms                 networks   \n",
       "19997   344608   191681                   hessian      approximate hessian   \n",
       "19998   344609   127538                    spikes                  tsclean   \n",
       "19999   344610   207128                 normality       dismiss assumption   \n",
       "\n",
       "                     TopWord3                TopWord4  \\\n",
       "0                       mixed               variables   \n",
       "1           training accuracy                 shallow   \n",
       "2             degrees freedom                 degrees   \n",
       "3                       excel                   treat   \n",
       "4          estimate realistic         forecast method   \n",
       "5                  correction                outliers   \n",
       "6               environmental            plant traits   \n",
       "7       differential equation              need solve   \n",
       "8              differentiable              increasing   \n",
       "9            understand shock                    prof   \n",
       "10            deciding sample              edit turns   \n",
       "11                   measures        outcome measures   \n",
       "12              process terms          process markov   \n",
       "13                 log linear                  models   \n",
       "14             neural network        recurrent neural   \n",
       "15                      young                     old   \n",
       "16          intervention time             respondents   \n",
       "17                   universe        overall universe   \n",
       "18                  old style           seek opinions   \n",
       "19                     series                  blocks   \n",
       "20                 constraint            matrix shape   \n",
       "21          block observation                resample   \n",
       "22              brief ideally      customer subscribe   \n",
       "23         distribution prove               look beta   \n",
       "24                 components              eigenvalue   \n",
       "25             symmetric beta               symmetric   \n",
       "26            bound saturated        channel variance   \n",
       "27         concatenate inputs               deep mind   \n",
       "28                     events         external events   \n",
       "29                  don proof           ingersoll ros   \n",
       "...                       ...                     ...   \n",
       "19970                    tree                   crown   \n",
       "19971              highschool          student answer   \n",
       "19972                test set                    test   \n",
       "19973              let number             high school   \n",
       "19974     function parameters          interpretation   \n",
       "19975       application model        baseline renders   \n",
       "19976             comparisons      ability explicitly   \n",
       "19977        combining binary  continous distribution   \n",
       "19978    accounting political             author help   \n",
       "19979             lm fonction                      lm   \n",
       "19980        density function                 density   \n",
       "19981  binomial distributions              sufficient   \n",
       "19982       downloaded plugin         fully motivated   \n",
       "19983      direction observed             does unable   \n",
       "19984             metrics auc              score gain   \n",
       "19985                  inputs            correlations   \n",
       "19986          simple example            unsupervised   \n",
       "19987                  dodder              host plant   \n",
       "19988     clusters estimating      density estimating   \n",
       "19989             time series                    time   \n",
       "19990   functions probability      finite dimensional   \n",
       "19991                  fuller             fuller test   \n",
       "19992      different possible             wilcox test   \n",
       "19993         number relevant      relevant questions   \n",
       "19994         matrix existing        permanent effect   \n",
       "19995   apologies incorrectly           batches pasta   \n",
       "19996           hopfield nets                hopfield   \n",
       "19997         dealing hessian      trying approximate   \n",
       "19998           winsorization         dummy variables   \n",
       "19999            know violate             know wilcox   \n",
       "\n",
       "                        TopWord5  Community  \n",
       "0      statistically significant         42  \n",
       "1                     validation        145  \n",
       "2                    data degree        140  \n",
       "3                  bias treating          1  \n",
       "4                  predicts time          1  \n",
       "5                 don understand        120  \n",
       "6                          plant         92  \n",
       "7               distribution pdf          1  \n",
       "8        assuming differentiable          1  \n",
       "9                          shock          1  \n",
       "10                effect variety         -1  \n",
       "11       multivariate regression        136  \n",
       "12                markov process          1  \n",
       "13                           log        148  \n",
       "14                        neural        102  \n",
       "15                 age indicator        137  \n",
       "16                          male         70  \n",
       "17                        cities          1  \n",
       "18                   recognition          1  \n",
       "19                      resample         50  \n",
       "20                           row          1  \n",
       "21                  fourth block          1  \n",
       "22            incorporate mining          1  \n",
       "23                    prove beta          1  \n",
       "24                     variables         42  \n",
       "25                 beta gaussian          1  \n",
       "26        deriving relationships          1  \n",
       "27              explaining works          1  \n",
       "28                      external         70  \n",
       "29                   proof prove         -1  \n",
       "...                          ...        ...  \n",
       "19970                      lidar        119  \n",
       "19971         correctly question          1  \n",
       "19972                  mean test         17  \n",
       "19973                    let let          1  \n",
       "19974                 parameters        118  \n",
       "19975         building important         16  \n",
       "19976          addition pairwise          1  \n",
       "19977           decisions assume         -1  \n",
       "19978           economics health          1  \n",
       "19979      avoid overpramatizing          1  \n",
       "19980                   function         59  \n",
       "19981                   textbook        118  \n",
       "19982           instruction spss        135  \n",
       "19983            effect opposite         -1  \n",
       "19984       different evaluation         -1  \n",
       "19985                     basing          1  \n",
       "19986                   learning         64  \n",
       "19987               dodder plant        144  \n",
       "19988         estimating density          1  \n",
       "19989                forecasting         50  \n",
       "19990                   discrete          1  \n",
       "19991                 test stata         32  \n",
       "19992              sample normal         26  \n",
       "19993                 tag number        147  \n",
       "19994            matter variable         -1  \n",
       "19995              cooking anova         -1  \n",
       "19996                     hinton          1  \n",
       "19997                       bfgs        118  \n",
       "19998                explainable        133  \n",
       "19999                 lt dismiss        118  \n",
       "\n",
       "[19725 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df_w_comm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community: 0 Size: 87\n",
      "Community: 1 Size: 8343\n",
      "Community: 2 Size: 2\n",
      "Community: 3 Size: 2\n",
      "Community: 4 Size: 2\n",
      "Community: 5 Size: 2\n",
      "Community: 6 Size: 2\n",
      "Community: 7 Size: 2\n",
      "Community: 8 Size: 2\n",
      "Community: 9 Size: 2\n",
      "Community: 10 Size: 2\n",
      "Community: 11 Size: 2\n",
      "Community: 12 Size: 2\n",
      "Community: 13 Size: 2\n",
      "Community: 14 Size: 2\n",
      "Community: 15 Size: 3\n",
      "Community: 16 Size: 169\n",
      "Community: 17 Size: 200\n",
      "Community: 18 Size: 8\n",
      "Community: 19 Size: 7\n",
      "Community: 20 Size: 2\n",
      "Community: 21 Size: 2\n",
      "Community: 22 Size: 2\n",
      "Community: 23 Size: 4\n",
      "Community: 24 Size: 2\n",
      "Community: 25 Size: 2\n",
      "Community: 26 Size: 5\n",
      "Community: 27 Size: 2\n",
      "Community: 28 Size: 2\n",
      "Community: 29 Size: 2\n",
      "Community: 30 Size: 29\n",
      "Community: 31 Size: 2\n",
      "Community: 32 Size: 4\n",
      "Community: 33 Size: 5\n",
      "Community: 34 Size: 2\n",
      "Community: 35 Size: 3\n",
      "Community: 36 Size: 2\n",
      "Community: 37 Size: 2\n",
      "Community: 38 Size: 6\n",
      "Community: 39 Size: 2\n",
      "Community: 40 Size: 2\n",
      "Community: 41 Size: 2\n",
      "Community: 42 Size: 109\n",
      "Community: 43 Size: 65\n",
      "Community: 44 Size: 2\n",
      "Community: 45 Size: 2\n",
      "Community: 46 Size: 2\n",
      "Community: 47 Size: 2\n",
      "Community: 48 Size: 2\n",
      "Community: 49 Size: 2\n",
      "Community: 50 Size: 222\n",
      "Community: 51 Size: 6\n",
      "Community: 52 Size: 4\n",
      "Community: 53 Size: 2\n",
      "Community: 54 Size: 145\n",
      "Community: 55 Size: 6\n",
      "Community: 56 Size: 67\n",
      "Community: 57 Size: 2\n",
      "Community: 58 Size: 114\n",
      "Community: 59 Size: 89\n",
      "Community: 60 Size: 50\n",
      "Community: 61 Size: 26\n",
      "Community: 62 Size: 2\n",
      "Community: 63 Size: 3\n",
      "Community: 64 Size: 73\n",
      "Community: 65 Size: 18\n",
      "Community: 66 Size: 206\n",
      "Community: 67 Size: 114\n",
      "Community: 68 Size: 84\n",
      "Community: 69 Size: 49\n",
      "Community: 70 Size: 42\n",
      "Community: 71 Size: 3\n",
      "Community: 72 Size: 84\n",
      "Community: 73 Size: 87\n",
      "Community: 74 Size: 21\n",
      "Community: 75 Size: 5\n",
      "Community: 76 Size: 58\n",
      "Community: 77 Size: 102\n",
      "Community: 78 Size: 104\n",
      "Community: 79 Size: 3\n",
      "Community: 80 Size: 6\n",
      "Community: 81 Size: 3\n",
      "Community: 82 Size: 53\n",
      "Community: 83 Size: 38\n",
      "Community: 84 Size: 120\n",
      "Community: 85 Size: 2\n",
      "Community: 86 Size: 50\n",
      "Community: 87 Size: 91\n",
      "Community: 88 Size: 79\n",
      "Community: 89 Size: 72\n",
      "Community: 90 Size: 13\n",
      "Community: 91 Size: 55\n",
      "Community: 92 Size: 19\n",
      "Community: 93 Size: 83\n",
      "Community: 94 Size: 8\n",
      "Community: 95 Size: 110\n",
      "Community: 96 Size: 72\n",
      "Community: 97 Size: 60\n",
      "Community: 98 Size: 2\n",
      "Community: 99 Size: 45\n",
      "Community: 100 Size: 128\n",
      "Community: 101 Size: 70\n",
      "Community: 102 Size: 246\n",
      "Community: 103 Size: 68\n",
      "Community: 104 Size: 16\n",
      "Community: 105 Size: 116\n",
      "Community: 106 Size: 27\n",
      "Community: 107 Size: 121\n",
      "Community: 108 Size: 112\n",
      "Community: 109 Size: 132\n",
      "Community: 110 Size: 80\n",
      "Community: 111 Size: 92\n",
      "Community: 112 Size: 6\n",
      "Community: 113 Size: 26\n",
      "Community: 114 Size: 82\n",
      "Community: 115 Size: 27\n",
      "Community: 116 Size: 73\n",
      "Community: 117 Size: 130\n",
      "Community: 118 Size: 1037\n",
      "Community: 119 Size: 106\n",
      "Community: 120 Size: 35\n",
      "Community: 121 Size: 55\n",
      "Community: 122 Size: 130\n",
      "Community: 123 Size: 184\n",
      "Community: 124 Size: 90\n",
      "Community: 125 Size: 48\n",
      "Community: 126 Size: 42\n",
      "Community: 127 Size: 77\n",
      "Community: 128 Size: 25\n",
      "Community: 129 Size: 42\n",
      "Community: 130 Size: 90\n",
      "Community: 131 Size: 88\n",
      "Community: 132 Size: 35\n",
      "Community: 133 Size: 44\n",
      "Community: 134 Size: 127\n",
      "Community: 135 Size: 180\n",
      "Community: 136 Size: 27\n",
      "Community: 137 Size: 175\n",
      "Community: 138 Size: 48\n",
      "Community: 139 Size: 5\n",
      "Community: 140 Size: 210\n",
      "Community: 141 Size: 34\n",
      "Community: 142 Size: 2\n",
      "Community: 143 Size: 18\n",
      "Community: 144 Size: 81\n",
      "Community: 145 Size: 301\n",
      "Community: 146 Size: 122\n",
      "Community: 147 Size: 156\n",
      "Community: 148 Size: 48\n",
      "Community: 149 Size: 38\n",
      "Community: -1 Size: 2586\n"
     ]
    }
   ],
   "source": [
    "communities2 = set(post_df_w_comm2[\"Community\"])\n",
    "for comm in communities2:\n",
    "    print \"Community:\", comm, \"Size:\", len(post_df2[post_df_w_comm2[\"Community\"] == comm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency in communities2\n",
    "word_counts2 = collections.defaultdict(dict)\n",
    "word_freqs2 = collections.defaultdict(dict)\n",
    "for comm in communities2:\n",
    "    total_words = 0.0\n",
    "    word_counts2[comm] = collections.defaultdict(int)\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord1']:\n",
    "        word_counts2[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord2']:\n",
    "        word_counts2[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord3']:\n",
    "        word_counts2[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord4']:\n",
    "        word_counts2[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord5']:\n",
    "        word_counts2[comm][word] += 1\n",
    "        total_words += 1\n",
    "    for word in word_counts2[comm]:\n",
    "        word_freqs2[comm][word] = word_counts2[comm][word] / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 8343, 42.29657794676806, 'feature|dataset|value'),\n",
       " (118, 1037, 5.257287705956908, 'density|normal|parameter'),\n",
       " (145, 301, 1.525982256020279, 'training|validation|data'),\n",
       " (102, 246, 1.247148288973384, 'network|cost|event'),\n",
       " (50, 222, 1.1254752851711027, 'series|time|time series'),\n",
       " (140, 210, 1.064638783269962, 'sample|population|mean'),\n",
       " (66, 206, 1.044359949302915, 'distribution|normal distribution|probability'),\n",
       " (17, 200, 1.0139416983523448, 'test|test set|test statistic'),\n",
       " (123, 184, 0.9328263624841572, 'stationary|process|acf'),\n",
       " (135, 180, 0.9125475285171103, 'distributions|aic|gamma'),\n",
       " (137, 175, 0.8871989860583016, 'weights|interaction|level'),\n",
       " (16, 169, 0.8567807351077313, 'model|fit|validation'),\n",
       " (147, 156, 0.7908745247148289, 'regression|logistic|ordinal'),\n",
       " (54, 145, 0.7351077313054499, 'matrix|covariance matrix|covariance'),\n",
       " (109, 132, 0.6692015209125475, 'state|policy|action'),\n",
       " (117, 130, 0.6590621039290241, 'frac|lambda|hat'),\n",
       " (122, 130, 0.6590621039290241, 'word|words|embedding'),\n",
       " (100, 128, 0.6489226869455006, 'clusters|cluster|clustering'),\n",
       " (134, 127, 0.6438529784537389, 'score|game|team'),\n",
       " (146, 122, 0.6185044359949303, 'points|line|mse'),\n",
       " (107, 121, 0.6134347275031685, 'values|missing|imputation'),\n",
       " (84, 120, 0.6083650190114068, 'layer|layers|hidden'),\n",
       " (105, 116, 0.5880861850443599, 'error|standard|standard error'),\n",
       " (58, 114, 0.5779467680608364, 'group|treatment|groups'),\n",
       " (67, 114, 0.5779467680608364, 'correlation|pearson|pearson correlation'),\n",
       " (108, 112, 0.5678073510773131, 'treatment|treatments|control'),\n",
       " (95, 110, 0.5576679340937896, 'features|feature|feature selection'),\n",
       " (42, 109, 0.5525982256020279, 'variables|categorical variables|categorical'),\n",
       " (119, 106, 0.5373891001267427, 'tree|forest|trees'),\n",
       " (78, 104, 0.5272496831432193, 'class|classes|class class'),\n",
       " (77, 102, 0.5171102661596958, 'confidence|interval|confidence interval'),\n",
       " (111, 92, 0.4664131812420786, 'image|images|cnn'),\n",
       " (87, 91, 0.46134347275031684, 'amp|amp amp|frac'),\n",
       " (124, 90, 0.45627376425855515, 'day|week|days'),\n",
       " (130, 90, 0.45627376425855515, 'measurements|measurement|stan'),\n",
       " (59,\n",
       "  89,\n",
       "  0.4512040557667934,\n",
       "  'probability|conditional probability|probability density'),\n",
       " (131, 88, 0.4461343472750317, 'equation|begin equation|end equation'),\n",
       " (0, 87, 0.44106463878326996, 'likelihood|log likelihood|likelihood function'),\n",
       " (73, 87, 0.44106463878326996, 'variance|sample variance|sample'),\n",
       " (68, 84, 0.42585551330798477, 'items|item|user'),\n",
       " (72, 84, 0.42585551330798477, 'variable|random|random variable'),\n",
       " (93, 83, 0.4207858048162231, 'estimator|unbiased|ols'),\n",
       " (114, 82, 0.4157160963244613, 'loss|loss function|reconstruction'),\n",
       " (144, 81, 0.41064638783269963, 'distance|species|abundance'),\n",
       " (110, 80, 0.4055766793409379, 'effect|effect size|size'),\n",
       " (88, 79, 0.4005069708491762, 'cell|convolution|memory'),\n",
       " (127, 77, 0.39036755386565275, 'effects|random effects|fixed effects'),\n",
       " (64, 73, 0.3700887198986058, 'learning|deep learning|rate'),\n",
       " (116, 73, 0.3700887198986058, 'odds|odds ratio|ratio'),\n",
       " (89, 72, 0.3650190114068441, 'prior|posterior|priors'),\n",
       " (96, 72, 0.3650190114068441, 'roc|auc|curve'),\n",
       " (101, 70, 0.3548795944233207, 'gradient|descent|gradient descent'),\n",
       " (103,\n",
       "  68,\n",
       "  0.34474017743979724,\n",
       "  'sequence|convergence|convergence probability'),\n",
       " (56, 67, 0.3396704689480355, 'kernel|kernels|density'),\n",
       " (43, 65, 0.32953105196451205, 'arima|arima model|seasonal'),\n",
       " (97, 60, 0.3041825095057034, 'lasso|ridge|ridge regression'),\n",
       " (76, 58, 0.29404309252217997, 'age|mother|gender'),\n",
       " (91, 55, 0.2788339670468948, 'pca|robust pca|robust'),\n",
       " (121, 55, 0.2788339670468948, 'sales|stores|store'),\n",
       " (82, 53, 0.26869455006337134, 'survival|hazard|survival rate'),\n",
       " (60, 50, 0.2534854245880862, 'year|year year|years'),\n",
       " (86, 50, 0.2534854245880862, 'factor|factors|factor analysis'),\n",
       " (69, 49, 0.24841571609632446, 'entropy|cross entropy|joint'),\n",
       " (125, 48, 0.24334600760456274, 'anova|table|iv2'),\n",
       " (138, 48, 0.24334600760456274, 'square|chi square|goodness fit'),\n",
       " (148, 48, 0.24334600760456274, 'log|log normal|log log'),\n",
       " (99, 45, 0.22813688212927757, 'red|balls|ball'),\n",
       " (133, 44, 0.22306717363751585, 'dummy|dummy variables|dummies'),\n",
       " (70, 42, 0.21292775665399238, 'intervention|standard deviation|covariates'),\n",
       " (126, 42, 0.21292775665399238, 'bayes|naive bayes|naive'),\n",
       " (129,\n",
       "  42,\n",
       "  0.21292775665399238,\n",
       "  'independent|independent variable|independent variables'),\n",
       " (83, 38, 0.1926489226869455, 'integral|density|substitution'),\n",
       " (149, 38, 0.1926489226869455, 'heads|coin|fair'),\n",
       " (120, 35, 0.17743979721166034, 'correction|bonferroni|yates correction'),\n",
       " (132, 35, 0.17743979721166034, 'outliers|outlier|seasonal'),\n",
       " (141, 34, 0.17237008871989862, 'meta|meta analysis|studies'),\n",
       " (30, 29, 0.14702154626108999, 'inequality|chebyshev|chebyshev inequality'),\n",
       " (106, 27, 0.13688212927756654, 'logit|logit model|conditional logit'),\n",
       " (115, 27, 0.13688212927756654, 'customer|customers|ltv'),\n",
       " (136, 27, 0.13688212927756654, 'power|power analysis|effect size'),\n",
       " (61, 26, 0.13181242078580482, 'income|person years|dollar'),\n",
       " (113, 26, 0.13181242078580482, 'monte|monte carlo|carlo'),\n",
       " (128, 25, 0.1267427122940431, 'lt|lt lt|ci'),\n",
       " (74, 21, 0.10646387832699619, 'pattern|agent|falling'),\n",
       " (92, 19, 0.09632446134347275, 'course|environmental|traits'),\n",
       " (65, 18, 0.09125475285171103, 'statement|htm|vertical profile'),\n",
       " (143, 18, 0.09125475285171103, 'proof|ideas|subset'),\n",
       " (104, 16, 0.08111533586818757, 'audio|recorded|sound'),\n",
       " (90, 13, 0.06590621039290241, 'minutes|average mpg|people'),\n",
       " (18, 8, 0.04055766793409379, 'let|mean bu|continued strictly'),\n",
       " (94, 8, 0.04055766793409379, 'tutorial|hope helps|definite model'),\n",
       " (19, 7, 0.035487959442332066, 'near|ratio near|convergence deeper'),\n",
       " (38, 6, 0.030418250950570342, 'derive|know derive|intercept simple'),\n",
       " (51, 6, 0.030418250950570342, 'dots|slid|following plot'),\n",
       " (55, 6, 0.030418250950570342, 'religion|islam|religiosity'),\n",
       " (80, 6, 0.030418250950570342, 'chapter|chapter gmm|containing chapter'),\n",
       " (112, 6, 0.030418250950570342, 'understand|proceed|paper understand'),\n",
       " (26, 5, 0.025348542458808618, 'wilcox|wilcox test|sums version'),\n",
       " (33, 5, 0.025348542458808618, 'https github|github com|com'),\n",
       " (75, 5, 0.025348542458808618, 'aggregated|attacks|mcfadden'),\n",
       " (139, 5, 0.025348542458808618, 'predator|prey|aquatic'),\n",
       " (23, 4, 0.020278833967046894, 'orange|vitamin|linux'),\n",
       " (32, 4, 0.020278833967046894, 'dickey fuller|fuller|dickey'),\n",
       " (52, 4, 0.020278833967046894, 'electricity|electricity used|homes'),\n",
       " (15, 3, 0.015209125475285171, 'rcpp|loops|current value'),\n",
       " (35, 3, 0.015209125475285171, 'nest|common materials|lastalive'),\n",
       " (63, 3, 0.015209125475285171, 'hypertension|history family|having headache'),\n",
       " (71, 3, 0.015209125475285171, 'intuitive|grasph like|intuitive explanation'),\n",
       " (79, 3, 0.015209125475285171, 'beta3|decaying|implicit conditions'),\n",
       " (81, 3, 0.015209125475285171, 'payment|booking|booking cancelled'),\n",
       " (2, 2, 0.010139416983523447, 'stuck|suppose hypotheses|able stuck'),\n",
       " (3,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'structure coefficients|corville|additionally sure'),\n",
       " (4, 2, 0.010139416983523447, 'geo|thrown getting|coin thrown'),\n",
       " (5, 2, 0.010139416983523447, 'advice|functions image|variance group'),\n",
       " (6,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'convolution quite|quite nicely|nicely different'),\n",
       " (7, 2, 0.010139416983523447, 'nrow|partykit|matrix nrow'),\n",
       " (8, 2, 0.010139416983523447, 'result general|general finally|methods ok'),\n",
       " (9,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'covariance variable|equivalent variance|equals variance'),\n",
       " (10, 2, 0.010139416983523447, 'donors|lapsed|frequency donations'),\n",
       " (11,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'distributed random|having exponential|convergeges'),\n",
       " (12, 2, 0.010139416983523447, 'grain|mineral|assume grain'),\n",
       " (13, 2, 0.010139416983523447, 'tso|lets nn1|tso function'),\n",
       " (14, 2, 0.010139416983523447, 'explain does|estimation come|does maximum'),\n",
       " (20, 2, 0.010139416983523447, 'factor1|factor2|according factor2'),\n",
       " (21, 2, 0.010139416983523447, 'key|variable placed|current key'),\n",
       " (22, 2, 0.010139416983523447, 'rmsep|lowest rmsep|command validation'),\n",
       " (24, 2, 0.010139416983523447, 'tax|property tax|tax size'),\n",
       " (25, 2, 0.010139416983523447, 'km curve|mean km|correct job'),\n",
       " (27,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'tests sampling|assumptions large|assumptions amp'),\n",
       " (28, 2, 0.010139416983523447, 'map2|change map2|argument change'),\n",
       " (29, 2, 0.010139416983523447, 'ip|ip port|wq'),\n",
       " (31,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'variable following|distribution suppose|property probability'),\n",
       " (34, 2, 0.010139416983523447, 'ed|distributions ed|budgetary'),\n",
       " (36, 2, 0.010139416983523447, 'armax|actually end|armax model'),\n",
       " (37, 2, 0.010139416983523447, 'independent measures|anova scores|violating'),\n",
       " (39, 2, 0.010139416983523447, 'case increase|given increasing|path says'),\n",
       " (40,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'realistic|realistic subjects|exponentiate result'),\n",
       " (41,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'consultation|care treatment|bothering consult'),\n",
       " (44, 2, 0.010139416983523447, 'effects logistic|idre|factor mixed'),\n",
       " (45, 2, 0.010139416983523447, 'subscript|gamma just|operator parentheses'),\n",
       " (46, 2, 0.010139416983523447, 'group comparison|trt2|comparison procedure'),\n",
       " (47, 2, 0.010139416983523447, 'berry esseen|berry|esseen'),\n",
       " (48, 2, 0.010139416983523447, 'wondering value|know place|place firstly'),\n",
       " (49,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'random component|component actually|complex stochastic'),\n",
       " (53,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'coefficient simple|work difference|coefficients refer'),\n",
       " (57,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'samples groups|error anova|groups similarities'),\n",
       " (62,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'condition area|anova condition|concentration subject'),\n",
       " (85, 2, 0.010139416983523447, 'attention|attention based|using attention'),\n",
       " (98,\n",
       "  2,\n",
       "  0.010139416983523447,\n",
       "  'using boruta|meaning interpret|correctly feature'),\n",
       " (142, 2, 0.010139416983523447, 'unclear vague|scope use|tags instead')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_freqs2 = collections.defaultdict(dict)\n",
    "for comm in word_freqs2:\n",
    "    sorted_word_freqs2[comm] = sorted(word_freqs2[comm].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "community_labels2 = collections.defaultdict(str) \n",
    "\n",
    "for ind, comm in enumerate(sorted_word_freqs2):\n",
    "    community_labels2[comm] = \"{}|{}|{}\".format(sorted_word_freqs2[comm][0][0], sorted_word_freqs2[comm][1][0], sorted_word_freqs2[comm][2][0])\n",
    "\n",
    "# for comm in communities2:\n",
    "#     print \"Community: {:3}  Size: {:5}  Label: {}\".format(comm, len(post_df[post_df_w_comm2[\"Community\"] == comm]), community_labels2[comm])\n",
    "    \n",
    "rankings2 = []\n",
    "\n",
    "for comm in communities2:\n",
    "    if comm == -1: continue\n",
    "#     print \"Community: {:3}  Size: {:5}  Proportion: {:.8f}  Label: {}\".format(comm, len(post_df[post_df_w_comm[\"Community\"] == comm]), len(post_df[post_df_w_comm[\"Community\"] == comm]) / float(len(post_df)), community_labels[comm])\n",
    "    rankings2.append((comm, len(post_df2[post_df_w_comm2[\"Community\"] == comm]), 100.0 * len(post_df2[post_df_w_comm2[\"Community\"] == comm]) / len(post_df2), community_labels2[comm]))\n",
    "    \n",
    "rankings2.sort(key=lambda x: x[2], reverse = True)\n",
    "rankings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "      <th>Community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317697</td>\n",
       "      <td>134975</td>\n",
       "      <td>variables statistically</td>\n",
       "      <td>mixed effect</td>\n",
       "      <td>mixed</td>\n",
       "      <td>variables</td>\n",
       "      <td>statistically significant</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317699</td>\n",
       "      <td>45374</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>validation accuracy</td>\n",
       "      <td>training accuracy</td>\n",
       "      <td>shallow</td>\n",
       "      <td>validation</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317701</td>\n",
       "      <td>171235</td>\n",
       "      <td>freedom</td>\n",
       "      <td>mean</td>\n",
       "      <td>degrees freedom</td>\n",
       "      <td>degrees</td>\n",
       "      <td>data degree</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317703</td>\n",
       "      <td>187797</td>\n",
       "      <td>patients</td>\n",
       "      <td>treating</td>\n",
       "      <td>excel</td>\n",
       "      <td>treat</td>\n",
       "      <td>bias treating</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317704</td>\n",
       "      <td>61496</td>\n",
       "      <td>uncertainty</td>\n",
       "      <td>error ways</td>\n",
       "      <td>estimate realistic</td>\n",
       "      <td>forecast method</td>\n",
       "      <td>predicts time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>317705</td>\n",
       "      <td>134369</td>\n",
       "      <td>bonferroni correction</td>\n",
       "      <td>bonferroni</td>\n",
       "      <td>correction</td>\n",
       "      <td>outliers</td>\n",
       "      <td>don understand</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>317707</td>\n",
       "      <td>187792</td>\n",
       "      <td>environmental variables</td>\n",
       "      <td>traits</td>\n",
       "      <td>environmental</td>\n",
       "      <td>plant traits</td>\n",
       "      <td>plant</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>317708</td>\n",
       "      <td>82816</td>\n",
       "      <td>solve differential</td>\n",
       "      <td>equation distribution</td>\n",
       "      <td>differential equation</td>\n",
       "      <td>need solve</td>\n",
       "      <td>distribution pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>317710</td>\n",
       "      <td>61092</td>\n",
       "      <td>monotonically increasing</td>\n",
       "      <td>monotonically</td>\n",
       "      <td>differentiable</td>\n",
       "      <td>increasing</td>\n",
       "      <td>assuming differentiable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>317711</td>\n",
       "      <td>179343</td>\n",
       "      <td>affect specified</td>\n",
       "      <td>shock affect</td>\n",
       "      <td>understand shock</td>\n",
       "      <td>prof</td>\n",
       "      <td>shock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>317712</td>\n",
       "      <td>67137</td>\n",
       "      <td>simr</td>\n",
       "      <td>able edit</td>\n",
       "      <td>deciding sample</td>\n",
       "      <td>edit turns</td>\n",
       "      <td>effect variety</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>317713</td>\n",
       "      <td>67137</td>\n",
       "      <td>measures construct</td>\n",
       "      <td>power</td>\n",
       "      <td>measures</td>\n",
       "      <td>outcome measures</td>\n",
       "      <td>multivariate regression</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>317716</td>\n",
       "      <td>187803</td>\n",
       "      <td>terms applications</td>\n",
       "      <td>difference poisson</td>\n",
       "      <td>process terms</td>\n",
       "      <td>process markov</td>\n",
       "      <td>markov process</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>317717</td>\n",
       "      <td>113090</td>\n",
       "      <td>graphical</td>\n",
       "      <td>graphical models</td>\n",
       "      <td>log linear</td>\n",
       "      <td>models</td>\n",
       "      <td>log</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>317718</td>\n",
       "      <td>80922</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>deep recurrent</td>\n",
       "      <td>neural network</td>\n",
       "      <td>recurrent neural</td>\n",
       "      <td>neural</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>317719</td>\n",
       "      <td>187804</td>\n",
       "      <td>person</td>\n",
       "      <td>young old</td>\n",
       "      <td>young</td>\n",
       "      <td>old</td>\n",
       "      <td>age indicator</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>317721</td>\n",
       "      <td>177228</td>\n",
       "      <td>intervention</td>\n",
       "      <td>male respondents</td>\n",
       "      <td>intervention time</td>\n",
       "      <td>respondents</td>\n",
       "      <td>male</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>317722</td>\n",
       "      <td>187806</td>\n",
       "      <td>fans</td>\n",
       "      <td>band</td>\n",
       "      <td>universe</td>\n",
       "      <td>overall universe</td>\n",
       "      <td>cities</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>317723</td>\n",
       "      <td>8123</td>\n",
       "      <td>distinguishes legged</td>\n",
       "      <td>legged</td>\n",
       "      <td>old style</td>\n",
       "      <td>seek opinions</td>\n",
       "      <td>recognition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>317724</td>\n",
       "      <td>117168</td>\n",
       "      <td>block</td>\n",
       "      <td>resampling</td>\n",
       "      <td>series</td>\n",
       "      <td>blocks</td>\n",
       "      <td>resample</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>317725</td>\n",
       "      <td>185581</td>\n",
       "      <td>rows small</td>\n",
       "      <td>corresponding rows</td>\n",
       "      <td>constraint</td>\n",
       "      <td>matrix shape</td>\n",
       "      <td>row</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>317727</td>\n",
       "      <td>117168</td>\n",
       "      <td>block</td>\n",
       "      <td>blocks</td>\n",
       "      <td>block observation</td>\n",
       "      <td>resample</td>\n",
       "      <td>fourth block</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>317728</td>\n",
       "      <td>187809</td>\n",
       "      <td>subscribe</td>\n",
       "      <td>mining</td>\n",
       "      <td>brief ideally</td>\n",
       "      <td>customer subscribe</td>\n",
       "      <td>incorporate mining</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>317729</td>\n",
       "      <td>31484</td>\n",
       "      <td>beta distribution</td>\n",
       "      <td>beta</td>\n",
       "      <td>distribution prove</td>\n",
       "      <td>look beta</td>\n",
       "      <td>prove beta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>317730</td>\n",
       "      <td>111479</td>\n",
       "      <td>eigenvector</td>\n",
       "      <td>grey</td>\n",
       "      <td>components</td>\n",
       "      <td>eigenvalue</td>\n",
       "      <td>variables</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>317731</td>\n",
       "      <td>805</td>\n",
       "      <td>beta</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>symmetric beta</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>beta gaussian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>317732</td>\n",
       "      <td>88727</td>\n",
       "      <td>signal</td>\n",
       "      <td>bound</td>\n",
       "      <td>bound saturated</td>\n",
       "      <td>channel variance</td>\n",
       "      <td>deriving relationships</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>317733</td>\n",
       "      <td>131977</td>\n",
       "      <td>don understand</td>\n",
       "      <td>architecture explaining</td>\n",
       "      <td>concatenate inputs</td>\n",
       "      <td>deep mind</td>\n",
       "      <td>explaining works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>317734</td>\n",
       "      <td>187810</td>\n",
       "      <td>intervention</td>\n",
       "      <td>signal</td>\n",
       "      <td>events</td>\n",
       "      <td>external events</td>\n",
       "      <td>external</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>317735</td>\n",
       "      <td>8402</td>\n",
       "      <td>denote noncentral</td>\n",
       "      <td>derived theory</td>\n",
       "      <td>don proof</td>\n",
       "      <td>ingersoll ros</td>\n",
       "      <td>proof prove</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>344573</td>\n",
       "      <td>94586</td>\n",
       "      <td>tree species</td>\n",
       "      <td>species</td>\n",
       "      <td>tree</td>\n",
       "      <td>crown</td>\n",
       "      <td>lidar</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>344574</td>\n",
       "      <td>105149</td>\n",
       "      <td>college</td>\n",
       "      <td>college highschool</td>\n",
       "      <td>highschool</td>\n",
       "      <td>student answer</td>\n",
       "      <td>correctly question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>344575</td>\n",
       "      <td>136275</td>\n",
       "      <td>mean</td>\n",
       "      <td>use mean</td>\n",
       "      <td>test set</td>\n",
       "      <td>test</td>\n",
       "      <td>mean test</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>344578</td>\n",
       "      <td>163648</td>\n",
       "      <td>number correct</td>\n",
       "      <td>correct answers</td>\n",
       "      <td>let number</td>\n",
       "      <td>high school</td>\n",
       "      <td>let let</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>344579</td>\n",
       "      <td>207112</td>\n",
       "      <td>equal equal</td>\n",
       "      <td>distribution variable</td>\n",
       "      <td>function parameters</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>parameters</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>344580</td>\n",
       "      <td>195935</td>\n",
       "      <td>model</td>\n",
       "      <td>mean</td>\n",
       "      <td>application model</td>\n",
       "      <td>baseline renders</td>\n",
       "      <td>building important</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>344581</td>\n",
       "      <td>195935</td>\n",
       "      <td>pairwise comparisons</td>\n",
       "      <td>pairwise</td>\n",
       "      <td>comparisons</td>\n",
       "      <td>ability explicitly</td>\n",
       "      <td>addition pairwise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>344583</td>\n",
       "      <td>195935</td>\n",
       "      <td>assume continous</td>\n",
       "      <td>binary models</td>\n",
       "      <td>combining binary</td>\n",
       "      <td>continous distribution</td>\n",
       "      <td>decisions assume</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>344585</td>\n",
       "      <td>207115</td>\n",
       "      <td>instrumental variables</td>\n",
       "      <td>instrumental</td>\n",
       "      <td>accounting political</td>\n",
       "      <td>author help</td>\n",
       "      <td>economics health</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>344586</td>\n",
       "      <td>206620</td>\n",
       "      <td>fonction</td>\n",
       "      <td>anova fonction</td>\n",
       "      <td>lm fonction</td>\n",
       "      <td>lm</td>\n",
       "      <td>avoid overpramatizing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>344587</td>\n",
       "      <td>207096</td>\n",
       "      <td>probability</td>\n",
       "      <td>probability density</td>\n",
       "      <td>density function</td>\n",
       "      <td>density</td>\n",
       "      <td>function</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>344588</td>\n",
       "      <td>198848</td>\n",
       "      <td>sufficient estimator</td>\n",
       "      <td>bernoulli</td>\n",
       "      <td>binomial distributions</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>textbook</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>344589</td>\n",
       "      <td>206947</td>\n",
       "      <td>spss</td>\n",
       "      <td>come instruction</td>\n",
       "      <td>downloaded plugin</td>\n",
       "      <td>fully motivated</td>\n",
       "      <td>instruction spss</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>344592</td>\n",
       "      <td>96600</td>\n",
       "      <td>area posterior</td>\n",
       "      <td>axis reasonable</td>\n",
       "      <td>direction observed</td>\n",
       "      <td>does unable</td>\n",
       "      <td>effect opposite</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>344593</td>\n",
       "      <td>206570</td>\n",
       "      <td>gain lift</td>\n",
       "      <td>lift used</td>\n",
       "      <td>metrics auc</td>\n",
       "      <td>score gain</td>\n",
       "      <td>different evaluation</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>344594</td>\n",
       "      <td>207118</td>\n",
       "      <td>neurons</td>\n",
       "      <td>basis</td>\n",
       "      <td>inputs</td>\n",
       "      <td>correlations</td>\n",
       "      <td>basing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>344595</td>\n",
       "      <td>230</td>\n",
       "      <td>example unsupervised</td>\n",
       "      <td>unsupervised learning</td>\n",
       "      <td>simple example</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>learning</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>344596</td>\n",
       "      <td>207021</td>\n",
       "      <td>plant</td>\n",
       "      <td>host</td>\n",
       "      <td>dodder</td>\n",
       "      <td>host plant</td>\n",
       "      <td>dodder plant</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>344597</td>\n",
       "      <td>207096</td>\n",
       "      <td>estimating</td>\n",
       "      <td>clustering meta</td>\n",
       "      <td>clusters estimating</td>\n",
       "      <td>density estimating</td>\n",
       "      <td>estimating density</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>344598</td>\n",
       "      <td>207058</td>\n",
       "      <td>series</td>\n",
       "      <td>paper</td>\n",
       "      <td>time series</td>\n",
       "      <td>time</td>\n",
       "      <td>forecasting</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>344599</td>\n",
       "      <td>207096</td>\n",
       "      <td>spaces</td>\n",
       "      <td>probability measures</td>\n",
       "      <td>functions probability</td>\n",
       "      <td>finite dimensional</td>\n",
       "      <td>discrete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>344600</td>\n",
       "      <td>163114</td>\n",
       "      <td>dickey fuller</td>\n",
       "      <td>dickey</td>\n",
       "      <td>fuller</td>\n",
       "      <td>fuller test</td>\n",
       "      <td>test stata</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>344601</td>\n",
       "      <td>207099</td>\n",
       "      <td>possible wilcox</td>\n",
       "      <td>check sample</td>\n",
       "      <td>different possible</td>\n",
       "      <td>wilcox test</td>\n",
       "      <td>sample normal</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>344602</td>\n",
       "      <td>121522</td>\n",
       "      <td>logistic</td>\n",
       "      <td>logistic tag</td>\n",
       "      <td>number relevant</td>\n",
       "      <td>relevant questions</td>\n",
       "      <td>tag number</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>344604</td>\n",
       "      <td>161278</td>\n",
       "      <td>effects limited</td>\n",
       "      <td>existing mean</td>\n",
       "      <td>matrix existing</td>\n",
       "      <td>permanent effect</td>\n",
       "      <td>matter variable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>344605</td>\n",
       "      <td>207126</td>\n",
       "      <td>pasta</td>\n",
       "      <td>anova tukeys</td>\n",
       "      <td>apologies incorrectly</td>\n",
       "      <td>batches pasta</td>\n",
       "      <td>cooking anova</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>344607</td>\n",
       "      <td>121270</td>\n",
       "      <td>rbms</td>\n",
       "      <td>networks</td>\n",
       "      <td>hopfield nets</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>hinton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>344608</td>\n",
       "      <td>191681</td>\n",
       "      <td>hessian</td>\n",
       "      <td>approximate hessian</td>\n",
       "      <td>dealing hessian</td>\n",
       "      <td>trying approximate</td>\n",
       "      <td>bfgs</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>344609</td>\n",
       "      <td>127538</td>\n",
       "      <td>spikes</td>\n",
       "      <td>tsclean</td>\n",
       "      <td>winsorization</td>\n",
       "      <td>dummy variables</td>\n",
       "      <td>explainable</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>344610</td>\n",
       "      <td>207128</td>\n",
       "      <td>normality</td>\n",
       "      <td>dismiss assumption</td>\n",
       "      <td>know violate</td>\n",
       "      <td>know wilcox</td>\n",
       "      <td>lt dismiss</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19725 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  user_id                  TopWord1                 TopWord2  \\\n",
       "0       317697   134975   variables statistically             mixed effect   \n",
       "1       317699    45374                  accuracy      validation accuracy   \n",
       "2       317701   171235                   freedom                     mean   \n",
       "3       317703   187797                  patients                 treating   \n",
       "4       317704    61496               uncertainty               error ways   \n",
       "5       317705   134369     bonferroni correction               bonferroni   \n",
       "6       317707   187792   environmental variables                   traits   \n",
       "7       317708    82816        solve differential    equation distribution   \n",
       "8       317710    61092  monotonically increasing            monotonically   \n",
       "9       317711   179343          affect specified             shock affect   \n",
       "10      317712    67137                      simr                able edit   \n",
       "11      317713    67137        measures construct                    power   \n",
       "12      317716   187803        terms applications       difference poisson   \n",
       "13      317717   113090                 graphical         graphical models   \n",
       "14      317718    80922                 recurrent           deep recurrent   \n",
       "15      317719   187804                    person                young old   \n",
       "16      317721   177228              intervention         male respondents   \n",
       "17      317722   187806                      fans                     band   \n",
       "18      317723     8123      distinguishes legged                   legged   \n",
       "19      317724   117168                     block               resampling   \n",
       "20      317725   185581                rows small       corresponding rows   \n",
       "21      317727   117168                     block                   blocks   \n",
       "22      317728   187809                 subscribe                   mining   \n",
       "23      317729    31484         beta distribution                     beta   \n",
       "24      317730   111479               eigenvector                     grey   \n",
       "25      317731      805                      beta                 gaussian   \n",
       "26      317732    88727                    signal                    bound   \n",
       "27      317733   131977            don understand  architecture explaining   \n",
       "28      317734   187810              intervention                   signal   \n",
       "29      317735     8402         denote noncentral           derived theory   \n",
       "...        ...      ...                       ...                      ...   \n",
       "19970   344573    94586              tree species                  species   \n",
       "19971   344574   105149                   college       college highschool   \n",
       "19972   344575   136275                      mean                 use mean   \n",
       "19973   344578   163648            number correct          correct answers   \n",
       "19974   344579   207112               equal equal    distribution variable   \n",
       "19975   344580   195935                     model                     mean   \n",
       "19976   344581   195935      pairwise comparisons                 pairwise   \n",
       "19977   344583   195935          assume continous            binary models   \n",
       "19978   344585   207115    instrumental variables             instrumental   \n",
       "19979   344586   206620                  fonction           anova fonction   \n",
       "19980   344587   207096               probability      probability density   \n",
       "19981   344588   198848      sufficient estimator                bernoulli   \n",
       "19982   344589   206947                      spss         come instruction   \n",
       "19983   344592    96600            area posterior          axis reasonable   \n",
       "19984   344593   206570                 gain lift                lift used   \n",
       "19985   344594   207118                   neurons                    basis   \n",
       "19986   344595      230      example unsupervised    unsupervised learning   \n",
       "19987   344596   207021                     plant                     host   \n",
       "19988   344597   207096                estimating          clustering meta   \n",
       "19989   344598   207058                    series                    paper   \n",
       "19990   344599   207096                    spaces     probability measures   \n",
       "19991   344600   163114             dickey fuller                   dickey   \n",
       "19992   344601   207099           possible wilcox             check sample   \n",
       "19993   344602   121522                  logistic             logistic tag   \n",
       "19994   344604   161278           effects limited            existing mean   \n",
       "19995   344605   207126                     pasta             anova tukeys   \n",
       "19996   344607   121270                      rbms                 networks   \n",
       "19997   344608   191681                   hessian      approximate hessian   \n",
       "19998   344609   127538                    spikes                  tsclean   \n",
       "19999   344610   207128                 normality       dismiss assumption   \n",
       "\n",
       "                     TopWord3                TopWord4  \\\n",
       "0                       mixed               variables   \n",
       "1           training accuracy                 shallow   \n",
       "2             degrees freedom                 degrees   \n",
       "3                       excel                   treat   \n",
       "4          estimate realistic         forecast method   \n",
       "5                  correction                outliers   \n",
       "6               environmental            plant traits   \n",
       "7       differential equation              need solve   \n",
       "8              differentiable              increasing   \n",
       "9            understand shock                    prof   \n",
       "10            deciding sample              edit turns   \n",
       "11                   measures        outcome measures   \n",
       "12              process terms          process markov   \n",
       "13                 log linear                  models   \n",
       "14             neural network        recurrent neural   \n",
       "15                      young                     old   \n",
       "16          intervention time             respondents   \n",
       "17                   universe        overall universe   \n",
       "18                  old style           seek opinions   \n",
       "19                     series                  blocks   \n",
       "20                 constraint            matrix shape   \n",
       "21          block observation                resample   \n",
       "22              brief ideally      customer subscribe   \n",
       "23         distribution prove               look beta   \n",
       "24                 components              eigenvalue   \n",
       "25             symmetric beta               symmetric   \n",
       "26            bound saturated        channel variance   \n",
       "27         concatenate inputs               deep mind   \n",
       "28                     events         external events   \n",
       "29                  don proof           ingersoll ros   \n",
       "...                       ...                     ...   \n",
       "19970                    tree                   crown   \n",
       "19971              highschool          student answer   \n",
       "19972                test set                    test   \n",
       "19973              let number             high school   \n",
       "19974     function parameters          interpretation   \n",
       "19975       application model        baseline renders   \n",
       "19976             comparisons      ability explicitly   \n",
       "19977        combining binary  continous distribution   \n",
       "19978    accounting political             author help   \n",
       "19979             lm fonction                      lm   \n",
       "19980        density function                 density   \n",
       "19981  binomial distributions              sufficient   \n",
       "19982       downloaded plugin         fully motivated   \n",
       "19983      direction observed             does unable   \n",
       "19984             metrics auc              score gain   \n",
       "19985                  inputs            correlations   \n",
       "19986          simple example            unsupervised   \n",
       "19987                  dodder              host plant   \n",
       "19988     clusters estimating      density estimating   \n",
       "19989             time series                    time   \n",
       "19990   functions probability      finite dimensional   \n",
       "19991                  fuller             fuller test   \n",
       "19992      different possible             wilcox test   \n",
       "19993         number relevant      relevant questions   \n",
       "19994         matrix existing        permanent effect   \n",
       "19995   apologies incorrectly           batches pasta   \n",
       "19996           hopfield nets                hopfield   \n",
       "19997         dealing hessian      trying approximate   \n",
       "19998           winsorization         dummy variables   \n",
       "19999            know violate             know wilcox   \n",
       "\n",
       "                        TopWord5  Community  \n",
       "0      statistically significant         42  \n",
       "1                     validation        145  \n",
       "2                    data degree        140  \n",
       "3                  bias treating          1  \n",
       "4                  predicts time          1  \n",
       "5                 don understand        120  \n",
       "6                          plant         92  \n",
       "7               distribution pdf          1  \n",
       "8        assuming differentiable          1  \n",
       "9                          shock          1  \n",
       "10                effect variety         -1  \n",
       "11       multivariate regression        136  \n",
       "12                markov process          1  \n",
       "13                           log        148  \n",
       "14                        neural        102  \n",
       "15                 age indicator        137  \n",
       "16                          male         70  \n",
       "17                        cities          1  \n",
       "18                   recognition          1  \n",
       "19                      resample         50  \n",
       "20                           row          1  \n",
       "21                  fourth block          1  \n",
       "22            incorporate mining          1  \n",
       "23                    prove beta          1  \n",
       "24                     variables         42  \n",
       "25                 beta gaussian          1  \n",
       "26        deriving relationships          1  \n",
       "27              explaining works          1  \n",
       "28                      external         70  \n",
       "29                   proof prove         -1  \n",
       "...                          ...        ...  \n",
       "19970                      lidar        119  \n",
       "19971         correctly question          1  \n",
       "19972                  mean test         17  \n",
       "19973                    let let          1  \n",
       "19974                 parameters        118  \n",
       "19975         building important         16  \n",
       "19976          addition pairwise          1  \n",
       "19977           decisions assume         -1  \n",
       "19978           economics health          1  \n",
       "19979      avoid overpramatizing          1  \n",
       "19980                   function         59  \n",
       "19981                   textbook        118  \n",
       "19982           instruction spss        135  \n",
       "19983            effect opposite         -1  \n",
       "19984       different evaluation         -1  \n",
       "19985                     basing          1  \n",
       "19986                   learning         64  \n",
       "19987               dodder plant        144  \n",
       "19988         estimating density          1  \n",
       "19989                forecasting         50  \n",
       "19990                   discrete          1  \n",
       "19991                 test stata         32  \n",
       "19992              sample normal         26  \n",
       "19993                 tag number        147  \n",
       "19994            matter variable         -1  \n",
       "19995              cooking anova         -1  \n",
       "19996                     hinton          1  \n",
       "19997                       bfgs        118  \n",
       "19998                explainable        133  \n",
       "19999                 lt dismiss        118  \n",
       "\n",
       "[19725 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df_w_comm2.to_csv(COMMUNITIES_VIZ_PATH2, encoding='utf-8', index=False, columns = ['post_id', 'Community'])\n",
    "post_df_w_comm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_f2 = open(CNM_COMMUNITIES_PICKLE, 'wb')\n",
    "pickle.dump(community_dict, pickle_f2)\n",
    "pickle_f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 1,\n",
       " 2: 74,\n",
       " 3: 78,\n",
       " 4: 106,\n",
       " 5: 1,\n",
       " 6: 99,\n",
       " 7: 1,\n",
       " 8: 78,\n",
       " 9: 1,\n",
       " 10: 111,\n",
       " 11: 83,\n",
       " 12: 17,\n",
       " 13: 61,\n",
       " 14: 133,\n",
       " 15: 1,\n",
       " 16: 93,\n",
       " 17: 118,\n",
       " 18: 1,\n",
       " 19: 1,\n",
       " 20: 1,\n",
       " 21: 1,\n",
       " 22: 56,\n",
       " 23: 118,\n",
       " 24: 118,\n",
       " 25: 102,\n",
       " 26: 1,\n",
       " 27: 1,\n",
       " 28: 118,\n",
       " 29: 118,\n",
       " 30: 126,\n",
       " 31: 1,\n",
       " 32: 1,\n",
       " 33: 50,\n",
       " 34: 1,\n",
       " 35: 1,\n",
       " 36: 1,\n",
       " 37: 1,\n",
       " 38: 1,\n",
       " 39: 1,\n",
       " 40: 66,\n",
       " 41: 1,\n",
       " 42: 1,\n",
       " 43: 66,\n",
       " 44: 1,\n",
       " 45: 1,\n",
       " 46: 16,\n",
       " 47: 147,\n",
       " 48: 122,\n",
       " 49: 143,\n",
       " 50: 58,\n",
       " 51: 1,\n",
       " 52: 1,\n",
       " 53: 119,\n",
       " 54: 1,\n",
       " 55: 1,\n",
       " 56: 1,\n",
       " 57: 130,\n",
       " 58: 1,\n",
       " 59: 1,\n",
       " 60: 1,\n",
       " 61: 1,\n",
       " 62: 1,\n",
       " 63: 1,\n",
       " 64: 96,\n",
       " 65: 129,\n",
       " 66: 1,\n",
       " 67: 1,\n",
       " 68: 1,\n",
       " 69: 1,\n",
       " 70: 1,\n",
       " 71: 61,\n",
       " 72: 77,\n",
       " 73: 118,\n",
       " 74: 117,\n",
       " 75: 1,\n",
       " 76: 145,\n",
       " 77: 1,\n",
       " 78: 135,\n",
       " 79: 1,\n",
       " 80: 72,\n",
       " 81: 118,\n",
       " 82: 1,\n",
       " 83: 68,\n",
       " 84: 1,\n",
       " 85: 1,\n",
       " 86: 1,\n",
       " 87: 54,\n",
       " 88: 58,\n",
       " 89: 1,\n",
       " 90: 1,\n",
       " 91: 1,\n",
       " 92: 1,\n",
       " 93: 137,\n",
       " 94: 1,\n",
       " 95: 111,\n",
       " 96: 66,\n",
       " 97: 1,\n",
       " 98: 121,\n",
       " 99: 1,\n",
       " 100: 1,\n",
       " 101: 106,\n",
       " 102: 1,\n",
       " 103: 1,\n",
       " 104: 1,\n",
       " 105: 101,\n",
       " 106: 1,\n",
       " 107: 109,\n",
       " 108: 1,\n",
       " 109: 118,\n",
       " 110: 69,\n",
       " 111: 137,\n",
       " 112: 130,\n",
       " 113: 1,\n",
       " 114: 117,\n",
       " 115: 1,\n",
       " 116: 1,\n",
       " 117: 1,\n",
       " 118: 73,\n",
       " 119: 60,\n",
       " 120: 1,\n",
       " 121: 73,\n",
       " 122: 71,\n",
       " 123: 1,\n",
       " 124: 70,\n",
       " 125: 1,\n",
       " 126: 93,\n",
       " 127: 42,\n",
       " 128: 1,\n",
       " 129: 1,\n",
       " 130: 118,\n",
       " 131: 1,\n",
       " 132: 1,\n",
       " 133: 103,\n",
       " 134: 86,\n",
       " 135: 1,\n",
       " 136: 122,\n",
       " 137: 1,\n",
       " 138: 102,\n",
       " 139: 1,\n",
       " 140: 118,\n",
       " 141: 1,\n",
       " 142: 93,\n",
       " 143: 66,\n",
       " 144: 1,\n",
       " 145: 1,\n",
       " 146: 1,\n",
       " 147: 1,\n",
       " 148: 118,\n",
       " 149: 118,\n",
       " 150: 1,\n",
       " 151: 1,\n",
       " 152: 1,\n",
       " 153: 56,\n",
       " 154: 118,\n",
       " 155: 56,\n",
       " 156: 1,\n",
       " 157: 1,\n",
       " 158: 138,\n",
       " 159: 84,\n",
       " 160: 1,\n",
       " 161: 1,\n",
       " 162: 84,\n",
       " 163: 90,\n",
       " 164: 1,\n",
       " 165: 1,\n",
       " 166: 147,\n",
       " 167: 134,\n",
       " 168: 107,\n",
       " 169: 22,\n",
       " 170: 120,\n",
       " 171: 102,\n",
       " 172: 145,\n",
       " 173: 133,\n",
       " 174: 1,\n",
       " 175: 1,\n",
       " 176: 1,\n",
       " 177: 1,\n",
       " 178: 147,\n",
       " 179: 1,\n",
       " 180: 1,\n",
       " 181: 1,\n",
       " 182: 145,\n",
       " 183: 1,\n",
       " 184: 40,\n",
       " 185: 135,\n",
       " 186: 140,\n",
       " 187: 1,\n",
       " 188: 1,\n",
       " 189: 1,\n",
       " 190: 1,\n",
       " 191: 1,\n",
       " 192: 147,\n",
       " 193: 1,\n",
       " 194: 1,\n",
       " 195: 1,\n",
       " 196: 87,\n",
       " 197: 1,\n",
       " 198: 1,\n",
       " 199: 124,\n",
       " 200: 118,\n",
       " 201: 147,\n",
       " 202: 1,\n",
       " 203: 1,\n",
       " 204: 1,\n",
       " 205: 1,\n",
       " 206: 102,\n",
       " 207: 1,\n",
       " 208: 95,\n",
       " 209: 1,\n",
       " 210: 1,\n",
       " 211: 102,\n",
       " 212: 1,\n",
       " 213: 118,\n",
       " 214: 99,\n",
       " 215: 1,\n",
       " 216: 88,\n",
       " 217: 86,\n",
       " 218: 42,\n",
       " 219: 1,\n",
       " 220: 1,\n",
       " 221: 1,\n",
       " 222: 1,\n",
       " 223: 86,\n",
       " 224: 119,\n",
       " 225: 1,\n",
       " 226: 118,\n",
       " 227: 1,\n",
       " 228: 119,\n",
       " 229: 68,\n",
       " 230: 1,\n",
       " 231: 1,\n",
       " 232: 1,\n",
       " 233: 1,\n",
       " 234: 1,\n",
       " 235: 60,\n",
       " 236: 1,\n",
       " 237: 1,\n",
       " 238: 1,\n",
       " 239: 64,\n",
       " 240: 1,\n",
       " 241: 77,\n",
       " 242: 93,\n",
       " 243: 118,\n",
       " 244: 132,\n",
       " 245: 133,\n",
       " 246: 93,\n",
       " 247: 145,\n",
       " 248: 42,\n",
       " 249: 118,\n",
       " 250: 58,\n",
       " 251: 78,\n",
       " 252: 145,\n",
       " 253: 122,\n",
       " 254: 1,\n",
       " 255: 1,\n",
       " 256: 1,\n",
       " 257: 1,\n",
       " 258: 1,\n",
       " 259: 1,\n",
       " 260: 16,\n",
       " 261: 93,\n",
       " 262: 135,\n",
       " 263: 117,\n",
       " 264: 102,\n",
       " 265: 1,\n",
       " 266: 78,\n",
       " 267: 1,\n",
       " 268: 137,\n",
       " 269: 1,\n",
       " 270: 122,\n",
       " 271: 1,\n",
       " 272: 140,\n",
       " 273: 1,\n",
       " 274: 118,\n",
       " 275: 1,\n",
       " 276: 66,\n",
       " 277: 118,\n",
       " 278: 1,\n",
       " 279: 1,\n",
       " 280: 132,\n",
       " 281: 1,\n",
       " 282: 1,\n",
       " 283: 1,\n",
       " 284: 137,\n",
       " 285: 66,\n",
       " 286: 1,\n",
       " 287: 22,\n",
       " 288: 132,\n",
       " 289: 1,\n",
       " 290: 1,\n",
       " 291: 1,\n",
       " 292: 117,\n",
       " 293: 67,\n",
       " 294: 124,\n",
       " 295: 50,\n",
       " 296: 1,\n",
       " 297: 1,\n",
       " 298: 1,\n",
       " 299: 1,\n",
       " 300: 42,\n",
       " 301: 102,\n",
       " 302: 39,\n",
       " 303: 140,\n",
       " 304: 1,\n",
       " 305: 1,\n",
       " 306: 84,\n",
       " 307: 1,\n",
       " 308: 95,\n",
       " 309: 132,\n",
       " 310: 1,\n",
       " 311: 145,\n",
       " 312: 66,\n",
       " 313: 17,\n",
       " 314: 1,\n",
       " 315: 1,\n",
       " 316: 137,\n",
       " 317: 124,\n",
       " 318: 1,\n",
       " 319: 1,\n",
       " 320: 84,\n",
       " 321: 1,\n",
       " 322: 1,\n",
       " 323: 148,\n",
       " 324: 100,\n",
       " 325: 111,\n",
       " 326: 1,\n",
       " 327: 105,\n",
       " 328: 109,\n",
       " 329: 1,\n",
       " 330: 1,\n",
       " 331: 77,\n",
       " 332: 144,\n",
       " 333: 1,\n",
       " 334: 1,\n",
       " 335: 1,\n",
       " 336: 1,\n",
       " 337: 1,\n",
       " 338: 102,\n",
       " 339: 120,\n",
       " 340: 68,\n",
       " 341: 1,\n",
       " 342: 44,\n",
       " 343: 1,\n",
       " 344: 140,\n",
       " 345: 1,\n",
       " 346: 1,\n",
       " 347: 50,\n",
       " 348: 125,\n",
       " 349: 148,\n",
       " 350: 103,\n",
       " 351: 1,\n",
       " 352: 1,\n",
       " 353: 95,\n",
       " 354: 1,\n",
       " 355: 95,\n",
       " 356: 101,\n",
       " 357: 1,\n",
       " 358: 140,\n",
       " 359: 1,\n",
       " 360: 64,\n",
       " 361: 95,\n",
       " 362: 137,\n",
       " 363: 108,\n",
       " 364: 54,\n",
       " 365: 16,\n",
       " 366: 1,\n",
       " 367: 1,\n",
       " 368: 1,\n",
       " 369: 1,\n",
       " 370: 118,\n",
       " 371: 118,\n",
       " 372: 1,\n",
       " 373: 131,\n",
       " 374: 50,\n",
       " 375: 118,\n",
       " 376: 1,\n",
       " 377: 1,\n",
       " 378: 1,\n",
       " 379: 1,\n",
       " 380: 1,\n",
       " 381: 118,\n",
       " 382: 1,\n",
       " 383: 1,\n",
       " 384: 17,\n",
       " 385: 1,\n",
       " 386: 87,\n",
       " 387: 1,\n",
       " 388: 68,\n",
       " 389: 1,\n",
       " 390: 1,\n",
       " 391: 1,\n",
       " 392: 96,\n",
       " 393: 1,\n",
       " 394: 1,\n",
       " 395: 1,\n",
       " 396: 1,\n",
       " 397: 1,\n",
       " 398: 118,\n",
       " 399: 1,\n",
       " 400: 119,\n",
       " 401: 83,\n",
       " 402: 145,\n",
       " 403: 1,\n",
       " 404: 66,\n",
       " 405: 66,\n",
       " 406: 68,\n",
       " 407: 59,\n",
       " 408: 1,\n",
       " 409: 101,\n",
       " 410: 1,\n",
       " 411: 107,\n",
       " 412: 89,\n",
       " 413: 1,\n",
       " 414: 1,\n",
       " 415: 1,\n",
       " 416: 145,\n",
       " 417: 1,\n",
       " 418: 1,\n",
       " 419: 1,\n",
       " 420: 88,\n",
       " 421: 1,\n",
       " 422: 147,\n",
       " 423: 1,\n",
       " 424: 1,\n",
       " 425: 118,\n",
       " 426: 1,\n",
       " 427: 1,\n",
       " 428: 140,\n",
       " 429: 54,\n",
       " 430: 1,\n",
       " 431: 16,\n",
       " 432: 130,\n",
       " 433: 72,\n",
       " 434: 1,\n",
       " 435: 1,\n",
       " 436: 58,\n",
       " 437: 58,\n",
       " 438: 1,\n",
       " 439: 1,\n",
       " 440: 130,\n",
       " 441: 54,\n",
       " 442: 1,\n",
       " 443: 147,\n",
       " 444: 1,\n",
       " 445: 110,\n",
       " 446: 1,\n",
       " 447: 58,\n",
       " 448: 118,\n",
       " 449: 59,\n",
       " 450: 1,\n",
       " 451: 1,\n",
       " 452: 1,\n",
       " 453: 130,\n",
       " 454: 118,\n",
       " 455: 100,\n",
       " 456: 1,\n",
       " 457: 1,\n",
       " 458: 1,\n",
       " 459: 54,\n",
       " 460: 1,\n",
       " 461: 1,\n",
       " 462: 1,\n",
       " 463: 95,\n",
       " 464: 64,\n",
       " 465: 123,\n",
       " 466: 1,\n",
       " 467: 115,\n",
       " 468: 42,\n",
       " 469: 54,\n",
       " 470: 118,\n",
       " 471: 1,\n",
       " 472: 1,\n",
       " 473: 89,\n",
       " 474: 16,\n",
       " 475: 1,\n",
       " 476: 102,\n",
       " 477: 1,\n",
       " 478: 131,\n",
       " 479: 66,\n",
       " 480: 118,\n",
       " 481: 118,\n",
       " 482: 118,\n",
       " 483: 107,\n",
       " 484: 117,\n",
       " 485: 1,\n",
       " 486: 1,\n",
       " 487: 1,\n",
       " 488: 66,\n",
       " 489: 88,\n",
       " 490: 107,\n",
       " 491: 17,\n",
       " 492: 143,\n",
       " 493: 1,\n",
       " 494: 54,\n",
       " 495: 137,\n",
       " 496: 1,\n",
       " 497: 118,\n",
       " 498: 134,\n",
       " 499: 50,\n",
       " 500: 73,\n",
       " 501: 116,\n",
       " 502: 145,\n",
       " 503: 145,\n",
       " 504: 77,\n",
       " 505: 66,\n",
       " 506: 84,\n",
       " 507: 1,\n",
       " 508: 1,\n",
       " 509: 1,\n",
       " 510: 1,\n",
       " 511: 58,\n",
       " 512: 84,\n",
       " 513: 1,\n",
       " 514: 1,\n",
       " 515: 131,\n",
       " 516: 1,\n",
       " 517: 1,\n",
       " 518: 89,\n",
       " 519: 101,\n",
       " 520: 1,\n",
       " 521: 1,\n",
       " 522: 147,\n",
       " 523: 1,\n",
       " 524: 118,\n",
       " 525: 1,\n",
       " 526: 118,\n",
       " 527: 1,\n",
       " 528: 105,\n",
       " 529: 1,\n",
       " 530: 16,\n",
       " 531: 1,\n",
       " 532: 131,\n",
       " 533: 16,\n",
       " 534: 1,\n",
       " 535: 58,\n",
       " 536: 84,\n",
       " 537: 1,\n",
       " 538: 1,\n",
       " 539: 108,\n",
       " 540: 1,\n",
       " 541: 1,\n",
       " 542: 137,\n",
       " 543: 77,\n",
       " 544: 82,\n",
       " 545: 131,\n",
       " 546: 76,\n",
       " 547: 1,\n",
       " 548: 1,\n",
       " 549: 1,\n",
       " 550: 1,\n",
       " 551: 116,\n",
       " 552: 76,\n",
       " 553: 118,\n",
       " 554: 117,\n",
       " 555: 1,\n",
       " 556: 1,\n",
       " 557: 125,\n",
       " 558: 67,\n",
       " 559: 134,\n",
       " 560: 66,\n",
       " 561: 126,\n",
       " 562: 102,\n",
       " 563: 78,\n",
       " 564: 1,\n",
       " 565: 1,\n",
       " 566: 1,\n",
       " 567: 1,\n",
       " 568: 77,\n",
       " 569: 1,\n",
       " 570: 72,\n",
       " 571: 76,\n",
       " 572: 146,\n",
       " 573: 137,\n",
       " 574: 140,\n",
       " 575: 137,\n",
       " 576: 1,\n",
       " 577: 119,\n",
       " 578: 1,\n",
       " 579: 1,\n",
       " 580: 138,\n",
       " 581: 1,\n",
       " 582: 1,\n",
       " 583: 137,\n",
       " 584: 63,\n",
       " 585: 68,\n",
       " 586: 83,\n",
       " 587: 118,\n",
       " 588: 95,\n",
       " 589: 140,\n",
       " 590: 67,\n",
       " 591: 1,\n",
       " 592: 110,\n",
       " 593: 1,\n",
       " 594: 118,\n",
       " 595: 130,\n",
       " 596: 118,\n",
       " 597: 118,\n",
       " 598: 1,\n",
       " 599: 1,\n",
       " 600: 93,\n",
       " 601: 102,\n",
       " 602: 118,\n",
       " 603: 1,\n",
       " 604: 126,\n",
       " 605: 1,\n",
       " 606: 65,\n",
       " 607: 107,\n",
       " 608: 58,\n",
       " 609: 1,\n",
       " 610: 1,\n",
       " 611: 63,\n",
       " 612: 144,\n",
       " 613: 86,\n",
       " 614: 118,\n",
       " 615: 1,\n",
       " 616: 102,\n",
       " 617: 118,\n",
       " 618: 1,\n",
       " 619: 1,\n",
       " 620: 125,\n",
       " 621: 1,\n",
       " 622: 67,\n",
       " 623: 67,\n",
       " 624: 82,\n",
       " 625: 1,\n",
       " 626: 1,\n",
       " 627: 1,\n",
       " 628: 67,\n",
       " 629: 67,\n",
       " 630: 1,\n",
       " 631: 1,\n",
       " 632: 1,\n",
       " 633: 1,\n",
       " 634: 1,\n",
       " 635: 1,\n",
       " 636: 1,\n",
       " 637: 1,\n",
       " 638: 105,\n",
       " 639: 1,\n",
       " 640: 123,\n",
       " 641: 135,\n",
       " 642: 1,\n",
       " 643: 58,\n",
       " 644: 125,\n",
       " 645: 1,\n",
       " 646: 1,\n",
       " 647: 1,\n",
       " 648: 122,\n",
       " 649: 28,\n",
       " 650: 1,\n",
       " 651: 50,\n",
       " 652: 1,\n",
       " 653: 1,\n",
       " 654: 117,\n",
       " 655: 1,\n",
       " 656: 145,\n",
       " 657: 135,\n",
       " 658: 1,\n",
       " 659: 91,\n",
       " 660: 50,\n",
       " 661: 89,\n",
       " 662: 108,\n",
       " 663: 1,\n",
       " 664: 1,\n",
       " 665: 1,\n",
       " 666: 97,\n",
       " 667: 118,\n",
       " 668: 97,\n",
       " 669: 97,\n",
       " 670: 1,\n",
       " 671: 1,\n",
       " 672: 1,\n",
       " 673: 1,\n",
       " 674: 1,\n",
       " 675: 1,\n",
       " 676: 91,\n",
       " 677: 1,\n",
       " 678: 1,\n",
       " 679: 103,\n",
       " 680: 107,\n",
       " 681: 1,\n",
       " 682: 1,\n",
       " 683: 1,\n",
       " 684: 1,\n",
       " 685: 1,\n",
       " 686: 97,\n",
       " 687: 1,\n",
       " 688: 1,\n",
       " 689: 145,\n",
       " 690: 130,\n",
       " 691: 64,\n",
       " 692: 1,\n",
       " 693: 118,\n",
       " 694: 103,\n",
       " 695: 106,\n",
       " 696: 1,\n",
       " 697: 1,\n",
       " 698: 1,\n",
       " 699: 1,\n",
       " 700: 96,\n",
       " 701: 1,\n",
       " 702: 1,\n",
       " 703: 1,\n",
       " 704: 147,\n",
       " 705: 1,\n",
       " 706: 1,\n",
       " 707: 118,\n",
       " 708: 50,\n",
       " 709: 77,\n",
       " 710: 1,\n",
       " 711: 1,\n",
       " 712: 1,\n",
       " 713: 1,\n",
       " 714: 1,\n",
       " 715: 78,\n",
       " 716: 1,\n",
       " 717: 1,\n",
       " 718: 1,\n",
       " 719: 1,\n",
       " 720: 147,\n",
       " 721: 1,\n",
       " 722: 1,\n",
       " 723: 67,\n",
       " 724: 1,\n",
       " 725: 1,\n",
       " 726: 1,\n",
       " 727: 1,\n",
       " 728: 1,\n",
       " 729: 0,\n",
       " 730: 1,\n",
       " 731: 1,\n",
       " 732: 134,\n",
       " 733: 123,\n",
       " 734: 109,\n",
       " 735: 119,\n",
       " 736: 1,\n",
       " 737: 1,\n",
       " 738: 1,\n",
       " 739: 118,\n",
       " 740: 50,\n",
       " 741: 123,\n",
       " 742: 117,\n",
       " 743: 1,\n",
       " 744: 102,\n",
       " 745: 101,\n",
       " 746: 130,\n",
       " 747: 1,\n",
       " 748: 1,\n",
       " 749: 1,\n",
       " 750: 1,\n",
       " 751: 145,\n",
       " 752: 130,\n",
       " 753: 1,\n",
       " 754: 126,\n",
       " 755: 114,\n",
       " 756: 1,\n",
       " 757: 141,\n",
       " 758: 1,\n",
       " 759: 50,\n",
       " 760: 101,\n",
       " 761: 50,\n",
       " 762: 1,\n",
       " 763: 1,\n",
       " 764: 1,\n",
       " 765: 1,\n",
       " 766: 91,\n",
       " 767: 134,\n",
       " 768: 64,\n",
       " 769: 1,\n",
       " 770: 50,\n",
       " 771: 82,\n",
       " 772: 1,\n",
       " 773: 1,\n",
       " 774: 95,\n",
       " 775: 103,\n",
       " 776: 117,\n",
       " 777: 118,\n",
       " 778: 1,\n",
       " 779: 91,\n",
       " 780: 1,\n",
       " 781: 1,\n",
       " 782: 1,\n",
       " 783: 18,\n",
       " 784: 1,\n",
       " 785: 117,\n",
       " 786: 1,\n",
       " 787: 78,\n",
       " 788: 118,\n",
       " 789: 1,\n",
       " 790: 1,\n",
       " 791: 118,\n",
       " 792: 1,\n",
       " 793: 1,\n",
       " 794: 117,\n",
       " 795: 118,\n",
       " 796: 1,\n",
       " 797: 116,\n",
       " 798: 140,\n",
       " 799: 54,\n",
       " 800: 1,\n",
       " 801: 103,\n",
       " 802: 135,\n",
       " 803: 1,\n",
       " 804: 54,\n",
       " 805: 1,\n",
       " 806: 54,\n",
       " 807: 17,\n",
       " 808: 68,\n",
       " 809: 67,\n",
       " 810: 1,\n",
       " 811: 1,\n",
       " 812: 118,\n",
       " 813: 137,\n",
       " 814: 105,\n",
       " 815: 1,\n",
       " 816: 58,\n",
       " 817: 1,\n",
       " 818: 1,\n",
       " 819: 1,\n",
       " 820: 1,\n",
       " 821: 1,\n",
       " 822: 1,\n",
       " 823: 1,\n",
       " 824: 1,\n",
       " 825: 118,\n",
       " 826: 118,\n",
       " 827: 1,\n",
       " 828: 1,\n",
       " 829: 118,\n",
       " 830: 145,\n",
       " 831: 1,\n",
       " 832: 84,\n",
       " 833: 16,\n",
       " 834: 132,\n",
       " 835: 132,\n",
       " 836: 1,\n",
       " 837: 137,\n",
       " 838: 1,\n",
       " 839: 135,\n",
       " 840: 60,\n",
       " 841: 1,\n",
       " 842: 1,\n",
       " 843: 1,\n",
       " 844: 137,\n",
       " 845: 16,\n",
       " 846: 56,\n",
       " 847: 1,\n",
       " 848: 145,\n",
       " 849: 56,\n",
       " 850: 1,\n",
       " 851: 118,\n",
       " 852: 1,\n",
       " 853: 1,\n",
       " 854: 105,\n",
       " 855: 147,\n",
       " 856: 123,\n",
       " 857: 96,\n",
       " 858: 51,\n",
       " 859: 1,\n",
       " 860: 117,\n",
       " 861: 105,\n",
       " 862: 84,\n",
       " 863: 118,\n",
       " 864: 115,\n",
       " 865: 1,\n",
       " 866: 1,\n",
       " 867: 1,\n",
       " 868: 145,\n",
       " 869: 1,\n",
       " 870: 118,\n",
       " 871: 1,\n",
       " 872: 42,\n",
       " 873: 1,\n",
       " 874: 1,\n",
       " 875: 1,\n",
       " 876: 78,\n",
       " 877: 1,\n",
       " 878: 54,\n",
       " 879: 137,\n",
       " 880: 1,\n",
       " 881: 120,\n",
       " 882: 1,\n",
       " 883: 127,\n",
       " 884: 16,\n",
       " 885: 123,\n",
       " 886: 1,\n",
       " 887: 1,\n",
       " 888: 147,\n",
       " 889: 108,\n",
       " 890: 1,\n",
       " 891: 147,\n",
       " 892: 1,\n",
       " 893: 1,\n",
       " 894: 118,\n",
       " 895: 87,\n",
       " 896: 1,\n",
       " 897: 144,\n",
       " 898: 1,\n",
       " 899: 16,\n",
       " 900: 1,\n",
       " 901: 1,\n",
       " 902: 67,\n",
       " 903: 1,\n",
       " 904: 1,\n",
       " 905: 102,\n",
       " 906: 100,\n",
       " 907: 147,\n",
       " 908: 66,\n",
       " 909: 1,\n",
       " 910: 118,\n",
       " 911: 119,\n",
       " 912: 30,\n",
       " 913: 93,\n",
       " 914: 118,\n",
       " 915: 131,\n",
       " 916: 1,\n",
       " 917: 78,\n",
       " 918: 78,\n",
       " 919: 1,\n",
       " 920: 1,\n",
       " 921: 107,\n",
       " 922: 1,\n",
       " 923: 114,\n",
       " 924: 105,\n",
       " 925: 1,\n",
       " 926: 1,\n",
       " 927: 1,\n",
       " 928: 146,\n",
       " 929: 1,\n",
       " 930: 1,\n",
       " 931: 1,\n",
       " 932: 118,\n",
       " 933: 67,\n",
       " 934: 84,\n",
       " 935: 118,\n",
       " 936: 118,\n",
       " 937: 147,\n",
       " 938: 147,\n",
       " 939: 1,\n",
       " 940: 96,\n",
       " 941: 1,\n",
       " 942: 0,\n",
       " 943: 119,\n",
       " 944: 123,\n",
       " 945: 66,\n",
       " 946: 68,\n",
       " 947: 118,\n",
       " 948: 84,\n",
       " 949: 1,\n",
       " 950: 42,\n",
       " 951: 147,\n",
       " 952: 1,\n",
       " 953: 1,\n",
       " 954: 54,\n",
       " 955: 129,\n",
       " 956: 148,\n",
       " 957: 1,\n",
       " 958: 118,\n",
       " 959: 1,\n",
       " 960: 118,\n",
       " 961: 1,\n",
       " 962: 140,\n",
       " 963: 50,\n",
       " 964: 1,\n",
       " 965: 140,\n",
       " 966: 107,\n",
       " 967: 1,\n",
       " 968: 1,\n",
       " 969: 1,\n",
       " 970: 1,\n",
       " 971: 1,\n",
       " 972: 1,\n",
       " 973: 113,\n",
       " 974: 54,\n",
       " 975: 113,\n",
       " 976: 1,\n",
       " 977: 54,\n",
       " 978: 1,\n",
       " 979: 58,\n",
       " 980: 1,\n",
       " 981: 54,\n",
       " 982: 1,\n",
       " 983: 102,\n",
       " 984: 118,\n",
       " 985: 89,\n",
       " 986: 42,\n",
       " 987: 122,\n",
       " 988: 1,\n",
       " 989: 1,\n",
       " 990: 1,\n",
       " 991: 70,\n",
       " 992: 1,\n",
       " 993: 76,\n",
       " 994: 145,\n",
       " 995: 102,\n",
       " 996: 1,\n",
       " 997: 1,\n",
       " 998: 134,\n",
       " 999: 1,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spectral clustering\n",
    "pickle_f = open(SPEC_COMMUNITIES_PICKLE, 'rb')\n",
    "community_dict2 = pickle.load(pickle_f)\n",
    "pickle_f.close()\n",
    "\n",
    "community_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {327680: 0,\n",
       "             327681: 1,\n",
       "             327682: 2,\n",
       "             327683: 3,\n",
       "             327684: 0,\n",
       "             327685: 0,\n",
       "             327686: 3,\n",
       "             327687: 3,\n",
       "             327688: 3,\n",
       "             327689: 4,\n",
       "             327690: 3,\n",
       "             327692: 0,\n",
       "             327695: 3,\n",
       "             327698: 4,\n",
       "             327699: 4,\n",
       "             327700: 1,\n",
       "             327701: 0,\n",
       "             327702: 0,\n",
       "             327703: 3,\n",
       "             327707: 0,\n",
       "             327709: 3,\n",
       "             327710: 4,\n",
       "             327711: 0,\n",
       "             327712: 0,\n",
       "             327714: 4,\n",
       "             327715: 3,\n",
       "             327718: 0,\n",
       "             327720: 4,\n",
       "             327721: 0,\n",
       "             327722: 0,\n",
       "             327723: 0,\n",
       "             327724: 3,\n",
       "             327725: 4,\n",
       "             327727: 4,\n",
       "             327729: 4,\n",
       "             327737: 4,\n",
       "             327738: 1,\n",
       "             327739: 1,\n",
       "             327740: 3,\n",
       "             327742: 3,\n",
       "             327743: 0,\n",
       "             327744: 2,\n",
       "             327746: 5,\n",
       "             327747: 0,\n",
       "             327748: 4,\n",
       "             327749: 4,\n",
       "             327750: 4,\n",
       "             327751: 1,\n",
       "             327752: 3,\n",
       "             327753: 0,\n",
       "             327754: 4,\n",
       "             327755: 1,\n",
       "             327756: 1,\n",
       "             327757: 6,\n",
       "             327760: 3,\n",
       "             327761: 4,\n",
       "             327762: 1,\n",
       "             327764: 4,\n",
       "             327766: 4,\n",
       "             327767: 1,\n",
       "             327768: 4,\n",
       "             327771: 3,\n",
       "             327772: 4,\n",
       "             327774: 0,\n",
       "             327778: 3,\n",
       "             327782: 0,\n",
       "             327784: 4,\n",
       "             327787: 0,\n",
       "             327790: 4,\n",
       "             327791: 1,\n",
       "             327794: 7,\n",
       "             327795: 4,\n",
       "             327796: 0,\n",
       "             327797: 4,\n",
       "             327799: 0,\n",
       "             327801: 1,\n",
       "             327802: 3,\n",
       "             327804: 0,\n",
       "             327805: 8,\n",
       "             327806: 0,\n",
       "             327807: 4,\n",
       "             327812: 1,\n",
       "             327815: 0,\n",
       "             327816: 3,\n",
       "             327817: 0,\n",
       "             327818: 1,\n",
       "             327820: 4,\n",
       "             327822: 1,\n",
       "             327823: 4,\n",
       "             327824: 0,\n",
       "             327830: 1,\n",
       "             327831: 3,\n",
       "             327832: 9,\n",
       "             327834: 4,\n",
       "             327838: 4,\n",
       "             327839: 3,\n",
       "             327840: 0,\n",
       "             327841: 3,\n",
       "             327843: 4,\n",
       "             327845: 3,\n",
       "             327846: 3,\n",
       "             327847: 1,\n",
       "             327848: 3,\n",
       "             327850: 3,\n",
       "             327852: 3,\n",
       "             327853: 3,\n",
       "             327855: 3,\n",
       "             327856: 4,\n",
       "             327857: 4,\n",
       "             327858: 4,\n",
       "             327860: 3,\n",
       "             327864: 3,\n",
       "             327865: 8,\n",
       "             327866: 0,\n",
       "             327867: 0,\n",
       "             327868: 3,\n",
       "             327869: 0,\n",
       "             327870: 0,\n",
       "             327871: 0,\n",
       "             327873: 4,\n",
       "             327875: 4,\n",
       "             327876: 0,\n",
       "             327878: 1,\n",
       "             327880: 3,\n",
       "             327881: 4,\n",
       "             327882: 4,\n",
       "             327885: 0,\n",
       "             327886: 1,\n",
       "             327888: 1,\n",
       "             327889: 3,\n",
       "             327890: 3,\n",
       "             327891: 3,\n",
       "             327892: 4,\n",
       "             327893: 0,\n",
       "             327894: 4,\n",
       "             327896: 3,\n",
       "             327897: 3,\n",
       "             327899: 1,\n",
       "             327901: 4,\n",
       "             327902: 4,\n",
       "             327903: 3,\n",
       "             327904: 4,\n",
       "             327906: 0,\n",
       "             327907: 0,\n",
       "             327908: 3,\n",
       "             327909: 4,\n",
       "             327910: 4,\n",
       "             327911: 3,\n",
       "             327912: 0,\n",
       "             327914: 0,\n",
       "             327915: 1,\n",
       "             327917: 4,\n",
       "             327918: 3,\n",
       "             327919: 0,\n",
       "             327922: 0,\n",
       "             327924: 0,\n",
       "             327925: 3,\n",
       "             327927: 4,\n",
       "             327931: 3,\n",
       "             327932: 3,\n",
       "             327935: 3,\n",
       "             327937: 3,\n",
       "             327939: 3,\n",
       "             327940: 4,\n",
       "             327941: 4,\n",
       "             327942: 1,\n",
       "             327943: 1,\n",
       "             327944: 1,\n",
       "             327945: 1,\n",
       "             327946: 10,\n",
       "             327947: 4,\n",
       "             327948: 3,\n",
       "             327949: 3,\n",
       "             327951: 1,\n",
       "             327952: 0,\n",
       "             327953: 1,\n",
       "             327954: 3,\n",
       "             327955: 1,\n",
       "             327956: 1,\n",
       "             327961: 4,\n",
       "             327962: 1,\n",
       "             327963: 3,\n",
       "             327964: 3,\n",
       "             327965: 1,\n",
       "             327966: 3,\n",
       "             327968: 3,\n",
       "             327969: 0,\n",
       "             327971: 1,\n",
       "             327972: 1,\n",
       "             327973: 3,\n",
       "             327974: 4,\n",
       "             327975: 3,\n",
       "             327977: 0,\n",
       "             327978: 1,\n",
       "             327980: 3,\n",
       "             327981: 3,\n",
       "             327982: 0,\n",
       "             327983: 4,\n",
       "             327984: 11,\n",
       "             327985: 4,\n",
       "             327986: 0,\n",
       "             327989: 0,\n",
       "             327990: 4,\n",
       "             327991: 4,\n",
       "             327992: 3,\n",
       "             327993: 1,\n",
       "             327995: 4,\n",
       "             327996: 3,\n",
       "             327998: 3,\n",
       "             328000: 1,\n",
       "             328002: 3,\n",
       "             328003: 4,\n",
       "             328005: 8,\n",
       "             328006: 0,\n",
       "             328007: 3,\n",
       "             328011: 3,\n",
       "             328012: 3,\n",
       "             328013: 1,\n",
       "             328015: 1,\n",
       "             328016: 4,\n",
       "             328017: 3,\n",
       "             328018: 3,\n",
       "             328022: 0,\n",
       "             328024: 4,\n",
       "             328025: 3,\n",
       "             328026: 4,\n",
       "             328028: 4,\n",
       "             328029: 0,\n",
       "             328031: 3,\n",
       "             328033: 4,\n",
       "             328034: 0,\n",
       "             328037: 5,\n",
       "             328039: 0,\n",
       "             328040: 0,\n",
       "             328041: 1,\n",
       "             328043: 4,\n",
       "             328045: 3,\n",
       "             328046: 3,\n",
       "             328048: 3,\n",
       "             328049: 9,\n",
       "             328050: 1,\n",
       "             328051: 0,\n",
       "             328052: 0,\n",
       "             328054: 0,\n",
       "             328055: 5,\n",
       "             328057: 1,\n",
       "             328058: 0,\n",
       "             328061: 3,\n",
       "             328062: 1,\n",
       "             328063: 0,\n",
       "             328067: 4,\n",
       "             328068: 3,\n",
       "             328071: 3,\n",
       "             328072: 3,\n",
       "             328073: 4,\n",
       "             328075: 3,\n",
       "             328076: 4,\n",
       "             328078: 3,\n",
       "             328079: 4,\n",
       "             328080: 4,\n",
       "             328082: 1,\n",
       "             328083: 0,\n",
       "             328084: 0,\n",
       "             328085: 0,\n",
       "             328087: 4,\n",
       "             328088: 3,\n",
       "             328089: 3,\n",
       "             328090: 0,\n",
       "             328091: 3,\n",
       "             328092: 1,\n",
       "             328094: 3,\n",
       "             328095: 3,\n",
       "             328096: 0,\n",
       "             328101: 3,\n",
       "             328103: 4,\n",
       "             328104: 1,\n",
       "             328105: 0,\n",
       "             328106: 0,\n",
       "             328107: 0,\n",
       "             328108: 4,\n",
       "             328109: 3,\n",
       "             328110: 1,\n",
       "             328111: 1,\n",
       "             328112: 1,\n",
       "             328114: 3,\n",
       "             328115: 0,\n",
       "             328116: 0,\n",
       "             328117: 10,\n",
       "             328119: 5,\n",
       "             328120: 3,\n",
       "             328121: 3,\n",
       "             328124: 3,\n",
       "             328127: 0,\n",
       "             328129: 3,\n",
       "             328130: 4,\n",
       "             328131: 4,\n",
       "             328132: 4,\n",
       "             328133: 1,\n",
       "             328136: 4,\n",
       "             328137: 0,\n",
       "             328141: 1,\n",
       "             328143: 4,\n",
       "             328144: 4,\n",
       "             328145: 0,\n",
       "             328146: 3,\n",
       "             328147: 4,\n",
       "             328148: 3,\n",
       "             328149: 3,\n",
       "             328151: 3,\n",
       "             328153: 5,\n",
       "             328154: 3,\n",
       "             328156: 3,\n",
       "             328160: 0,\n",
       "             328163: 3,\n",
       "             328164: 4,\n",
       "             328167: 3,\n",
       "             328168: 4,\n",
       "             328170: 4,\n",
       "             328171: 4,\n",
       "             328172: 1,\n",
       "             328174: 3,\n",
       "             328176: 4,\n",
       "             328177: 1,\n",
       "             328178: 0,\n",
       "             328180: 3,\n",
       "             328181: 3,\n",
       "             328182: 4,\n",
       "             328183: 4,\n",
       "             328184: 4,\n",
       "             328185: 4,\n",
       "             328186: 3,\n",
       "             328187: 0,\n",
       "             328188: 0,\n",
       "             328189: 4,\n",
       "             328190: 0,\n",
       "             328194: 4,\n",
       "             328195: 3,\n",
       "             328196: 0,\n",
       "             328197: 4,\n",
       "             328200: 4,\n",
       "             328201: 1,\n",
       "             328203: 3,\n",
       "             328204: 4,\n",
       "             328205: 3,\n",
       "             328207: 4,\n",
       "             328208: 3,\n",
       "             328209: 0,\n",
       "             328211: 4,\n",
       "             328212: 4,\n",
       "             328213: 0,\n",
       "             328215: 3,\n",
       "             328218: 4,\n",
       "             328219: 0,\n",
       "             328221: 3,\n",
       "             328225: 0,\n",
       "             328227: 3,\n",
       "             328229: 3,\n",
       "             328230: 0,\n",
       "             328231: 0,\n",
       "             328233: 0,\n",
       "             328236: 9,\n",
       "             328238: 3,\n",
       "             328240: 4,\n",
       "             328241: 4,\n",
       "             328242: 3,\n",
       "             328244: 4,\n",
       "             328245: 0,\n",
       "             328247: 0,\n",
       "             328248: 1,\n",
       "             328249: 0,\n",
       "             328250: 0,\n",
       "             328251: 0,\n",
       "             328252: 4,\n",
       "             328253: 0,\n",
       "             328255: 4,\n",
       "             328256: 1,\n",
       "             328258: 4,\n",
       "             328259: 4,\n",
       "             328260: 1,\n",
       "             328261: 3,\n",
       "             328263: 4,\n",
       "             328265: 3,\n",
       "             328270: 9,\n",
       "             328271: 0,\n",
       "             328273: 3,\n",
       "             328275: 4,\n",
       "             328276: 0,\n",
       "             328278: 3,\n",
       "             328279: 1,\n",
       "             328280: 3,\n",
       "             328283: 4,\n",
       "             328284: 4,\n",
       "             328285: 3,\n",
       "             328286: 1,\n",
       "             328287: 4,\n",
       "             328288: 4,\n",
       "             328289: 5,\n",
       "             328290: 3,\n",
       "             328292: 4,\n",
       "             328293: 1,\n",
       "             328296: 0,\n",
       "             328298: 0,\n",
       "             328303: 3,\n",
       "             328304: 3,\n",
       "             328305: 0,\n",
       "             328307: 0,\n",
       "             328310: 1,\n",
       "             328311: 3,\n",
       "             328313: 0,\n",
       "             328321: 3,\n",
       "             328325: 0,\n",
       "             328326: 0,\n",
       "             328327: 0,\n",
       "             328328: 4,\n",
       "             328329: 0,\n",
       "             328330: 4,\n",
       "             328331: 3,\n",
       "             328332: 4,\n",
       "             328333: 3,\n",
       "             328337: 0,\n",
       "             328341: 3,\n",
       "             328344: 1,\n",
       "             328345: 3,\n",
       "             328346: 0,\n",
       "             328347: 0,\n",
       "             328348: 1,\n",
       "             328349: 0,\n",
       "             328350: 4,\n",
       "             328352: 0,\n",
       "             328356: 1,\n",
       "             328358: 3,\n",
       "             328359: 3,\n",
       "             328360: 4,\n",
       "             328363: 0,\n",
       "             328365: 1,\n",
       "             328366: 3,\n",
       "             328367: 4,\n",
       "             328368: 4,\n",
       "             328373: 4,\n",
       "             328375: 0,\n",
       "             328377: 4,\n",
       "             328379: 1,\n",
       "             328380: 4,\n",
       "             328383: 1,\n",
       "             328384: 3,\n",
       "             328385: 4,\n",
       "             328389: 4,\n",
       "             328390: 4,\n",
       "             328391: 0,\n",
       "             328392: 4,\n",
       "             328395: 3,\n",
       "             328397: 0,\n",
       "             328398: 3,\n",
       "             328399: 4,\n",
       "             328401: 0,\n",
       "             328402: 3,\n",
       "             328403: 0,\n",
       "             328405: 3,\n",
       "             328406: 4,\n",
       "             328407: 1,\n",
       "             328408: 1,\n",
       "             328409: 3,\n",
       "             328412: 0,\n",
       "             328413: 3,\n",
       "             328414: 9,\n",
       "             328415: 4,\n",
       "             328417: 1,\n",
       "             328418: 4,\n",
       "             328419: 1,\n",
       "             328421: 1,\n",
       "             328422: 4,\n",
       "             328423: 3,\n",
       "             328424: 4,\n",
       "             328425: 0,\n",
       "             328426: 1,\n",
       "             328427: 4,\n",
       "             328432: 4,\n",
       "             328434: 4,\n",
       "             328436: 0,\n",
       "             328437: 0,\n",
       "             328439: 4,\n",
       "             328441: 0,\n",
       "             328442: 0,\n",
       "             328443: 1,\n",
       "             328445: 0,\n",
       "             328447: 3,\n",
       "             328450: 3,\n",
       "             328451: 1,\n",
       "             328452: 0,\n",
       "             328453: 3,\n",
       "             328454: 3,\n",
       "             328455: 3,\n",
       "             328457: 0,\n",
       "             328459: 0,\n",
       "             328460: 1,\n",
       "             328461: 4,\n",
       "             328463: 4,\n",
       "             328466: 4,\n",
       "             328467: 3,\n",
       "             328468: 4,\n",
       "             328470: 0,\n",
       "             328472: 0,\n",
       "             328473: 3,\n",
       "             328477: 3,\n",
       "             328479: 4,\n",
       "             328480: 0,\n",
       "             328484: 3,\n",
       "             328485: 4,\n",
       "             328486: 4,\n",
       "             328488: 3,\n",
       "             328489: 3,\n",
       "             328490: 4,\n",
       "             328491: 3,\n",
       "             328492: 3,\n",
       "             328493: 3,\n",
       "             328494: 4,\n",
       "             328496: 3,\n",
       "             328498: 4,\n",
       "             328499: 0,\n",
       "             328500: 3,\n",
       "             328501: 0,\n",
       "             328502: 4,\n",
       "             328503: 3,\n",
       "             328504: 1,\n",
       "             328505: 0,\n",
       "             328506: 0,\n",
       "             328507: 3,\n",
       "             328508: 12,\n",
       "             328509: 0,\n",
       "             328510: 1,\n",
       "             328516: 1,\n",
       "             328518: 1,\n",
       "             328522: 4,\n",
       "             328523: 4,\n",
       "             328524: 4,\n",
       "             328528: 4,\n",
       "             328529: 3,\n",
       "             328530: 3,\n",
       "             328531: 0,\n",
       "             328533: 4,\n",
       "             328534: 3,\n",
       "             328535: 0,\n",
       "             328536: 4,\n",
       "             328538: 0,\n",
       "             328539: 4,\n",
       "             328543: 0,\n",
       "             328545: 4,\n",
       "             328547: 4,\n",
       "             328550: 13,\n",
       "             328551: 1,\n",
       "             328552: 0,\n",
       "             328553: 0,\n",
       "             328554: 4,\n",
       "             328555: 0,\n",
       "             328556: 0,\n",
       "             328557: 0,\n",
       "             328559: 0,\n",
       "             328561: 4,\n",
       "             328562: 1,\n",
       "             328563: 1,\n",
       "             328564: 0,\n",
       "             328566: 0,\n",
       "             328567: 3,\n",
       "             328568: 3,\n",
       "             328569: 3,\n",
       "             328571: 3,\n",
       "             328572: 1,\n",
       "             328574: 1,\n",
       "             328576: 0,\n",
       "             328577: 0,\n",
       "             328579: 1,\n",
       "             328580: 4,\n",
       "             328582: 3,\n",
       "             328583: 3,\n",
       "             328584: 0,\n",
       "             328585: 4,\n",
       "             328589: 4,\n",
       "             328590: 3,\n",
       "             328592: 1,\n",
       "             328593: 3,\n",
       "             328594: 3,\n",
       "             328596: 3,\n",
       "             328597: 3,\n",
       "             328600: 4,\n",
       "             328604: 14,\n",
       "             328605: 1,\n",
       "             328606: 0,\n",
       "             328607: 0,\n",
       "             328609: 3,\n",
       "             328610: 0,\n",
       "             328613: 0,\n",
       "             328615: 1,\n",
       "             328616: 4,\n",
       "             328618: 15,\n",
       "             328619: 1,\n",
       "             328622: 4,\n",
       "             328624: 3,\n",
       "             328625: 0,\n",
       "             328626: 3,\n",
       "             328629: 4,\n",
       "             328630: 0,\n",
       "             328631: 4,\n",
       "             328632: 4,\n",
       "             328633: 1,\n",
       "             328635: 0,\n",
       "             328637: 1,\n",
       "             328640: 1,\n",
       "             328644: 1,\n",
       "             328645: 4,\n",
       "             328648: 3,\n",
       "             328649: 0,\n",
       "             328650: 14,\n",
       "             328653: 1,\n",
       "             328655: 1,\n",
       "             328658: 4,\n",
       "             328659: 3,\n",
       "             328661: 4,\n",
       "             328663: 3,\n",
       "             328664: 4,\n",
       "             328665: 3,\n",
       "             328666: 0,\n",
       "             328667: 3,\n",
       "             328668: 0,\n",
       "             328672: 0,\n",
       "             328673: 4,\n",
       "             328674: 3,\n",
       "             328675: 0,\n",
       "             328677: 4,\n",
       "             328678: 1,\n",
       "             328679: 1,\n",
       "             328681: 4,\n",
       "             328682: 3,\n",
       "             328683: 4,\n",
       "             328684: 1,\n",
       "             328685: 1,\n",
       "             328686: 3,\n",
       "             328687: 1,\n",
       "             328688: 0,\n",
       "             328690: 0,\n",
       "             328691: 4,\n",
       "             328692: 4,\n",
       "             328693: 0,\n",
       "             328694: 3,\n",
       "             328698: 4,\n",
       "             328699: 4,\n",
       "             328701: 3,\n",
       "             328702: 3,\n",
       "             328703: 1,\n",
       "             328704: 3,\n",
       "             328705: 16,\n",
       "             328707: 4,\n",
       "             328710: 4,\n",
       "             328712: 4,\n",
       "             328714: 4,\n",
       "             328715: 0,\n",
       "             328716: 4,\n",
       "             328717: 3,\n",
       "             328718: 4,\n",
       "             328719: 4,\n",
       "             328720: 3,\n",
       "             328721: 4,\n",
       "             328722: 0,\n",
       "             328723: 4,\n",
       "             328724: 4,\n",
       "             328725: 1,\n",
       "             328726: 0,\n",
       "             328728: 1,\n",
       "             328729: 0,\n",
       "             328731: 1,\n",
       "             328733: 3,\n",
       "             328734: 0,\n",
       "             328735: 3,\n",
       "             328737: 4,\n",
       "             328738: 3,\n",
       "             328743: 0,\n",
       "             328744: 4,\n",
       "             328745: 3,\n",
       "             328746: 4,\n",
       "             328747: 3,\n",
       "             328749: 0,\n",
       "             328750: 1,\n",
       "             328751: 3,\n",
       "             328752: 3,\n",
       "             328753: 4,\n",
       "             328754: 3,\n",
       "             328757: 3,\n",
       "             328760: 3,\n",
       "             328762: 3,\n",
       "             328765: 3,\n",
       "             328766: 3,\n",
       "             328767: 4,\n",
       "             328769: 9,\n",
       "             328772: 3,\n",
       "             328774: 0,\n",
       "             328775: 0,\n",
       "             328776: 1,\n",
       "             328777: 3,\n",
       "             328778: 0,\n",
       "             328779: 3,\n",
       "             328780: 1,\n",
       "             328784: 3,\n",
       "             328788: 4,\n",
       "             328790: 4,\n",
       "             328791: 3,\n",
       "             328794: 1,\n",
       "             328795: 3,\n",
       "             328796: 4,\n",
       "             328798: 3,\n",
       "             328801: 4,\n",
       "             328802: 0,\n",
       "             328803: 3,\n",
       "             328806: 4,\n",
       "             328807: 0,\n",
       "             328808: 3,\n",
       "             328809: 1,\n",
       "             328810: 3,\n",
       "             328813: 3,\n",
       "             328814: 4,\n",
       "             328819: 4,\n",
       "             328820: 4,\n",
       "             328821: 1,\n",
       "             328822: 4,\n",
       "             328824: 4,\n",
       "             328825: 4,\n",
       "             328826: 4,\n",
       "             328827: 1,\n",
       "             328828: 4,\n",
       "             328830: 3,\n",
       "             328831: 4,\n",
       "             328832: 0,\n",
       "             328833: 4,\n",
       "             328834: 1,\n",
       "             328835: 3,\n",
       "             328836: 4,\n",
       "             328837: 4,\n",
       "             328841: 3,\n",
       "             328843: 4,\n",
       "             328844: 1,\n",
       "             328845: 0,\n",
       "             328846: 3,\n",
       "             328850: 4,\n",
       "             328851: 4,\n",
       "             328852: 3,\n",
       "             328854: 3,\n",
       "             328855: 3,\n",
       "             328856: 3,\n",
       "             328857: 0,\n",
       "             328858: 3,\n",
       "             328859: 3,\n",
       "             328860: 0,\n",
       "             328862: 3,\n",
       "             328863: 3,\n",
       "             328866: 4,\n",
       "             328867: 0,\n",
       "             328868: 3,\n",
       "             328869: 3,\n",
       "             328872: 4,\n",
       "             328874: 4,\n",
       "             328875: 4,\n",
       "             328877: 4,\n",
       "             328879: 3,\n",
       "             328880: 4,\n",
       "             328881: 1,\n",
       "             328882: 3,\n",
       "             328884: 7,\n",
       "             328886: 3,\n",
       "             328887: 3,\n",
       "             328888: 4,\n",
       "             328889: 3,\n",
       "             328890: 1,\n",
       "             328891: 4,\n",
       "             328892: 4,\n",
       "             328893: 0,\n",
       "             328894: 3,\n",
       "             328897: 3,\n",
       "             328898: 0,\n",
       "             328899: 0,\n",
       "             328900: 0,\n",
       "             328901: 3,\n",
       "             328902: 3,\n",
       "             328903: 4,\n",
       "             328905: 1,\n",
       "             328906: 0,\n",
       "             328910: 0,\n",
       "             328912: 4,\n",
       "             328915: 0,\n",
       "             328919: 3,\n",
       "             328921: 4,\n",
       "             328923: 0,\n",
       "             328924: 1,\n",
       "             328926: 3,\n",
       "             328927: 3,\n",
       "             328928: 0,\n",
       "             328929: 4,\n",
       "             328930: 0,\n",
       "             328932: 0,\n",
       "             328933: 0,\n",
       "             328934: 4,\n",
       "             328935: 0,\n",
       "             328938: 1,\n",
       "             328939: 4,\n",
       "             328940: 0,\n",
       "             328941: 4,\n",
       "             328942: 1,\n",
       "             328943: 1,\n",
       "             328944: 4,\n",
       "             328945: 1,\n",
       "             328947: 3,\n",
       "             328948: 1,\n",
       "             328950: 4,\n",
       "             328953: 4,\n",
       "             328954: 1,\n",
       "             328955: 4,\n",
       "             328956: 4,\n",
       "             328957: 0,\n",
       "             328960: 0,\n",
       "             328961: 4,\n",
       "             328962: 4,\n",
       "             328963: 4,\n",
       "             328964: 4,\n",
       "             328965: 3,\n",
       "             328966: 5,\n",
       "             328967: 0,\n",
       "             328968: 3,\n",
       "             328972: 0,\n",
       "             328974: 3,\n",
       "             328975: 4,\n",
       "             328978: 3,\n",
       "             328979: 1,\n",
       "             328980: 3,\n",
       "             328981: 3,\n",
       "             328982: 4,\n",
       "             328983: 3,\n",
       "             328984: 1,\n",
       "             328985: 5,\n",
       "             328986: 5,\n",
       "             328988: 3,\n",
       "             328989: 4,\n",
       "             328991: 0,\n",
       "             328993: 3,\n",
       "             328994: 4,\n",
       "             328995: 3,\n",
       "             328996: 4,\n",
       "             328998: 3,\n",
       "             328999: 3,\n",
       "             329001: 1,\n",
       "             329002: 0,\n",
       "             329003: 4,\n",
       "             329005: 3,\n",
       "             329007: 0,\n",
       "             329008: 3,\n",
       "             329009: 3,\n",
       "             329010: 3,\n",
       "             329011: 0,\n",
       "             329012: 4,\n",
       "             329016: 1,\n",
       "             329017: 4,\n",
       "             329020: 3,\n",
       "             329022: 5,\n",
       "             329023: 3,\n",
       "             329024: 0,\n",
       "             329025: 0,\n",
       "             329026: 3,\n",
       "             329027: 3,\n",
       "             329029: 4,\n",
       "             329031: 4,\n",
       "             329032: 4,\n",
       "             329036: 4,\n",
       "             329037: 3,\n",
       "             329038: 3,\n",
       "             329039: 0,\n",
       "             329040: 1,\n",
       "             329042: 1,\n",
       "             329043: 1,\n",
       "             329044: 3,\n",
       "             329046: 3,\n",
       "             329047: 3,\n",
       "             329048: 3,\n",
       "             329049: 1,\n",
       "             329052: 4,\n",
       "             329054: 4,\n",
       "             329056: 4,\n",
       "             329057: 0,\n",
       "             329058: 4,\n",
       "             329059: 1,\n",
       "             329060: 4,\n",
       "             329061: 4,\n",
       "             329062: 3,\n",
       "             329063: 4,\n",
       "             329064: 4,\n",
       "             329065: 4,\n",
       "             329066: 3,\n",
       "             329068: 3,\n",
       "             329069: 4,\n",
       "             329070: 3,\n",
       "             329072: 0,\n",
       "             329073: 3,\n",
       "             329074: 3,\n",
       "             329075: 0,\n",
       "             329076: 4,\n",
       "             329077: 3,\n",
       "             329078: 1,\n",
       "             329079: 1,\n",
       "             329080: 1,\n",
       "             329081: 4,\n",
       "             329082: 4,\n",
       "             329084: 3,\n",
       "             329085: 0,\n",
       "             329086: 0,\n",
       "             329089: 1,\n",
       "             329090: 0,\n",
       "             329091: 3,\n",
       "             329093: 17,\n",
       "             329094: 0,\n",
       "             329097: 0,\n",
       "             329098: 0,\n",
       "             329100: 9,\n",
       "             329101: 3,\n",
       "             329102: 3,\n",
       "             329103: 3,\n",
       "             329104: 4,\n",
       "             329106: 3,\n",
       "             329107: 0,\n",
       "             329108: 3,\n",
       "             329112: 0,\n",
       "             329113: 1,\n",
       "             329114: 3,\n",
       "             329115: 4,\n",
       "             329116: 3,\n",
       "             329117: 3,\n",
       "             329121: 0,\n",
       "             329122: 3,\n",
       "             329123: 0,\n",
       "             329124: 1,\n",
       "             329126: 3,\n",
       "             329130: 3,\n",
       "             329131: 0,\n",
       "             329133: 1,\n",
       "             329135: 1,\n",
       "             329136: 4,\n",
       "             329138: 3,\n",
       "             329140: 0,\n",
       "             329141: 0,\n",
       "             329144: 3,\n",
       "             329145: 4,\n",
       "             329146: 3,\n",
       "             329147: 4,\n",
       "             329148: 3,\n",
       "             329149: 3,\n",
       "             329150: 13,\n",
       "             329151: 1,\n",
       "             329152: 1,\n",
       "             329155: 3,\n",
       "             329157: 4,\n",
       "             329162: 1,\n",
       "             329164: 0,\n",
       "             329165: 0,\n",
       "             329166: 3,\n",
       "             329167: 4,\n",
       "             329170: 4,\n",
       "             329171: 0,\n",
       "             329173: 1,\n",
       "             329174: 0,\n",
       "             329175: 4,\n",
       "             329177: 4,\n",
       "             329179: 0,\n",
       "             329181: 1,\n",
       "             329183: 1,\n",
       "             329186: 3,\n",
       "             329187: 5,\n",
       "             329188: 4,\n",
       "             329189: 4,\n",
       "             329190: 0,\n",
       "             329191: 0,\n",
       "             329192: 1,\n",
       "             329194: 0,\n",
       "             329195: 0,\n",
       "             329196: 1,\n",
       "             329197: 4,\n",
       "             329199: 4,\n",
       "             329200: 1,\n",
       "             329201: 1,\n",
       "             329202: 4,\n",
       "             329204: 3,\n",
       "             329205: 0,\n",
       "             329207: 4,\n",
       "             329208: 1,\n",
       "             329212: 3,\n",
       "             329214: 1,\n",
       "             329215: 4,\n",
       "             329216: 1,\n",
       "             329217: 4,\n",
       "             329218: 4,\n",
       "             329219: 4,\n",
       "             329221: 3,\n",
       "             329223: 3,\n",
       "             329224: 1,\n",
       "             329226: 4,\n",
       "             329229: 4,\n",
       "             329230: 3,\n",
       "             ...})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnm clustering\n",
    "pickle_f2 = open(CNM_COMMUNITIES_PICKLE, 'rb')\n",
    "community_dict = pickle.load(pickle_f2)\n",
    "pickle_f2.close()\n",
    "\n",
    "community_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "      <th>Community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>317788</td>\n",
       "      <td>187855</td>\n",
       "      <td>th level</td>\n",
       "      <td>effect th</td>\n",
       "      <td>factor</td>\n",
       "      <td>level factor</td>\n",
       "      <td>levene</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>318375</td>\n",
       "      <td>122192</td>\n",
       "      <td>factor</td>\n",
       "      <td>variables clustering</td>\n",
       "      <td>clustering</td>\n",
       "      <td>dataframe</td>\n",
       "      <td>numerical</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>318976</td>\n",
       "      <td>164061</td>\n",
       "      <td>alias</td>\n",
       "      <td>column</td>\n",
       "      <td>factors</td>\n",
       "      <td>factor</td>\n",
       "      <td>dummy</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>319526</td>\n",
       "      <td>85650</td>\n",
       "      <td>loadings</td>\n",
       "      <td>sign</td>\n",
       "      <td>varimax</td>\n",
       "      <td>factor</td>\n",
       "      <td>sign factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>320895</td>\n",
       "      <td>26456</td>\n",
       "      <td>subjects subjects</td>\n",
       "      <td>dfs</td>\n",
       "      <td>subjects</td>\n",
       "      <td>factor</td>\n",
       "      <td>returns</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>321472</td>\n",
       "      <td>129390</td>\n",
       "      <td>communalities</td>\n",
       "      <td>efa</td>\n",
       "      <td>factor</td>\n",
       "      <td>eigenvalue</td>\n",
       "      <td>accounted variance</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>321886</td>\n",
       "      <td>187640</td>\n",
       "      <td>irt</td>\n",
       "      <td>cfa</td>\n",
       "      <td>factor cfa</td>\n",
       "      <td>factor</td>\n",
       "      <td>single factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>322430</td>\n",
       "      <td>8013</td>\n",
       "      <td>analysis</td>\n",
       "      <td>complete factor</td>\n",
       "      <td>complete</td>\n",
       "      <td>factor</td>\n",
       "      <td>consider complete</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>324173</td>\n",
       "      <td>192279</td>\n",
       "      <td>dk</td>\n",
       "      <td>wrong dk</td>\n",
       "      <td>factor analysis</td>\n",
       "      <td>scale wrong</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>324282</td>\n",
       "      <td>26569</td>\n",
       "      <td>portfolio</td>\n",
       "      <td>portfolio factor</td>\n",
       "      <td>averaged time</td>\n",
       "      <td>fama</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>324588</td>\n",
       "      <td>40634</td>\n",
       "      <td>factor</td>\n",
       "      <td>factor factor</td>\n",
       "      <td>factor combinations</td>\n",
       "      <td>studentized</td>\n",
       "      <td>measurements</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>324969</td>\n",
       "      <td>192795</td>\n",
       "      <td>factors</td>\n",
       "      <td>problem</td>\n",
       "      <td>data item</td>\n",
       "      <td>factor</td>\n",
       "      <td>2n</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>326772</td>\n",
       "      <td>123700</td>\n",
       "      <td>load</td>\n",
       "      <td>factors</td>\n",
       "      <td>factor</td>\n",
       "      <td>subgeneral</td>\n",
       "      <td>trifactor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>327337</td>\n",
       "      <td>194464</td>\n",
       "      <td>factor</td>\n",
       "      <td>factor factor</td>\n",
       "      <td>interaction factor</td>\n",
       "      <td>covariate interaction</td>\n",
       "      <td>factor significant</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>327894</td>\n",
       "      <td>59951</td>\n",
       "      <td>ancova</td>\n",
       "      <td>ancova used</td>\n",
       "      <td>covariate</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>328013</td>\n",
       "      <td>81743</td>\n",
       "      <td>ignored</td>\n",
       "      <td>factor</td>\n",
       "      <td>numeric</td>\n",
       "      <td>column factor</td>\n",
       "      <td>column happens</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>328024</td>\n",
       "      <td>194945</td>\n",
       "      <td>plot factor</td>\n",
       "      <td>site factor</td>\n",
       "      <td>split plot</td>\n",
       "      <td>factor</td>\n",
       "      <td>site</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8603</th>\n",
       "      <td>328655</td>\n",
       "      <td>139121</td>\n",
       "      <td>items</td>\n",
       "      <td>factor</td>\n",
       "      <td>th</td>\n",
       "      <td>according weights</td>\n",
       "      <td>believe distribution</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>330177</td>\n",
       "      <td>162705</td>\n",
       "      <td>factor analysis</td>\n",
       "      <td>psych package</td>\n",
       "      <td>loadings</td>\n",
       "      <td>common variance</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9788</th>\n",
       "      <td>330229</td>\n",
       "      <td>148743</td>\n",
       "      <td>factor different</td>\n",
       "      <td>factor</td>\n",
       "      <td>control condition</td>\n",
       "      <td>condition</td>\n",
       "      <td>linear mixed</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10823</th>\n",
       "      <td>331571</td>\n",
       "      <td>143094</td>\n",
       "      <td>insignificant variance</td>\n",
       "      <td>insignificant</td>\n",
       "      <td>items</td>\n",
       "      <td>items loading</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10965</th>\n",
       "      <td>331752</td>\n",
       "      <td>17072</td>\n",
       "      <td>cfa</td>\n",
       "      <td>confirmatory factor</td>\n",
       "      <td>confirmatory</td>\n",
       "      <td>factor analysis</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>331790</td>\n",
       "      <td>76762</td>\n",
       "      <td>factor</td>\n",
       "      <td>factor analysis</td>\n",
       "      <td>personality</td>\n",
       "      <td>personality dimension</td>\n",
       "      <td>principal</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11733</th>\n",
       "      <td>332769</td>\n",
       "      <td>198276</td>\n",
       "      <td>factors</td>\n",
       "      <td>level</td>\n",
       "      <td>levels</td>\n",
       "      <td>factor</td>\n",
       "      <td>3rd factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12139</th>\n",
       "      <td>333297</td>\n",
       "      <td>183208</td>\n",
       "      <td>chain</td>\n",
       "      <td>factor</td>\n",
       "      <td>store</td>\n",
       "      <td>shop</td>\n",
       "      <td>store chains</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12861</th>\n",
       "      <td>335242</td>\n",
       "      <td>188154</td>\n",
       "      <td>called factor</td>\n",
       "      <td>factor</td>\n",
       "      <td>coefficients</td>\n",
       "      <td>constituent variables</td>\n",
       "      <td>factor constituent</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>335293</td>\n",
       "      <td>200417</td>\n",
       "      <td>factor</td>\n",
       "      <td>factor level</td>\n",
       "      <td>level</td>\n",
       "      <td>appears thinking</td>\n",
       "      <td>combinations removes</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13527</th>\n",
       "      <td>336105</td>\n",
       "      <td>53456</td>\n",
       "      <td>latent</td>\n",
       "      <td>loadings</td>\n",
       "      <td>factor</td>\n",
       "      <td>factor loadings</td>\n",
       "      <td>latent variables</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13745</th>\n",
       "      <td>336384</td>\n",
       "      <td>199063</td>\n",
       "      <td>latent factor</td>\n",
       "      <td>factor</td>\n",
       "      <td>solutions</td>\n",
       "      <td>latent</td>\n",
       "      <td>efa</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14371</th>\n",
       "      <td>337228</td>\n",
       "      <td>102192</td>\n",
       "      <td>factors</td>\n",
       "      <td>factor analysis</td>\n",
       "      <td>number factors</td>\n",
       "      <td>factor</td>\n",
       "      <td>number</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14804</th>\n",
       "      <td>337791</td>\n",
       "      <td>163114</td>\n",
       "      <td>factor</td>\n",
       "      <td>indicators</td>\n",
       "      <td>factors displayed</td>\n",
       "      <td>set indicators</td>\n",
       "      <td>factors</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14922</th>\n",
       "      <td>337949</td>\n",
       "      <td>202507</td>\n",
       "      <td>factor</td>\n",
       "      <td>factor model</td>\n",
       "      <td>subgroup</td>\n",
       "      <td>factor explains</td>\n",
       "      <td>percent variance</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15128</th>\n",
       "      <td>338218</td>\n",
       "      <td>53456</td>\n",
       "      <td>multilevel</td>\n",
       "      <td>multilevel factor</td>\n",
       "      <td>factor analysis</td>\n",
       "      <td>muthen</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>338576</td>\n",
       "      <td>149096</td>\n",
       "      <td>factor solution</td>\n",
       "      <td>generated</td>\n",
       "      <td>factor</td>\n",
       "      <td>generated data</td>\n",
       "      <td>solution</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15557</th>\n",
       "      <td>338780</td>\n",
       "      <td>199063</td>\n",
       "      <td>uvi</td>\n",
       "      <td>loadings</td>\n",
       "      <td>latent</td>\n",
       "      <td>latent variables</td>\n",
       "      <td>run uvi</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16138</th>\n",
       "      <td>339555</td>\n",
       "      <td>158856</td>\n",
       "      <td>factor</td>\n",
       "      <td>trays</td>\n",
       "      <td>blocking factor</td>\n",
       "      <td>factor treatment</td>\n",
       "      <td>blocking</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16140</th>\n",
       "      <td>339557</td>\n",
       "      <td>188851</td>\n",
       "      <td>aic</td>\n",
       "      <td>factor</td>\n",
       "      <td>aic value</td>\n",
       "      <td>change aic</td>\n",
       "      <td>factor change</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16386</th>\n",
       "      <td>339868</td>\n",
       "      <td>198635</td>\n",
       "      <td>factor</td>\n",
       "      <td>latent factor</td>\n",
       "      <td>load</td>\n",
       "      <td>factor analysis</td>\n",
       "      <td>remember</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>340542</td>\n",
       "      <td>202968</td>\n",
       "      <td>rfe</td>\n",
       "      <td>factor</td>\n",
       "      <td>argument vector</td>\n",
       "      <td>classes object</td>\n",
       "      <td>error task</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17087</th>\n",
       "      <td>340793</td>\n",
       "      <td>204577</td>\n",
       "      <td>factor rotation</td>\n",
       "      <td>rotation</td>\n",
       "      <td>factor</td>\n",
       "      <td>arbitrary procrustean</td>\n",
       "      <td>coefficient suitable</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17241</th>\n",
       "      <td>340995</td>\n",
       "      <td>198195</td>\n",
       "      <td>factor</td>\n",
       "      <td>factor scores</td>\n",
       "      <td>scores</td>\n",
       "      <td>loyalty</td>\n",
       "      <td>satisfaction</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17555</th>\n",
       "      <td>341407</td>\n",
       "      <td>199063</td>\n",
       "      <td>factor</td>\n",
       "      <td>factors</td>\n",
       "      <td>cloud</td>\n",
       "      <td>latent</td>\n",
       "      <td>cloud points</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17818</th>\n",
       "      <td>341743</td>\n",
       "      <td>205238</td>\n",
       "      <td>emotion</td>\n",
       "      <td>emotion differentiation</td>\n",
       "      <td>differentiation</td>\n",
       "      <td>loadings</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17828</th>\n",
       "      <td>341755</td>\n",
       "      <td>52554</td>\n",
       "      <td>factor</td>\n",
       "      <td>comparisons</td>\n",
       "      <td>comparisons pairwise</td>\n",
       "      <td>explicitly obtain</td>\n",
       "      <td>factor combination</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18460</th>\n",
       "      <td>342623</td>\n",
       "      <td>205826</td>\n",
       "      <td>factor extraction</td>\n",
       "      <td>factor</td>\n",
       "      <td>extraction</td>\n",
       "      <td>cortable</td>\n",
       "      <td>extraction methods</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675</th>\n",
       "      <td>342897</td>\n",
       "      <td>206002</td>\n",
       "      <td>factor scores</td>\n",
       "      <td>paf</td>\n",
       "      <td>structure matrix</td>\n",
       "      <td>tetrachoric</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19142</th>\n",
       "      <td>343463</td>\n",
       "      <td>178588</td>\n",
       "      <td>minitab</td>\n",
       "      <td>block</td>\n",
       "      <td>block factor</td>\n",
       "      <td>factor covariates</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19147</th>\n",
       "      <td>343470</td>\n",
       "      <td>206373</td>\n",
       "      <td>items correlated</td>\n",
       "      <td>factor model</td>\n",
       "      <td>correlated residuals</td>\n",
       "      <td>factor</td>\n",
       "      <td>items</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19267</th>\n",
       "      <td>343626</td>\n",
       "      <td>159259</td>\n",
       "      <td>bias</td>\n",
       "      <td>factor scores</td>\n",
       "      <td>factor</td>\n",
       "      <td>avoiding method</td>\n",
       "      <td>bias avoiding</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19752</th>\n",
       "      <td>344279</td>\n",
       "      <td>206936</td>\n",
       "      <td>fixed factor</td>\n",
       "      <td>know fixed</td>\n",
       "      <td>disease</td>\n",
       "      <td>affect</td>\n",
       "      <td>factor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  user_id                TopWord1                 TopWord2  \\\n",
       "67      317788   187855                th level                effect th   \n",
       "526     318375   122192                  factor     variables clustering   \n",
       "990     318976   164061                   alias                   column   \n",
       "1417    319526    85650                loadings                     sign   \n",
       "2466    320895    26456       subjects subjects                      dfs   \n",
       "2930    321472   129390           communalities                      efa   \n",
       "3252    321886   187640                     irt                      cfa   \n",
       "3672    322430     8013                analysis          complete factor   \n",
       "5036    324173   192279                      dk                 wrong dk   \n",
       "5116    324282    26569               portfolio         portfolio factor   \n",
       "5355    324588    40634                  factor            factor factor   \n",
       "5664    324969   192795                 factors                  problem   \n",
       "7126    326772   123700                    load                  factors   \n",
       "7592    327337   194464                  factor            factor factor   \n",
       "8026    327894    59951                  ancova              ancova used   \n",
       "8116    328013    81743                 ignored                   factor   \n",
       "8125    328024   194945             plot factor              site factor   \n",
       "8603    328655   139121                   items                   factor   \n",
       "9752    330177   162705         factor analysis            psych package   \n",
       "9788    330229   148743        factor different                   factor   \n",
       "10823   331571   143094  insignificant variance            insignificant   \n",
       "10965   331752    17072                     cfa      confirmatory factor   \n",
       "10995   331790    76762                  factor          factor analysis   \n",
       "11733   332769   198276                 factors                    level   \n",
       "12139   333297   183208                   chain                   factor   \n",
       "12861   335242   188154           called factor                   factor   \n",
       "12905   335293   200417                  factor             factor level   \n",
       "13527   336105    53456                  latent                 loadings   \n",
       "13745   336384   199063           latent factor                   factor   \n",
       "14371   337228   102192                 factors          factor analysis   \n",
       "14804   337791   163114                  factor               indicators   \n",
       "14922   337949   202507                  factor             factor model   \n",
       "15128   338218    53456              multilevel        multilevel factor   \n",
       "15399   338576   149096         factor solution                generated   \n",
       "15557   338780   199063                     uvi                 loadings   \n",
       "16138   339555   158856                  factor                    trays   \n",
       "16140   339557   188851                     aic                   factor   \n",
       "16386   339868   198635                  factor            latent factor   \n",
       "16902   340542   202968                     rfe                   factor   \n",
       "17087   340793   204577         factor rotation                 rotation   \n",
       "17241   340995   198195                  factor            factor scores   \n",
       "17555   341407   199063                  factor                  factors   \n",
       "17818   341743   205238                 emotion  emotion differentiation   \n",
       "17828   341755    52554                  factor              comparisons   \n",
       "18460   342623   205826       factor extraction                   factor   \n",
       "18675   342897   206002           factor scores                      paf   \n",
       "19142   343463   178588                 minitab                    block   \n",
       "19147   343470   206373        items correlated             factor model   \n",
       "19267   343626   159259                    bias            factor scores   \n",
       "19752   344279   206936            fixed factor               know fixed   \n",
       "\n",
       "                   TopWord3               TopWord4              TopWord5  \\\n",
       "67                   factor           level factor                levene   \n",
       "526              clustering              dataframe             numerical   \n",
       "990                 factors                 factor                 dummy   \n",
       "1417                varimax                 factor           sign factor   \n",
       "2466               subjects                 factor               returns   \n",
       "2930                 factor             eigenvalue    accounted variance   \n",
       "3252             factor cfa                 factor         single factor   \n",
       "3672               complete                 factor     consider complete   \n",
       "5036        factor analysis            scale wrong                factor   \n",
       "5116          averaged time                   fama                factor   \n",
       "5355    factor combinations            studentized          measurements   \n",
       "5664              data item                 factor                    2n   \n",
       "7126                 factor             subgeneral             trifactor   \n",
       "7592     interaction factor  covariate interaction    factor significant   \n",
       "8026              covariate               adjusted                factor   \n",
       "8116                numeric          column factor        column happens   \n",
       "8125             split plot                 factor                  site   \n",
       "8603                     th      according weights  believe distribution   \n",
       "9752               loadings        common variance                factor   \n",
       "9788      control condition              condition          linear mixed   \n",
       "10823                 items          items loading                factor   \n",
       "10965          confirmatory        factor analysis                factor   \n",
       "10995           personality  personality dimension             principal   \n",
       "11733                levels                 factor            3rd factor   \n",
       "12139                 store                   shop          store chains   \n",
       "12861          coefficients  constituent variables    factor constituent   \n",
       "12905                 level       appears thinking  combinations removes   \n",
       "13527                factor        factor loadings      latent variables   \n",
       "13745             solutions                 latent                   efa   \n",
       "14371        number factors                 factor                number   \n",
       "14804     factors displayed         set indicators               factors   \n",
       "14922              subgroup        factor explains      percent variance   \n",
       "15128       factor analysis                 muthen                factor   \n",
       "15399                factor         generated data              solution   \n",
       "15557                latent       latent variables               run uvi   \n",
       "16138       blocking factor       factor treatment              blocking   \n",
       "16140             aic value             change aic         factor change   \n",
       "16386                  load        factor analysis              remember   \n",
       "16902       argument vector         classes object            error task   \n",
       "17087                factor  arbitrary procrustean  coefficient suitable   \n",
       "17241                scores                loyalty          satisfaction   \n",
       "17555                 cloud                 latent          cloud points   \n",
       "17818       differentiation               loadings                factor   \n",
       "17828  comparisons pairwise      explicitly obtain    factor combination   \n",
       "18460            extraction               cortable    extraction methods   \n",
       "18675      structure matrix            tetrachoric                factor   \n",
       "19142          block factor      factor covariates                factor   \n",
       "19147  correlated residuals                 factor                 items   \n",
       "19267                factor        avoiding method         bias avoiding   \n",
       "19752               disease                 affect                factor   \n",
       "\n",
       "       Community  \n",
       "67            86  \n",
       "526           86  \n",
       "990           86  \n",
       "1417          86  \n",
       "2466          86  \n",
       "2930          86  \n",
       "3252          86  \n",
       "3672          86  \n",
       "5036          86  \n",
       "5116          86  \n",
       "5355          86  \n",
       "5664          86  \n",
       "7126          86  \n",
       "7592          86  \n",
       "8026          86  \n",
       "8116          86  \n",
       "8125          86  \n",
       "8603          86  \n",
       "9752          86  \n",
       "9788          86  \n",
       "10823         86  \n",
       "10965         86  \n",
       "10995         86  \n",
       "11733         86  \n",
       "12139         86  \n",
       "12861         86  \n",
       "12905         86  \n",
       "13527         86  \n",
       "13745         86  \n",
       "14371         86  \n",
       "14804         86  \n",
       "14922         86  \n",
       "15128         86  \n",
       "15399         86  \n",
       "15557         86  \n",
       "16138         86  \n",
       "16140         86  \n",
       "16386         86  \n",
       "16902         86  \n",
       "17087         86  \n",
       "17241         86  \n",
       "17555         86  \n",
       "17818         86  \n",
       "17828         86  \n",
       "18460         86  \n",
       "18675         86  \n",
       "19142         86  \n",
       "19147         86  \n",
       "19267         86  \n",
       "19752         86  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df2[post_df_w_comm2[\"Community\"] == 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8XGW9x/HPL/vSNOm+pRtt6QZtgUDZVGTfKoog25XFAsK9Air3CioqKi6oXLwuwOUCsoOIomyyKBRkp0BLKW2hG3Rf6JY2bZMmv/vHOWmn6UwySWZyZpLv+/XKK3OWOec3z5yZ35znec5zzN0RERFpKifqAEREJDMpQYiISFxKECIiEpcShIiIxKUEISIicSlBiIhIXF0yQZjZOWb2TAfv81IzW2Vmm82sV0fuOwpmdouZfa+Z5d8xs9s6MqbOxMzuNLPrEiw738xe6uiYMkVzZdPC8xab2dHpiKmVcXT491MinTZBmNnhZvaKmW00s3Vm9rKZHQjg7ve5+7EdGEs+8N/Ase7ezd0/6ah9R8XdL3H3HwOY2RFmtrTJ8p+6+4XRRBc9M3MzGxl1HJkmU76k28rMrjWze9uzjY7+fmpOXtQBpIOZdQceBy4FHgIKgE8B2yMKqR9QBMyOaP/Sgcwsz913RB1HZ9TZyzbjXp+7d7o/oArY0Mzy84GXwsffAjbH/NUBd4bLyoHbgRXAMuA6IDfBNguBXwPLw79fh/P2BrYAHm7/uQTPPxx4BdgALAHOj4nhbmAN8BFwDZAT8zpeBm4Mn7cQODScvwRYDZwXs487gZuAv4exvAz0D2NdD8wF9otZ34GRTZ5/Xfj4CGApcGW4nxXABU3XBUqBrUBDTBkPBK4F7o1Z/+CY1z8TOKLJ+7UQqAYWAeckKMNi4K7wtcwJ39ulMcsHAn8Oy3IRcHnMsmsJfkzcHe5nNlDViuc+DNwLbAIuBA4CXg1fzwrgd0BBuP6LYdluCcvjjHD+ycCM8DmvABNi9rEf8HYY2x+BBxvfiwTH98vhPjeG7+tR4bLTgbearP9N4G/NbGuPsm9uH8l8doCLwveoGngf2B+4JzxOtobl8i1gWFhWU4GPgRfD5/8JWBnu+0VgfLzjNMFr2mPf4fzFwNHxtkF4vMdMXxW+rmpgHnAUcDxQS/AdshmY2VJZsPtn+JNw2fmE308xn8NLgA/DY+P3gIXLcoEbgLXh+/O1cP28lHyXpuMLOuo/oHtY2HcBJwA94hz0L8V53mCCL/cTwulHgP8l+JLrC7wBfDXBPn8EvBau14fgA/7jcFnjQR73TQOGhgfaWUA+0AuYFC67G/gbUBZu5wNgaszr2AFcEB4o14Ufot8TJKdjw+12izno1wIHEJzRPBceVOfGPP/5JgdmcwliR/i684ETgZrGso6z7tImr/lawgQBDArfrxMJqj2PCaf7hGW/CRgdrjuAmC+DJtv8OfAC0AOoBN5t3G+43beA7xOcUe5F8MV3XEw828IYcoGfAa+14rl1wOfDdYvDMj6Y4Cx9GMEX0tebKdv9CBLt5HD/5xF8YRWG+/wI+EZY1qeF+2suQeyIWf8Mgi/SnuH21gFjY9Z/B/hinO0kLPvm9tHSZ4cgSS0DDgQMGAkMDZctJvySbvLZuTvcVnE4/ysEn4nGH2Yz4h2ncV5TUvtuug1ijmFgNMEPsIExMY5oelzHPLe5smgsx8sIjpVi4ieIx4EKYAjBj5Tjw2WXECS5SoLj/h8oQSSVJMaGb/LS8A14FOgX86a81GT9YoIvgavC6X4EVVLFMeucRcwXaJPnLwBOjJk+Dljc5CBPlCC+DTwSZ34uwS+ScTHzvgpMi3kdH8Ys2zfcT7+YeZ+wK9ncCfxfzLLLgDlNnr8hZrqlBLE19jURfMEdnGDd5hLEVcA9TZY/TfAlWUrwq+mLse9FgnLc+aUdTl/Irg/1ZODjOOX+h5h4/hGzbBywtRXPfbGF2L4e+x7HKdubCX9QxMybB3wG+DTBDxeLWfYKzSeIpuu/AXw5Zl8/CR+PJzjjKoyznYRl39w+aOGzE763VySIfTHxE8RezZRtRbhOedNjL866Se276TbYPUGMJDjWjwbyEx3X4XRLZXF+nGPrfPZMEIfHTD8EXB0+fo6YH61hTClLEJ22kdrd57j7+e5eCexDUEXw62aecjswz92vD6eHEvwyWmFmG8xsA8GvgL4Jnj+Q4Fdeo4/CeckYTJBgmuodxtB0u4NiplfFPN4K4O5N53VrZv3m1m3JJ757fWlNK5/faChwemM5h2V9ODDA3bcQ/Dq9hOC9eMLMxiTYzkCCX3aNYh8PBQY22cd3CD7AjVY2eS1FZpaX5HNj94WZ7W1mj5vZSjPbBPyU4P1srgyubLKPweFrGggs8/AbIPRRvI3EiLd+4/F4F3C2mRnBF/pD7r5H+1wSZZ9oHy19dhId783ZWb5mlmtmPzezBWHZLg4XNVe+jdqy7924+3yChH8tsNrMHjSzRJ/1ZL5HlsR95u6aHpuNn7Pmjvl267QJIpa7zyX4RbBPvOVmdjVBW8HUmNlLCDJ/b3evCP+6u/v4BLtZTnAwNBoSzkvGEmBEnPlrCaoSmm53WZLbba8aoCRmun8bt+MtLF9CcAZREfNX6u4/B3D3p939GIIqjrnA/yXYzgqCU+1Gg5vsY1GTfZS5+4lJxJ/Mc5u+xpvDWEe5e3eChGIt7OMnTfZR4u4PhK9rUPiF3mhICzHHW385gLu/RnBm+ingbIK6/7haKPtE+2jps5PoeIfEx0rs/LOBUwh+LZcTnGVA8+XbqLl9x9pCM8e+u9/v7ocTfDYdaPxh2TT+ZL5HWvp8NKe5Y77dOmWCMLMxZnalmVWG04MJTutei7PuCcDlwBfcfWvjfHdfATwD3GBm3c0sx8xGmNlnEuz2AeAaM+tjZr0J6quT7e52H3C0mX3JzPLMrJeZTXL3eoLTyZ+YWZmZDSVoUGxXN7pWmEHwSzPXzI4nqO5oi1VALzMrT7D8XmCKmR0X7qso7BpbaWb9zOwUMysl+KBtJmjIjOch4Ntm1sPMBhE02DV6A6g2s6vMrDjczz6NXZ9b0JbnlhHU328Of3Vf2mT5KoK2jEb/B1xiZpMtUGpmJ5lZGUFj9w7gcjPLN7NTCRrBm9M3Zv3TCapcn4xZfjdBA3Odu8e9ZiKJso+7jyQ+O7cB/2lmB4SvdWR4bMcrl3jKwng+IfgS/2kL68dqbt+xZgAnmllPM+tPcMYAgJmNNrMjzayQoN2qsRNGY/zDzCwH2vQ90loPAVeY2SAzqyCork2ZTpkgCBpmJwOvm9kWgsTwHkGPm6bOIGgMnWPBRWybzeyWcNm5BA2E7xPU0z5M8EsqnuuA6QQNo7MIepwkdbGOu39M0Dh6JUED4gxgYrj4MoJfMwuBl4D7gTuS2W4KXAFMIaiHPgf4a1s2Ep7BPQAsDE+zBzZZvoTgF+F3CBrglgD/RXB85hAkxeUEZfMZ9vyybfQjgjanRQSNdQ8Tdm0Ok+3JwKRw+VqCL4tESSs2vrY89z8JfulWE3z5/7HJ8muBu8Ly+JK7TyfoXfM7gmNtPkFdNO5eC5waTq8jOGb/0kLYrwOjwlh/Apzmu19/cw/BGXVzPzZaKvvm9pHws+PufwrXv5+gfP5K0IAOQeeAa8Jy+c8Ecd1NUJ21LNz+Hj/8Emlh37HuIehNt5jgCz72/Ssk6BCxlqDqpy9BmxQEvasAPjGzt8PHrfkeaa3/C+N7l6CzwZMEPybqU7Hxxq5SIp2OmV0KnOnuqfq11mmYWTFBQ+v+7v5hG55/PnBhWM0iGSKsEbnF3eOdFbVaZz2DkC7IzAaY2WHhafxogjOyR6KOK0NdCrzZluQgmSOs8jwxrJoeBPyAFB7zGZUgwnrX6WZ2ctSxSFYqIOghUk3Q/e9vBBcGSgwzW0xQfRivylWyiwE/JKi6eofgepvvp2zj6axiMrM7COpuV7v7PjHzjwf+h6Cf/22NvVXM7EcEDWHvu/vjaQtMRERalO4E8WmCL/y7GxOEmeUSXA18DEGD4psEPYwGEVxBXASsVYIQEYlWWgfrc/cXzWxYk9kHAfPdfSGAmT1I0IOlG8GVm+OArWb2pLvv0Z3RzC4GLgYoLS09YMyYRNdMiYhIPG+99dZad+/T0npRjOY6iN2v9lsKTHb3r8HO3hFr4yUHAHe/FbgVoKqqyqdPn57eaEVEOhkza+lKfCADh/t29zujjkFERKLpxbSM3S8Hr6SVQ0eY2RQzu3Xjxo1tCmDz9h0sWVfTpueKiHQVUSSIN4FRZjbczAqAMwlGWk2auz/m7heXl7d4EWxct/1rIZ/6xfPUN+giQRGRRNKaIMzsAYJxZEab2VIzmxqO/vk1gmF35xCMJNmhd1orKcgFYFtdSq5GFxHplNLdi+msBPOfZPeBw1rFzKYAU0aObNstfYsLgpddU1tPaWHGNcOIiGSEjLqSOlntrWIqzg/OILbW6gxCRCSRrEwQ7dVYxbRVVUwiIgllZYJoby+mxjOImtodLawpItJ1ZWWCaHcVk84gRERalJUJor12VjGpDUJEJKGsTBCpq2JSghARSSQrE4SqmERE0i8rE0R7lYTXQaiKSUQksS6ZIFTFJCLSsi6ZIIryg5etKiYRkcSyMkG0t5HazCjOz2WrroMQEUkoKxNEexupIejqqjMIEZHEsjJBpEJxQa7aIEREmtF1E0R+rnoxiYg0o8smCFUxiYg0LysTRHsbqUFVTCIiLcnKBJGKRmpVMYmINC8rE0QqlBTkqYpJRKQZXTZBFOkMQkSkWV02QaiRWkSkeV06QeiOciIiiXXZBFGUn8u2ugYaGjzqUEREMlJWJohUdHNtvKvcth2qZhIRiScrE0SqxmICDfktIpJIViaIVCjK132pRUSa02UTxM67yqknk4hIXF02QRQXBC9dVUwiIvF13QSRr/tSi4g0p8smiMZG6q11uhZCRCSeLpsgitWLSUSkWV03QagXk4hIs7IyQaTyQjn1YhIRiS8rE0RK7gehKiYRkWZlZYJIhaI8VTGJiDSnyyaInByjKD9HVUwiIgl02QQBwdXUGvJbRCS+Lp0ggvtSN0QdhohIRuraCaIgVxfKiYgk0KUTREmB7kstIpJIl04Qxfm56uYqIpJA104QBbnqxSQikkCXThCqYhIRSaxLJ4giVTGJiCTUpRNEiaqYREQSypgEYWZjzewWM3vYzC7tiH2WFOSpiklEJIG0Jggzu8PMVpvZe03mH29m88xsvpldDeDuc9z9EuBLwGHpjKtRUX5wBtHQ4B2xOxGRrJLuM4g7geNjZ5hZLvB74ARgHHCWmY0Ll30OeAJ4Ms1xAbuG/N62Q2cRIiJNpTVBuPuLwLomsw8C5rv7QnevBR4ETgnXf9TdTwDOSWdcjcqKgvtSV2/T1dQiIk3lRbDPQcCSmOmlwGQzOwI4FSikmTMIM7sYuBhgyJAh7QqkorgAgA01dfTrXtSubYmIdDZRJIi43H0aMC2J9W4FbgWoqqpqV+NBRUk+ABtqatuzGRGRTimKXkzLgMEx05XhvKSl4pajAOXFQYLYuLWuXdsREemMokgQbwKjzGy4mRUAZwKPtmYDqbjlKMScQShBiIjsId3dXB8AXgVGm9lSM5vq7juArwFPA3OAh9x9djrjSKSiJGiD2FijBCEi0lRa2yDc/awE85+kHV1ZzWwKMGXkyJFt3QQApQW55OUYG7aqDUJEpKmMuZK6NVJVxWRmlBfns0FnECIie8jKBJFK5SX5aoMQEYkjKxNEqnoxAVQU56sNQkQkjqxMEKmqYoKgoVptECIie8rKBJFKFWqDEBGJq8sniPISVTGJiMSTlQkitW0QBVRv30FdfUMKIhMR6TxaTBBmNsLMCsPHR5jZ5WZWkf7QEkttG0RwNfUm9WQSEdlNMmcQfwbqzWwkwSB5g4H70xpVB9JwGyIi8SWTIBrC4TG+APzW3f8LGJDesDpO44B9aqgWEdldMgmizszOAs4DHg/n5acvpJalsg2iMUGoiklEZHfJJIgLgEOAn7j7IjMbDtyT3rCal+rrIABdCyEi0kSLg/W5+/tmdhUwJJxeBFyf7sA6SoWqmERE4kqmF9MUYAbwVDg9ycxadf+GTNZdCUJEJK5kqpiuBQ4CNgC4+wxgrzTG1KFyc4zuRXm6q5yISBNJNVK7e9PW4EivKktlIzWE4zHpvtQiIrtJJkHMNrOzgVwzG2VmvwVeSXNczUplIzUE10LoOggRkd0lkyAuA8YD24EHgE3A19MZVEfTTYNERPaUTC+mGuC74V+nVFFSwNL1W6MOQ0QkoyRMEGb2GOCJlrv759ISUQSCIb/VBiEiEqu5M4hfhf9PBfoD94bTZwGr0hlUR6soyWfj1joaGpycHIs6HBGRjJAwQbj7CwBmdoO7V8UseszMpqc9sg5UXpxPg0P1th2Ul0Q6ioiISMZIppG61Mx2XvcQDrVRmr6QWpbqbq6j+5cBMO2D1SnZnohIZ5BMgvgGMM3MppnZC8DzwBXpDat5qe7metiI3uzVu5Q/vLw4JdsTEekMWkwQ7v4UMIogKVwOjHb3Z9IdWEfKyTHOPWQoM5ZsYMaSDVGHIyKSEZIZiykf+CrwvfDvonBep/LFAyrpVpjHXa8sjjoUEZGMkEwV083AAcBN4d8B4bxOpawon9MOqOTxd5czf3V11OGIiEQumQRxoLuf5+7PhX8XAAemO7AoXPKZEZQX5zP1rums26LrIkSka0smQdSb2YjGibBHU336QopO//Iibj23ihUbt3HJPW9phFcR6dKSSRD/BTwf04vpOeDK9IYVnf2H9OCG0ycy/aN1HPPfL/D3WSuoq4908FoRkUgkMxbTP81sFDA6nDXP3benN6xoTZk4kKG9Srjqz7O49L63KcrPYUJlBceO68fJEwbSv7wo6hBFRNLO3BMOt7RrJbNDgWHEJBR3vzt9YSWnqqrKp09P30XddfUNPDN7FdM/WsdrC9cxZ8Umcgx+MGU85x06LG37FRFJJzN7q8kIGXG1eAZhZvcAIwhuO9rY9uBAZAkivA3qlJEjR6Z1P/m5OZw0YQAnTRgAwMI1m/npk3P5waOz2VZXz1c/M6KFLYiIZK8WzyDMbA4wzpM51ehg6T6DiKeuvoFvPjSTx2YuZ0jPEg7ZqxdHje3Lp/fuQ1F+bofGIiLSFik7gwDeIxjNdUW7o+oE8nNz+PUZkzh4r568MG8NT763gj9OX0JpQS4n7juAsycPYdLgCsw0KqyIZLdkziCeByYBbxDcVQ7IjPtBRHEG0VRdfQOvLfyEx2eu4LF3l1NTW8+Xqir56Rf2JS83mU5iIiIdK5VnENe2P5zOKz83h0+N6sOnRvXhmpPHctO0Bdw8bQEbaur4zVn7qdpJRLJWMt1cX+iIQDqDsqJ8rjp+DH3LCvnhY+/zb7e9zv9++QB6dSuMOjQRkVZTHUgaXHDYcH539n7MWraRz9/0MvNXb446JBGRVlOCSJOTJwzkwYsPZmttPefc9hpL1tVEHZKISKskTBBm9s/w//UdF07nst+QHtx74WS21tZz7h1vsGDNZjKwt7CISFzNtUEMCK+g/pyZPQjs1m/T3d9Oa2SdxJj+3bnj/AP5t9tf56gbXqBbYR49SwsA6NWtgDH9yxjWq5Te3QqZUFnOqH5lEUcsIhJI2M3VzE4DpgKHA037krq7H5nm2FqUCd1ck7Vo7RZeWbCWD1ZWs2nbDtydlZu2MXdlNRtqdo0ae8ToPpy6fyUDyovo062Qvt0LKSlIprOZiEhy2t3N1d0fBh42s++5+49TGl0XNLx3KcN7l+4x393ZUlvP6k3beHLWCv7w8mKmzVuz2zoDy4s47YBKvrB/JcN6legiPBHpEMkO1vc54NPh5DR3fzytUSUpm84gkrWtrp5Fa7ewpno7q6u3s7p6G28sWscLH6zBHSpK8tmrdym5OUZRfi7jB5YzsbKcCYMrGFhepOQhIi1K9gwimSupfwYcBNwXzjoLeNPdv9PuKPfc1+eBk4DuwO3u/kxz63fGBJHIsg1bmTZvNe8t28hHnwQ9ojZureODVdXU1QfvYY+SfAaUFzO4ZzFHjO7LMeP60VvXYIhIE6lMEO8Ck9y9IZzOBd5x9wlJBnIHcDKw2t33iZl/PPA/QC5wm7v/PGZZD+BX7j61uW13pQSRyPYd9cxdUc27SzcwZ2U1qzZu44PV1SxZtxWAkX27sf+QCvYf0oOqYT0Z2bdbxBGLSNRSOdQGQAWwLnxc3spY7gR+R8zw4GGS+T1wDLAUeNPMHnX398NVrgmXSwsK83KZOLiCiYMrds5zd+aurOafc1bx9scbeOb9VTw0fSkAP5gyjgsOGx5VuCKSRZJJED8D3gkH7TOCtoirk92Bu79oZsOazD4ImO/uCwHCbrSnhEOL/xz4e6JutGZ2MXAxwJAhQ5INo0sxM8YO6M7YAd2BIGEsWruFnz45hx8//j7Depfy2dF9I45SRDJdso3UA4ADw8k33H1lq3YSJIjHG6uYwi60x7v7heH0l4HJwAfAecCbwAx3v6W57aqKqXW2bN/Babe8ypJ1NUyZOJDBPYsZ3KOEQT2KKcrLxQx6dyukd7cCNXaLdGIprWJy9xXAo+2OquX9/Ab4Tbr301WVFuZx+3lVfPOhGTz13grWx1x/Eas4P3dn8hjcM/grKwwOlXEDu7PPoNbWMopINorqCqxlwOCY6cpwXlI66pajndHAimIevPgQADZv38HS9TUs37CV2h2Ou7Nq0zaWrN/Kx+tqWLKuhtcWfsKW2vrdtjGxspwDhvbEDMqL8xnaq4RhvUoZ1ruU8uL8KF6WiKRBUlVM7d7JnlVMeQTVSUcRJIY3gbPdfXZrtqsqpvRzd9bX1LG1rp76eue5uat48M0lLF2/dedFfrF6lOQztFdwUWBs4hjRp5SyIiUPkUyQkm6uYW+j2e4+ph2BPAAcAfQGVgE/cPfbzexE4NcE3VzvcPeftGKbjWcQF3344YdtDU1SYFtdPR+vq2HR2i189MkWFn9SE/xfW8PyjVtpPLxyc4yqoT04acIAzjpoCPm6255IZFJ5HcTfgMvc/eNUBZcqOoPIbNvq6lm6voZFa2t45+P1PDd3NXNXVrN3v25ceexoepQUUJCXw3BVTYl0qFQmiBeB/QjuSb2lcb7uSS1t8Y/3V/GDR2ezbMPW3eaXF+eTFw4f8pnRfThp3wFMHt5T9/UWSYNU9mL6XgriEQHg6HH9OGxkb95Zsh73oOvtorVbWLZhKw3urK2u5ZG3l3H/6x/ToySfY8b1Y0JlBWMHdGdiZbkShkgHSvY6iKHAKHf/h5mVALnuXp326BLHozaITmxrbT0vfLCaJ2et5Pm5q6nevgMIrtE4ecIArjhqFD3Ce2qISOulsorpIoIrl3u6+wgzGwXc4u5HpSbUtlMVU+fn7izfuI2ZSzbw+LvLefb9VQztVco9Uw9iQHlx1OGJZKVkE0Qy5+v/ARwGbAJw9w8BjdMgHcLMGFRRzIn7DuCmcw7gnqmTWbVxG6fd/Cp/n7WCuvqGqEMU6bSSSRDb3b22cSK8hiHSGyub2RQzu3Xjxo1RhiEROHivXjxw8cEAXHrf2xzys39y1yuLqW/Qvb5FUi2ZKqZfABuAc4HLgH8H3nf376Y/vOapiqnr2lHfwIsfruG2fy3ilQWfsM+g7kwe3gsjSCKfHdOX3ByNJyUSTyrbIHII7k19LMFork8T3L8h8p9sShDi7jwxawW/eGoe67bUUlffwPYdDQzpWcI3j9mbUyYN1MCDIk2kLEGEGysAxhBULc2LrXKKkhKENFVX38DTs1fyvy8sZNayjRw3vh9f3L8SM6OyRzGj+5WRozML6eJSeQZxEnALsIDgDGI48FV3/3sqAm0LdXOVltQ3OLf9ayE3PPsBtTt2NWSXFeVRNTS4u15lj+Ldzi7GDShjZN+yKMIV6VCpTBBzgZPdfX44PQJ4oj3jM6WKziCkJaurt7F603Ya3Jm/ejNvLl7P9MXr+HD15j3Wzc81rjp+DFMPH65qKenUUnkldXVjcggtBCK7SE6kNfqWFdG3rAiACZUVnLp/JQDrt9TyyZZdNaU7Ghq44ZkPuO6JOTwxawVHjenLMeP6M7q/ziik60p4BmFmp4YPjwGGAg8RtEGcDnzs7v/eIRE2Q2cQkkruzr2vfcT9byxhzopNAEyZOJDzDx1KYV7uzvX6dS+iT1lhVGGKtFu7q5jM7A/NPdHdL2hjbCmjBCHpsnbzdu58eTG3vbSQbXW7X4xXmJfD/RdN5oChPSOKTqR9UtqLKVMpQUi6ra7exoyPN+ycbnC4/qm5bKip5ZF/P4xhvUsjjE6kbVLZSD2c4AK5YcS0WUQ53Ld6MUmUFq3dwqk3vYwDfcsK6d2tkOu/OIHBPUuiDk0kKalMEDOB24FZwM5zbXd/ob1BtpfOICQqM5ds4LaXFrGjvoGX56+ltDCPey+czIg+3aIOTaRFqUwQr7v75JRFlkJKEJIJ3l++iS/f/jo1tfVUlOQHNz3auw+nTBrIfkN6RB2eyB5SmSDOBkYBzwDbG+e7+9vtDbK9lCAkUyxcs5k7Xl5E7Y4G1m2p5cUP11K7o4E/XHAgnx2twY8ls6TyOoh9gS8DR7KrisnDaREB9urTjes+v+/O6eptdUz57Uv8/Mm5fHpUHw0cKFkpmeG+Twf2cvfPuPtnwz8lB5FmlBXl863jxzBvVTV/fntp1OGItEkyCeI9oCLdgYh0Nifs059Jgyv472c+YEt421SRbJJMgqgA5prZ02b2aONfugNrjm4YJNnAzPjuSWNZXb2N0295lWUbtkYdkkirJNNI/Zl489XNVSQ5z89bzeX3v0NerjEqZrTYnBw4ckxfzjhwCOXF+RFGKF2NrqQWySDzV1dz/VPz2LxtV1XTpm11zF6+iaL8HPqUFZJjxuEjezP18OHspespJI1S2c21ml33oC4A8oEt7t693VG2kxKEZLvZyzfyp+lL2bS1jpraep6bt5q6+gZ+9oV9OfOgIVGHJ51Uyrq5uvvOc2ILBsk/BTi4feGJCMD4geWM/1z5zuk11du59N63+NUz8zhl0iC41W6SAAARGElEQVSKC3KbebZIeiXTSL2TB/4KHJemeES6tD5lhXzr+DGs3VzLfa9/FHU40sW1eAYRc18ICBJKFbAtbRGJdHEHDe/JoSN68b8vLuTfDh5KUb7OIiQayZxBTIn5O47gbnKnpDMoka7uiqNGsaZ6O7f9a2HUoUgXlkwbROQ3BhLpaibv1YuT9h3ADc9+wN79yjh2fP+oQ5IuKGGCMLPvN/M8d/cfpyGepMTcDyKqEETS7lenT2Tphq1c/uA73P2VyRw0XHewk47V3C1Hr4wzuxSYCvRy98g7aqubq3R2a6q388WbX2Hp+hrOPWQYpx1QiRmM7Nttt/tki7RGSi+UM7My4AqC5PAQcIO7r253lO2kBCFdwaZtdfzq6Xnc89pHNH5cJ1aW86dLDqUgr1UdEUWAFF0HYWY9gW8C5wB3Afu7+/rUhCgiyehelM+PTtmHfzt4KIvWbmHJuhque2IOv3hqLtecPC7q8KQTa64N4pfAqcCtwL7uvrnDohKRPezdr4y9+wXXrS5ZV8NtLy3i0JG9OHJMv4gjk86qufPTK4GBwDXAcjPbFP5Vm9mmjglPROL59oljGd2vjB8/PoeGhuwdT00yW8IE4e457l7s7mXu3j3mrywTxmES6cqK8nO59IgRLFq7hZfmr406HOmk1MIlkqVO2Lc/vUoLuPtVDckh6aEEIZKlCvNyOePAwTw3dxVL19dEHY50QkoQIlnsnIOHAnD/6x9HHIl0RkoQIllsUEUxh43szbPvr4o6FOmElCBEstyEynIWrt3C9h31UYcinYwShEiWG92/O/UNzoLVW6IORTqZjEkQZraXmd1uZg9HHYtINhnbP7h4bu5KXZ4kqZXWBGFmd5jZajN7r8n8481snpnNN7OrAdx9obtPTWc8Ip3R8N6lFOTmMHdlddShSCeT7jOIO4HjY2eYWS7we+AEYBxwlplpQBmRNsrLzWFk325KEJJyaU0Q7v4isK7J7IOA+eEZQy3wIK24Q52ZXWxm081s+po1a1IYrUj2GjOgjLkrVMUkqRVFG8QgYEnM9FJgkJn1MrNbgP3M7NuJnuzut7p7lbtX9enTJ92ximSFMf3LWF29nXVbaqMORTqRFm852lHc/RPgkqjjEMlGY/oHw6PNXbmJQ0f0jjga6SyiOINYBgyOma4M5yXNzKaY2a0bN25MaWAi2WrMgKAn0zy1Q0gKRZEg3gRGmdlwMysAzgQebc0G3P0xd7+4vLw8LQGKZJs+3QrpWVrAe8s2UVO7Q0OAS0qku5vrA8CrwGgzW2pmU919B/A14GlgDvCQu89OZxwinZ2ZMXZAGX9+eynjvv80X7j5FbbV6cpqaZ+k7kmdacxsCjBl5MiRF3344YdRhyOSEeau3MQL89awYWsdN09bwGVHjuTKY0dHHZZkoJTckzpTuftjwGNVVVUXRR2LSKYY07/7zsbqVZu2cfO0BZywzwDGDdT9vaRtMmaoDRFJne+dNI6Kknyu/su7ao+QNsvKBKFeTCLN61FawHdPGsu7SzfyyDut6iQoslNWJgj1YhJp2SkTBzGxspxfPj2PmtodUYcjWSgr2yBEpGU5OcY1J4/j9Fte5RdPzeO48f0TrtujNH9n+4VIo6xMEDG9mKIORSSjHTisJydNGMCdryzmzlcWN7vu45cdzj6DdFYuu2RlN9dGVVVVPn369KjDEMlodfUNvP3RehK1Vdc3OJfe9xafGtWbm845oGODk0h06m6uIpK8/NwcJu/Vq9l1zj1kKDdNW8CCNZsZ0adbB0UmmS4rG6lFJLUuOGw4hXk53DJtQdShSAbRGYSI0LtbIWceOIQ7X1nM399bucfywrwc7p56EOMHqo2iK8nKBKFGapHUu+zIkRTl51JX37DHsgfe+Ji7X/mI60+bEEFkEhU1UotIi/7rTzN5ctYK3vju0ZQWZuXvSomRbCO12iBEpEVnHjSYLbX1PPHuiqhDkQ6kBCEiLdp/SA9G9CnlwTc/jjoU6UA6VxSRFpkZZxw4mJ8+OZcL75pObvjTMi8nh28cszcj+6prbGeUlQlCjdQiHe+0Awbz7PurWLq+Zue8BWs207tbAT88ZZ8II5N0USO1iLTZhXe9yZwV1bx01Wcxs6jDkSSpkVpE0u6osf1YtmEr81ZVRx2KpIEShIi02VFj+gLwzzmrI45E0kEJQkTarG/3IiZUlvOPOauiDkXSQAlCRNrlqDH9mLFkA2s3b486FEmxrOzFJCKZ46ixfbnxHx9w7I0vUpjX8m/Orxw2nIs+vVcHRCbtlZUJQt1cRTLH+IHd+frRo1i+YWuL67668BP+/PZSJYgskZUJwt0fAx6rqqq6KOpYRLo6M+PrR++d1Lo3PvsBv33uQ7Zs36ExnbKA2iBEpMNMGlxBg8OsZRujDkWSoAQhIh1m4uAKAGYs2RBxJJIMJQgR6TA9SwsY0rOEmUoQWUEJQkQ61KTBFTqDyBJKECLSoSYOrmDFxm2s2rQt6lCkBUoQItKhJqkdImuon5mIdKjxA7uTl2M8rrvTtcv4gd2p7FGS1n1kZYLQhXIi2asoP5f9hlTw2MzlPDZzedThZK1fnDaBL1WlN0HofhAi0uE2batjybqalleUhAaWF9OjtKBNz032fhBZeQYhItmte1E+4weWRx2GtECN1CIiEpcShIiIxKUEISIicSlBiIhIXEoQIiISlxKEiIjEpQQhIiJxKUGIiEhcShAiIhKXEoSIiMSlBCEiInFlzFhMZlYK3ATUAtPc/b6IQxIR6dLSegZhZneY2Woze6/J/OPNbJ6ZzTezq8PZpwIPu/tFwOfSGZeIiLQs3VVMdwLHx84ws1zg98AJwDjgLDMbB1QCS8LV6tMcl4iItCCtVUzu/qKZDWsy+yBgvrsvBDCzB4FTgKUESWIGzSQuM7sYuDic3Gxm89oYXm9gbRuf21EUY2ooxtTI9BgzPT7InBiHJrNSFG0Qg9h1pgBBYpgM/Ab4nZmdBDyW6Mnufitwa3uDMLPpydwwI0qKMTUUY2pkeoyZHh9kR4yxMqaR2t23ABdEHYeIiASi6Oa6DBgcM10ZzhMRkQwSRYJ4ExhlZsPNrAA4E3g0gjjaXU3VARRjaijG1Mj0GDM9PsiOGHcyd0/fxs0eAI4gaJhZBfzA3W83sxOBXwO5wB3u/pO0BSEiIm2S1gQhIiLZS0NtiIhIXF0yQSS4kjtSZjbYzJ43s/fNbLaZXRHO72lmz5rZh+H/HhHHmWtm75jZ4+H0cDN7PSzLP4btSlHGV2FmD5vZXDObY2aHZGAZfiN8j98zswfMrCjqcow36kGicrPAb8JY3zWz/SOM8Zfhe/2umT1iZhUxy74dxjjPzI6LKsaYZVeamZtZ73A6knJsjS6XIJq5kjtqO4Ar3X0ccDDwH2FcVwP/dPdRwD/D6ShdAcyJmb4euNHdRwLrgamRRLXL/wBPufsYYCJBrBlThmY2CLgcqHL3fQja4c4k+nK8kyajHpC43E4ARoV/FwM3Rxjjs8A+7j4B+AD4NkD42TkTGB8+56bwsx9FjJjZYOBY4OOY2VGVY9K6XIIg5kpud68FGq/kjpS7r3D3t8PH1QRfbIMIYrsrXO0u4PPRRAhmVgmcBNwWThtwJPBwuErU8ZUDnwZuB3D3WnffQAaVYSgPKDazPKAEWEHE5ejuLwLrmsxOVG6nAHd74DWgwswGRBGjuz/j7jvCydcIus03xvigu29390XAfILPfofHGLoR+BYQ2+gbSTm2RldMEPGu5B4UUSxxhcOT7Ae8DvRz9xXhopVAv4jCgqDn2beAhnC6F7Ah5gMadVkOB9YAfwirwW6zYJTgjClDd18G/Irgl+QKYCPwFplVjo0SlVumfoa+Avw9fJwxMZrZKcAyd5/ZZFHGxJhIV0wQGc3MugF/Br7u7ptil3nQ5SySbmdmdjKw2t3fimL/ScoD9gdudvf9gC00qU6KsgwBwnr8UwiS2UCglDhVEpkm6nJriZl9l6CaNqNuE2BmJcB3gO9HHUtbdMUEkbFXcptZPkFyuM/d/xLOXtV42hn+Xx1ReIcBnzOzxQTVckcS1PdXhFUlEH1ZLgWWuvvr4fTDBAkjU8oQ4Ghgkbuvcfc64C8EZZtJ5dgoUbll1GfIzM4HTgbO8V399jMlxhEEPwZmhp+dSuBtM+tP5sSYUFdMEJlyJfduwvr824E57v7fMYseBc4LH58H/K2jYwNw92+7e6W7DyMos+fc/RzgeeC0qOMDcPeVwBIzGx3OOgp4nwwpw9DHwMFmVhK+540xZkw5xkhUbo8C54a9cA4GNsZURXUoMzueoNrzc+5eE7PoUeBMMys0s+EEDcFvdHR87j7L3fu6+7Dws7MU2D88VjOmHBNy9y73B5xI0ONhAfDdqOMJYzqc4BT+XYIhz2eEcfYi6EHyIfAPoGcGxHoE8Hj4eC+CD9584E9AYcSxTQKmh+X4V6BHppUh8ENgLvAecA9QGHU5Ag8QtInUEXyJTU1UboAR9ARcAMwi6JEVVYzzCerxGz8zt8Ss/90wxnnACVHF2GT5YqB3lOXYmj9dSS0iInF1xSomERFJghKEiIjEpQQhIiJxKUGIiEhcShAiIhKXEoRkJDPrb2YPmtkCM3vLzJ40s72jjisRMxtoZg+HjydZcFOsyJnZsHgji4okQwlCMk54AdkjwDR3H+HuBxCM0hnlOFTNcvfl7t54odskgmtYsl7M1d3SBSlBSCb6LFDn7rc0znD3me7+r/Cq019acC+FWWZ2BoCZHWFmL5jZ38xsoZn93MzOMbM3wvVGhOvdaWY3m9lr4XpHhGP4zzGzOxv3Z2abYx6f1rgsfP5vzOyV8PmnhfOHhTEVAD8CzjCzGWZ2hgX3U+gTrpcTjv/fJ/YFm9m1YRzTwu1eHrvdmPX+08yuDR9PM7MbzWx6GP+BZvaXcH/XxWw+z8zuC9d5OBwfCDM7ICyzt8zs6ZhhNaaZ2a/NbDrB8O7SRSlBSCbah2CE03hOJfiFPpFgXKNf2q4hkicClwBjgS8De7v7QQTDk18Ws40ewCHANwiGO7iR4L4B+5rZpCTiG0Bw5fvJwM9jF3gwhPz3gT+6+yR3/yNwL3BOuMrRwEx3XxNnu2OA4wiGpf5BODZXS2rdvQq4hWAojP8gKL/zzaxXuM5o4CZ3HwtsAv493PZvgdPCM7Q7gNh7wxe4e5W735BEDNJJKUFItjkceMDd6919FfACcGC47E0P7quxnWD4gmfC+bOAYTHbeMyDIQRmAas8GC+nAZjdZL1E/uruDe7+PslVe90BnBs+/grwhwTrPeHB/QvWEgyMl8y2G8cRmwXMjnn9C9k1ENwSd385fHwvQRmOJkgkz5rZDOAadt1LAeCPSexbOjnVL0omms2ugetaY3vM44aY6QZ2P9a3x1mn6XqxY9AUNbMfaykod19iZqvM7EiCs4NzEqwau936MJYd7P5DLlEsyb6WxmkjSCiHJIhlS4L50oXoDEIy0XNAoZld3DjDzCaY2aeAfxHU7+eG9fifJj2jdK4ys7FmlgN8oZXPrQbKmsy7jeDX+5/cvb41cQB9zayXmRUSVGu11hAza0wEZwMvEQxg16dxvpnlm9n4NmxbOjElCMk4YfXPF4Cjw26us4GfEdzV7BGCkVpnEiSSb3kwdHKqXQ08DrxCMDpnazwPjGtspA7nPQp0I3H1Ulwe3DPiRwRJ8FmCUWBbax7BPc7nELS/3By2lZwGXG9mMwlGQj20DduWTkyjuYp0ADOrAm50909FHYtIstQGIZJmZnY1cCmJ2x5EMpLOIEREJC61QYiISFxKECIiEpcShIiIxKUEISIicSlBiIhIXP8PREr5F2yqdHEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots\n",
    "\n",
    "y_pos = []\n",
    "x_labels = []\n",
    "for comm2 in communities2:\n",
    "    if comm2 == -1: continue\n",
    "    y_pos.append(len(post_df2[post_df_w_comm2[\"Community\"] == comm2]))\n",
    "#     x_labels.append(\"{}: {}\".format(comm, community_labels[comm]))\n",
    "    x_labels.append(community_labels[comm2])\n",
    "\n",
    "y_pos, x_labels = zip(*sorted(zip(y_pos, x_labels), reverse=True))\n",
    "\n",
    "plt.plot(y_pos)\n",
    "plt.title(\"Size of communities generated by spectral clustering\")\n",
    "plt.ylabel(\"Number of nodes\")\n",
    "plt.yscale('log')\n",
    "plt.ylim((1,10000))\n",
    "plt.xlabel(\"Community number\")\n",
    "plt.savefig('spec_community_size.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8343, 1037, 301, 246, 222, 210, 206, 200, 184, 180, 175, 169, 156, 145, 132, 130, 130, 128, 127, 122, 121, 120, 116, 114, 114, 112, 110, 109, 106, 104, 102, 92, 91, 90, 90, 89, 88, 87, 87, 84, 84, 83, 82, 81, 80, 79, 77, 73, 73, 72, 72, 70, 68, 67, 65, 60, 58, 55, 55, 53, 50, 50, 49, 48, 48, 48, 45, 44, 42, 42, 42, 38, 38, 35, 35, 34, 29, 27, 27, 27, 26, 26, 25, 21, 19, 18, 18, 16, 13, 8, 8, 7, 6, 6, 6, 6, 6, 5, 5, 5, 5, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pos = []\n",
    "x_labels = []\n",
    "for comm2 in communities2:\n",
    "    if comm2 == -1: continue\n",
    "    y_pos.append(len(post_df2[post_df_w_comm2[\"Community\"] == comm2]))\n",
    "#     x_labels.append(\"{}: {}\".format(comm, community_labels[comm]))\n",
    "    x_labels.append(community_labels[comm2])\n",
    "\n",
    "y_pos, x_labels = zip(*sorted(zip(y_pos, x_labels), reverse=True))\n",
    "\n",
    "print y_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "      <th>Community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>317836</td>\n",
       "      <td>187875</td>\n",
       "      <td>outliers</td>\n",
       "      <td>iqr</td>\n",
       "      <td>attached</td>\n",
       "      <td>articles</td>\n",
       "      <td>learned</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>317839</td>\n",
       "      <td>187543</td>\n",
       "      <td>vs age</td>\n",
       "      <td>5th percentile</td>\n",
       "      <td>variable vs</td>\n",
       "      <td>5th</td>\n",
       "      <td>percentile</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>318065</td>\n",
       "      <td>172079</td>\n",
       "      <td>data source</td>\n",
       "      <td>bias</td>\n",
       "      <td>source</td>\n",
       "      <td>selection bias</td>\n",
       "      <td>news</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>319427</td>\n",
       "      <td>151724</td>\n",
       "      <td>occupied</td>\n",
       "      <td>occupied past</td>\n",
       "      <td>past occupied</td>\n",
       "      <td>past</td>\n",
       "      <td>bird species</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>319729</td>\n",
       "      <td>189194</td>\n",
       "      <td>en wikipedia</td>\n",
       "      <td>wikipedia org</td>\n",
       "      <td>https en</td>\n",
       "      <td>org wiki</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>319809</td>\n",
       "      <td>3382</td>\n",
       "      <td>recorded fixed</td>\n",
       "      <td>fixed intervals</td>\n",
       "      <td>recorded</td>\n",
       "      <td>ambiguous recorded</td>\n",
       "      <td>better define</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>320986</td>\n",
       "      <td>189901</td>\n",
       "      <td>processes</td>\n",
       "      <td>probability statistics</td>\n",
       "      <td>stochastic processes</td>\n",
       "      <td>regression analysis</td>\n",
       "      <td>textbook</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>321502</td>\n",
       "      <td>144089</td>\n",
       "      <td>shrinkage factor</td>\n",
       "      <td>shrinkage</td>\n",
       "      <td>overall shrinkage</td>\n",
       "      <td>multinomial regression</td>\n",
       "      <td>level outcome</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>321747</td>\n",
       "      <td>130324</td>\n",
       "      <td>bias</td>\n",
       "      <td>statistical bias</td>\n",
       "      <td>bias differs</td>\n",
       "      <td>bias quantity</td>\n",
       "      <td>case kinds</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>321751</td>\n",
       "      <td>67791</td>\n",
       "      <td>egreg</td>\n",
       "      <td>past days</td>\n",
       "      <td>rep</td>\n",
       "      <td>se</td>\n",
       "      <td>past</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>322002</td>\n",
       "      <td>190656</td>\n",
       "      <td>outliers</td>\n",
       "      <td>outliers outliers</td>\n",
       "      <td>transmission</td>\n",
       "      <td>climate</td>\n",
       "      <td>bad</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>322082</td>\n",
       "      <td>111319</td>\n",
       "      <td>polson scott</td>\n",
       "      <td>scott windle</td>\n",
       "      <td>windle</td>\n",
       "      <td>polson</td>\n",
       "      <td>scott</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>322538</td>\n",
       "      <td>187387</td>\n",
       "      <td>ai course</td>\n",
       "      <td>deeplearning ai</td>\n",
       "      <td>sigmoid derivative</td>\n",
       "      <td>deeplearning</td>\n",
       "      <td>ai</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>322588</td>\n",
       "      <td>191159</td>\n",
       "      <td>taleb</td>\n",
       "      <td>content</td>\n",
       "      <td>make comment</td>\n",
       "      <td>org</td>\n",
       "      <td>en wikipedia</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>322647</td>\n",
       "      <td>37306</td>\n",
       "      <td>outliers</td>\n",
       "      <td>course remove</td>\n",
       "      <td>definition follow</td>\n",
       "      <td>distribution scrutiny</td>\n",
       "      <td>outliers definition</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>323832</td>\n",
       "      <td>115012</td>\n",
       "      <td>auc_</td>\n",
       "      <td>se auc_</td>\n",
       "      <td>se</td>\n",
       "      <td>auc_ se</td>\n",
       "      <td>auc_1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>324334</td>\n",
       "      <td>191472</td>\n",
       "      <td>processes</td>\n",
       "      <td>careful putting</td>\n",
       "      <td>coefficient false</td>\n",
       "      <td>cointegrated estimation</td>\n",
       "      <td>false significance</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>324367</td>\n",
       "      <td>192401</td>\n",
       "      <td>higher bias</td>\n",
       "      <td>bias</td>\n",
       "      <td>bias limit</td>\n",
       "      <td>bias reasonable</td>\n",
       "      <td>bootstrap higher</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>324473</td>\n",
       "      <td>31979</td>\n",
       "      <td>ecosystem</td>\n",
       "      <td>ecosystems</td>\n",
       "      <td>se</td>\n",
       "      <td>ecosystem type</td>\n",
       "      <td>upscaled</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>324488</td>\n",
       "      <td>112141</td>\n",
       "      <td>aimlcs229</td>\n",
       "      <td>edu materials</td>\n",
       "      <td>materials aimlcs229</td>\n",
       "      <td>cs229</td>\n",
       "      <td>https stanford</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>324689</td>\n",
       "      <td>191729</td>\n",
       "      <td>smoothing parameter</td>\n",
       "      <td>data support</td>\n",
       "      <td>following plot</td>\n",
       "      <td>gives following</td>\n",
       "      <td>dots</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>325179</td>\n",
       "      <td>73794</td>\n",
       "      <td>dataset somewhat</td>\n",
       "      <td>trees reduce</td>\n",
       "      <td>somewhat biased</td>\n",
       "      <td>bias</td>\n",
       "      <td>biased</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>325334</td>\n",
       "      <td>190274</td>\n",
       "      <td>light</td>\n",
       "      <td>artificial light</td>\n",
       "      <td>source</td>\n",
       "      <td>artificial</td>\n",
       "      <td>bat passes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>325478</td>\n",
       "      <td>97577</td>\n",
       "      <td>results</td>\n",
       "      <td>showing</td>\n",
       "      <td>histogram expected</td>\n",
       "      <td>showing observed</td>\n",
       "      <td>way display</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>325702</td>\n",
       "      <td>191330</td>\n",
       "      <td>got</td>\n",
       "      <td>ve got</td>\n",
       "      <td>adjust repeated</td>\n",
       "      <td>apart outcome</td>\n",
       "      <td>baselines ve</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>325813</td>\n",
       "      <td>11887</td>\n",
       "      <td>record_linkage</td>\n",
       "      <td>wiki record_linkage</td>\n",
       "      <td>information https</td>\n",
       "      <td>en wikipedia</td>\n",
       "      <td>wikipedia org</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>325883</td>\n",
       "      <td>192848</td>\n",
       "      <td>outliers</td>\n",
       "      <td>behavior</td>\n",
       "      <td>anybody willing</td>\n",
       "      <td>behavior did</td>\n",
       "      <td>behavior happy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6513</th>\n",
       "      <td>326022</td>\n",
       "      <td>19833</td>\n",
       "      <td>en</td>\n",
       "      <td>calculation said</td>\n",
       "      <td>default stuck</td>\n",
       "      <td>en asymptotically</td>\n",
       "      <td>en true</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>326267</td>\n",
       "      <td>164061</td>\n",
       "      <td>ecosystems</td>\n",
       "      <td>incorporate additional</td>\n",
       "      <td>ecosystem</td>\n",
       "      <td>effect model</td>\n",
       "      <td>incorporate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>326290</td>\n",
       "      <td>113777</td>\n",
       "      <td>gung</td>\n",
       "      <td>low variance</td>\n",
       "      <td>estimations</td>\n",
       "      <td>shrinkage</td>\n",
       "      <td>biased</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13782</th>\n",
       "      <td>336429</td>\n",
       "      <td>198360</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>outliers</td>\n",
       "      <td>adataframe</td>\n",
       "      <td>adataframe data</td>\n",
       "      <td>choosing good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14215</th>\n",
       "      <td>336998</td>\n",
       "      <td>201739</td>\n",
       "      <td>high control</td>\n",
       "      <td>high</td>\n",
       "      <td>counted</td>\n",
       "      <td>checked</td>\n",
       "      <td>did</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14455</th>\n",
       "      <td>337325</td>\n",
       "      <td>201992</td>\n",
       "      <td>audio</td>\n",
       "      <td>audio recorded</td>\n",
       "      <td>recorded</td>\n",
       "      <td>audio recognition</td>\n",
       "      <td>dataset negatively</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14517</th>\n",
       "      <td>337406</td>\n",
       "      <td>152331</td>\n",
       "      <td>hfood</td>\n",
       "      <td>model result</td>\n",
       "      <td>got</td>\n",
       "      <td>did</td>\n",
       "      <td>regression analysis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14612</th>\n",
       "      <td>337541</td>\n",
       "      <td>112141</td>\n",
       "      <td>ica</td>\n",
       "      <td>cs229</td>\n",
       "      <td>unmixing</td>\n",
       "      <td>audio</td>\n",
       "      <td>stanford</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14731</th>\n",
       "      <td>337692</td>\n",
       "      <td>7555</td>\n",
       "      <td>branch</td>\n",
       "      <td>branch votes</td>\n",
       "      <td>right branch</td>\n",
       "      <td>tree passenger</td>\n",
       "      <td>votes survive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14950</th>\n",
       "      <td>337983</td>\n",
       "      <td>202535</td>\n",
       "      <td>dots</td>\n",
       "      <td>black dots</td>\n",
       "      <td>red dots</td>\n",
       "      <td>semilandmarks</td>\n",
       "      <td>slid</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15052</th>\n",
       "      <td>338125</td>\n",
       "      <td>180727</td>\n",
       "      <td>xi</td>\n",
       "      <td>ni</td>\n",
       "      <td>poisson xi</td>\n",
       "      <td>xi gamma</td>\n",
       "      <td>xi ni</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15085</th>\n",
       "      <td>338169</td>\n",
       "      <td>193326</td>\n",
       "      <td>audio data</td>\n",
       "      <td>tier</td>\n",
       "      <td>phonetic</td>\n",
       "      <td>audio</td>\n",
       "      <td>sound</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15298</th>\n",
       "      <td>338438</td>\n",
       "      <td>202863</td>\n",
       "      <td>mean rms</td>\n",
       "      <td>muscle</td>\n",
       "      <td>rms</td>\n",
       "      <td>muscle variable</td>\n",
       "      <td>sec</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15300</th>\n",
       "      <td>338441</td>\n",
       "      <td>180722</td>\n",
       "      <td>bad things</td>\n",
       "      <td>bad</td>\n",
       "      <td>gets right</td>\n",
       "      <td>likely hit</td>\n",
       "      <td>things</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15405</th>\n",
       "      <td>338585</td>\n",
       "      <td>8013</td>\n",
       "      <td>neyman scott</td>\n",
       "      <td>scott paradox</td>\n",
       "      <td>shrinkage estimators</td>\n",
       "      <td>shrinkage</td>\n",
       "      <td>scott</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15605</th>\n",
       "      <td>338848</td>\n",
       "      <td>37306</td>\n",
       "      <td>outliers</td>\n",
       "      <td>assigning closest</td>\n",
       "      <td>assume median</td>\n",
       "      <td>averages assume</td>\n",
       "      <td>bimodal advise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>338932</td>\n",
       "      <td>203251</td>\n",
       "      <td>ai model</td>\n",
       "      <td>make ai</td>\n",
       "      <td>organization</td>\n",
       "      <td>data make</td>\n",
       "      <td>ai</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16563</th>\n",
       "      <td>340108</td>\n",
       "      <td>204085</td>\n",
       "      <td>percentile</td>\n",
       "      <td>completely independend</td>\n",
       "      <td>distribution reaches</td>\n",
       "      <td>estimate principal</td>\n",
       "      <td>independend possible</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17773</th>\n",
       "      <td>341685</td>\n",
       "      <td>205195</td>\n",
       "      <td>future</td>\n",
       "      <td>dots</td>\n",
       "      <td>past</td>\n",
       "      <td>comes ingested</td>\n",
       "      <td>dots light</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17920</th>\n",
       "      <td>341881</td>\n",
       "      <td>23853</td>\n",
       "      <td>outliers</td>\n",
       "      <td>bimodal fine</td>\n",
       "      <td>bootstrap outliers</td>\n",
       "      <td>distributed important</td>\n",
       "      <td>distributions going</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18191</th>\n",
       "      <td>342259</td>\n",
       "      <td>204247</td>\n",
       "      <td>boxplot</td>\n",
       "      <td>outliers</td>\n",
       "      <td>boxplot plot</td>\n",
       "      <td>come boxplot</td>\n",
       "      <td>dataset handle</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18269</th>\n",
       "      <td>342360</td>\n",
       "      <td>74500</td>\n",
       "      <td>shmueli</td>\n",
       "      <td>minimizing bias</td>\n",
       "      <td>professor shmueli</td>\n",
       "      <td>representation underlying</td>\n",
       "      <td>bias</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18329</th>\n",
       "      <td>342433</td>\n",
       "      <td>166983</td>\n",
       "      <td>percentile</td>\n",
       "      <td>calculating percentile</td>\n",
       "      <td>convert value</td>\n",
       "      <td>distributions scaled</td>\n",
       "      <td>moment looking</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18468</th>\n",
       "      <td>342632</td>\n",
       "      <td>177870</td>\n",
       "      <td>understand standard</td>\n",
       "      <td>se regression</td>\n",
       "      <td>error se</td>\n",
       "      <td>regression slope</td>\n",
       "      <td>se</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>342762</td>\n",
       "      <td>185965</td>\n",
       "      <td>understanding vae</td>\n",
       "      <td>learned distribution</td>\n",
       "      <td>vae</td>\n",
       "      <td>learned</td>\n",
       "      <td>past</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18599</th>\n",
       "      <td>342795</td>\n",
       "      <td>165273</td>\n",
       "      <td>built features</td>\n",
       "      <td>molecules</td>\n",
       "      <td>built</td>\n",
       "      <td>dose</td>\n",
       "      <td>subtract</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18629</th>\n",
       "      <td>342841</td>\n",
       "      <td>205978</td>\n",
       "      <td>anaesthetic</td>\n",
       "      <td>dose anaesthetic</td>\n",
       "      <td>high dose</td>\n",
       "      <td>dose</td>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18664</th>\n",
       "      <td>342883</td>\n",
       "      <td>142398</td>\n",
       "      <td>bad results</td>\n",
       "      <td>results</td>\n",
       "      <td>good results</td>\n",
       "      <td>bad</td>\n",
       "      <td>algorithm classify</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18829</th>\n",
       "      <td>343085</td>\n",
       "      <td>205209</td>\n",
       "      <td>bj</td>\n",
       "      <td>bias</td>\n",
       "      <td>positive bias</td>\n",
       "      <td>se</td>\n",
       "      <td>bias bj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19466</th>\n",
       "      <td>343900</td>\n",
       "      <td>44378</td>\n",
       "      <td>outliers</td>\n",
       "      <td>bad outlier</td>\n",
       "      <td>doing density</td>\n",
       "      <td>easy identify</td>\n",
       "      <td>histogram box</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19517</th>\n",
       "      <td>343965</td>\n",
       "      <td>181921</td>\n",
       "      <td>datum iqr</td>\n",
       "      <td>iqr</td>\n",
       "      <td>datum</td>\n",
       "      <td>quartile</td>\n",
       "      <td>highest datum</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19925</th>\n",
       "      <td>344520</td>\n",
       "      <td>98627</td>\n",
       "      <td>percentile</td>\n",
       "      <td>outliers</td>\n",
       "      <td>1st 99th</td>\n",
       "      <td>btw problem</td>\n",
       "      <td>impact outliers</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19928</th>\n",
       "      <td>344523</td>\n",
       "      <td>204636</td>\n",
       "      <td>sound</td>\n",
       "      <td>incongruent sound</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>congruent</td>\n",
       "      <td>simple effects</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  user_id             TopWord1                TopWord2  \\\n",
       "106     317836   187875             outliers                     iqr   \n",
       "109     317839   187543               vs age          5th percentile   \n",
       "292     318065   172079          data source                    bias   \n",
       "1348    319427   151724             occupied           occupied past   \n",
       "1576    319729   189194         en wikipedia           wikipedia org   \n",
       "1639    319809     3382       recorded fixed         fixed intervals   \n",
       "2538    320986   189901            processes  probability statistics   \n",
       "2953    321502   144089     shrinkage factor               shrinkage   \n",
       "3144    321747   130324                 bias        statistical bias   \n",
       "3148    321751    67791                egreg               past days   \n",
       "3345    322002   190656             outliers       outliers outliers   \n",
       "3406    322082   111319         polson scott            scott windle   \n",
       "3756    322538   187387            ai course         deeplearning ai   \n",
       "3794    322588   191159                taleb                 content   \n",
       "3841    322647    37306             outliers           course remove   \n",
       "4775    323832   115012                 auc_                 se auc_   \n",
       "5153    324334   191472            processes         careful putting   \n",
       "5185    324367   192401          higher bias                    bias   \n",
       "5261    324473    31979            ecosystem              ecosystems   \n",
       "5275    324488   112141            aimlcs229           edu materials   \n",
       "5440    324689   191729  smoothing parameter            data support   \n",
       "5830    325179    73794     dataset somewhat            trees reduce   \n",
       "5950    325334   190274                light        artificial light   \n",
       "6066    325478    97577              results                 showing   \n",
       "6240    325702   191330                  got                  ve got   \n",
       "6333    325813    11887       record_linkage     wiki record_linkage   \n",
       "6394    325883   192848             outliers                behavior   \n",
       "6513    326022    19833                   en        calculation said   \n",
       "6723    326267   164061           ecosystems  incorporate additional   \n",
       "6743    326290   113777                 gung            low variance   \n",
       "...        ...      ...                  ...                     ...   \n",
       "13782   336429   198360               dbscan                outliers   \n",
       "14215   336998   201739         high control                    high   \n",
       "14455   337325   201992                audio          audio recorded   \n",
       "14517   337406   152331                hfood            model result   \n",
       "14612   337541   112141                  ica                   cs229   \n",
       "14731   337692     7555               branch            branch votes   \n",
       "14950   337983   202535                 dots              black dots   \n",
       "15052   338125   180727                   xi                      ni   \n",
       "15085   338169   193326           audio data                    tier   \n",
       "15298   338438   202863             mean rms                  muscle   \n",
       "15300   338441   180722           bad things                     bad   \n",
       "15405   338585     8013         neyman scott           scott paradox   \n",
       "15605   338848    37306             outliers       assigning closest   \n",
       "15663   338932   203251             ai model                 make ai   \n",
       "16563   340108   204085           percentile  completely independend   \n",
       "17773   341685   205195               future                    dots   \n",
       "17920   341881    23853             outliers            bimodal fine   \n",
       "18191   342259   204247              boxplot                outliers   \n",
       "18269   342360    74500              shmueli         minimizing bias   \n",
       "18329   342433   166983           percentile  calculating percentile   \n",
       "18468   342632   177870  understand standard           se regression   \n",
       "18572   342762   185965    understanding vae    learned distribution   \n",
       "18599   342795   165273       built features               molecules   \n",
       "18629   342841   205978          anaesthetic        dose anaesthetic   \n",
       "18664   342883   142398          bad results                 results   \n",
       "18829   343085   205209                   bj                    bias   \n",
       "19466   343900    44378             outliers             bad outlier   \n",
       "19517   343965   181921            datum iqr                     iqr   \n",
       "19925   344520    98627           percentile                outliers   \n",
       "19928   344523   204636                sound       incongruent sound   \n",
       "\n",
       "                   TopWord3                   TopWord4              TopWord5  \\\n",
       "106                attached                   articles               learned   \n",
       "109             variable vs                        5th            percentile   \n",
       "292                  source             selection bias                  news   \n",
       "1348          past occupied                       past          bird species   \n",
       "1576               https en                   org wiki                    en   \n",
       "1639               recorded         ambiguous recorded         better define   \n",
       "2538   stochastic processes        regression analysis              textbook   \n",
       "2953      overall shrinkage     multinomial regression         level outcome   \n",
       "3144           bias differs              bias quantity            case kinds   \n",
       "3148                    rep                         se                  past   \n",
       "3345           transmission                    climate                   bad   \n",
       "3406                 windle                     polson                 scott   \n",
       "3756     sigmoid derivative               deeplearning                    ai   \n",
       "3794           make comment                        org          en wikipedia   \n",
       "3841      definition follow      distribution scrutiny   outliers definition   \n",
       "4775                     se                    auc_ se                 auc_1   \n",
       "5153      coefficient false    cointegrated estimation    false significance   \n",
       "5185             bias limit            bias reasonable      bootstrap higher   \n",
       "5261                     se             ecosystem type              upscaled   \n",
       "5275    materials aimlcs229                      cs229        https stanford   \n",
       "5440         following plot            gives following                  dots   \n",
       "5830        somewhat biased                       bias                biased   \n",
       "5950                 source                 artificial            bat passes   \n",
       "6066     histogram expected           showing observed           way display   \n",
       "6240        adjust repeated              apart outcome          baselines ve   \n",
       "6333      information https               en wikipedia         wikipedia org   \n",
       "6394        anybody willing               behavior did        behavior happy   \n",
       "6513          default stuck          en asymptotically               en true   \n",
       "6723              ecosystem               effect model           incorporate   \n",
       "6743            estimations                  shrinkage                biased   \n",
       "...                     ...                        ...                   ...   \n",
       "13782            adataframe            adataframe data         choosing good   \n",
       "14215               counted                    checked                   did   \n",
       "14455              recorded          audio recognition    dataset negatively   \n",
       "14517                   got                        did   regression analysis   \n",
       "14612              unmixing                      audio              stanford   \n",
       "14731          right branch             tree passenger         votes survive   \n",
       "14950              red dots              semilandmarks                  slid   \n",
       "15052            poisson xi                   xi gamma                 xi ni   \n",
       "15085              phonetic                      audio                 sound   \n",
       "15298                   rms            muscle variable                   sec   \n",
       "15300            gets right                 likely hit                things   \n",
       "15405  shrinkage estimators                  shrinkage                 scott   \n",
       "15605         assume median            averages assume        bimodal advise   \n",
       "15663          organization                  data make                    ai   \n",
       "16563  distribution reaches         estimate principal  independend possible   \n",
       "17773                  past             comes ingested            dots light   \n",
       "17920    bootstrap outliers      distributed important   distributions going   \n",
       "18191          boxplot plot               come boxplot        dataset handle   \n",
       "18269     professor shmueli  representation underlying                  bias   \n",
       "18329         convert value       distributions scaled        moment looking   \n",
       "18468              error se           regression slope                    se   \n",
       "18572                   vae                    learned                  past   \n",
       "18599                 built                       dose              subtract   \n",
       "18629             high dose                       dose                  high   \n",
       "18664          good results                        bad    algorithm classify   \n",
       "18829         positive bias                         se               bias bj   \n",
       "19466         doing density              easy identify         histogram box   \n",
       "19517                 datum                   quartile         highest datum   \n",
       "19925              1st 99th                btw problem       impact outliers   \n",
       "19928           incongruent                  congruent        simple effects   \n",
       "\n",
       "       Community  \n",
       "106            5  \n",
       "109            5  \n",
       "292            5  \n",
       "1348           5  \n",
       "1576           5  \n",
       "1639           5  \n",
       "2538           5  \n",
       "2953           5  \n",
       "3144           5  \n",
       "3148           5  \n",
       "3345           5  \n",
       "3406           5  \n",
       "3756           5  \n",
       "3794           5  \n",
       "3841           5  \n",
       "4775           5  \n",
       "5153           5  \n",
       "5185           5  \n",
       "5261           5  \n",
       "5275           5  \n",
       "5440           5  \n",
       "5830           5  \n",
       "5950           5  \n",
       "6066           5  \n",
       "6240           5  \n",
       "6333           5  \n",
       "6394           5  \n",
       "6513           5  \n",
       "6723           5  \n",
       "6743           5  \n",
       "...          ...  \n",
       "13782          5  \n",
       "14215          5  \n",
       "14455          5  \n",
       "14517          5  \n",
       "14612          5  \n",
       "14731          5  \n",
       "14950          5  \n",
       "15052          5  \n",
       "15085          5  \n",
       "15298          5  \n",
       "15300          5  \n",
       "15405          5  \n",
       "15605          5  \n",
       "15663          5  \n",
       "16563          5  \n",
       "17773          5  \n",
       "17920          5  \n",
       "18191          5  \n",
       "18269          5  \n",
       "18329          5  \n",
       "18468          5  \n",
       "18572          5  \n",
       "18599          5  \n",
       "18629          5  \n",
       "18664          5  \n",
       "18829          5  \n",
       "19466          5  \n",
       "19517          5  \n",
       "19925          5  \n",
       "19928          5  \n",
       "\n",
       "[97 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMM_TEST = 5\n",
    "\n",
    "print len(post_df[post_df_w_comm[\"Community\"] == COMM_TEST])\n",
    "\n",
    "post_df[post_df_w_comm[\"Community\"] == COMM_TEST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word frequency in communities2\n",
    "word_counts2 = collections.defaultdict(dict)\n",
    "word_freqs2 = collections.defaultdict(dict)\n",
    "for comm in communities2:\n",
    "    total_rows = 0.0\n",
    "    word_counts2[comm] = collections.defaultdict(int)\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord1']:\n",
    "        word_counts2[comm][word] += 1\n",
    "        total_rows += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord2']:\n",
    "        word_counts2[comm][word] += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord3']:\n",
    "        word_counts2[comm][word] += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord4']:\n",
    "        word_counts2[comm][word] += 1\n",
    "    for word in post_df_w_comm2[post_df_w_comm2[\"Community\"] == comm]['TopWord5']:\n",
    "        word_counts2[comm][word] += 1\n",
    "    for word in word_counts2[comm]:\n",
    "        word_freqs2[comm][word] = word_counts2[comm][word] / total_rows\n",
    "    \n",
    "sorted_word_freqs2 = collections.defaultdict(dict)\n",
    "for comm in word_freqs2:\n",
    "    sorted_word_freqs2[comm] = sorted(word_freqs2[comm].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "COMM_TERMS2 = 64\n",
    "y_pos = []\n",
    "x_labels = []\n",
    "for word in sorted_word_freqs2[COMM_TERMS2][:10]:\n",
    "    y_pos.append(word[1])\n",
    "    x_labels.append(word[0])\n",
    "    \n",
    "plt.bar(x_labels, y_pos)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Proportion of posts\")\n",
    "plt.title(\"Spectral clustering community 'learning|deep learning|rate'\")\n",
    "plt.suptitle('Proportion of posts for which a specific term is \"important\"')\n",
    "plt.savefig('spec_proportion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318423</td>\n",
       "      <td>texts</td>\n",
       "      <td>author</td>\n",
       "      <td>learning</td>\n",
       "      <td>author texts</td>\n",
       "      <td>berger extremely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319130</td>\n",
       "      <td>hardness</td>\n",
       "      <td>learning</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>deep</td>\n",
       "      <td>non informative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>319532</td>\n",
       "      <td>principled</td>\n",
       "      <td>science</td>\n",
       "      <td>learning</td>\n",
       "      <td>able technologies</td>\n",
       "      <td>build ships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320357</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>multilayer</td>\n",
       "      <td>deep</td>\n",
       "      <td>learning</td>\n",
       "      <td>learning algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320803</td>\n",
       "      <td>policy</td>\n",
       "      <td>policy methods</td>\n",
       "      <td>methods</td>\n",
       "      <td>sutton barto</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id       TopWord1        TopWord2       TopWord3           TopWord4  \\\n",
       "0   318423          texts          author       learning       author texts   \n",
       "1   319130       hardness        learning  deep learning               deep   \n",
       "2   319532     principled         science       learning  able technologies   \n",
       "3   320357  deep learning      multilayer           deep           learning   \n",
       "4   320803         policy  policy methods        methods       sutton barto   \n",
       "\n",
       "             TopWord5  \n",
       "0    berger extremely  \n",
       "1     non informative  \n",
       "2         build ships  \n",
       "3  learning algorithm  \n",
       "4            learning  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df2[post_df_w_comm2[\"Community\"] == 64][1:6][[\"post_id\", \"TopWord1\", \"TopWord2\", \"TopWord3\", \"TopWord4\", \"TopWord5\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>TopWord1</th>\n",
       "      <th>TopWord2</th>\n",
       "      <th>TopWord3</th>\n",
       "      <th>TopWord4</th>\n",
       "      <th>TopWord5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318082</td>\n",
       "      <td>architecture</td>\n",
       "      <td>reinforcement learning</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>learning</td>\n",
       "      <td>24x24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318311</td>\n",
       "      <td>ordinate</td>\n",
       "      <td>elbow</td>\n",
       "      <td>elbow point</td>\n",
       "      <td>drops</td>\n",
       "      <td>value ordinate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318423</td>\n",
       "      <td>texts</td>\n",
       "      <td>author</td>\n",
       "      <td>learning</td>\n",
       "      <td>author texts</td>\n",
       "      <td>berger extremely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319061</td>\n",
       "      <td>bus</td>\n",
       "      <td>observe process</td>\n",
       "      <td>having seen</td>\n",
       "      <td>long</td>\n",
       "      <td>minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319130</td>\n",
       "      <td>hardness</td>\n",
       "      <td>learning</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>deep</td>\n",
       "      <td>non informative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id      TopWord1                TopWord2       TopWord3      TopWord4  \\\n",
       "0   318082  architecture  reinforcement learning  reinforcement      learning   \n",
       "1   318311      ordinate                   elbow    elbow point         drops   \n",
       "2   318423         texts                  author       learning  author texts   \n",
       "3   319061           bus         observe process    having seen          long   \n",
       "4   319130      hardness                learning  deep learning          deep   \n",
       "\n",
       "           TopWord5  \n",
       "0             24x24  \n",
       "1    value ordinate  \n",
       "2  berger extremely  \n",
       "3           minutes  \n",
       "4   non informative  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df[post_df_w_comm[\"Community\"] == 9][1:6][[\"post_id\", \"TopWord1\", \"TopWord2\", \"TopWord3\", \"TopWord4\", \"TopWord5\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm_postids = set(post_df[post_df_w_comm[\"Community\"] == 9][\"post_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_postids = set(post_df2[post_df_w_comm2[\"Community\"] == 64][\"post_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnm_postids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spectral_postids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnm_postids.intersection(spectral_postids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs224w]",
   "language": "python",
   "name": "conda-env-cs224w-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
